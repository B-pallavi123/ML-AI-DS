{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/B-pallavi123/ML-AI-DS/blob/main/Assigment_for_HAI_interview_(2)_(5)_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWA2TdtpyBoW"
      },
      "source": [
        "# Fundamental Machine Learning Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "US7XqP1SyHrt"
      },
      "source": [
        "## Easy\n",
        "### Score - 3 points for each correct and confident answer\n",
        "1. What is the difference between supervised, semi-supervised, weakly supervised, and unsupervised learning?\n",
        "\n",
        "2. Can you explain the concept of overfitting? How can you avoid it? Answer the question from a traditional ML perspective.\n",
        "\n",
        "3. What is generalization? How do you evaluate a model's ability to generalize?\n",
        "\n",
        "\n",
        "## Medium\n",
        "### Score - 5 points for each correct and confident answer\n",
        "\n",
        "1. Explain the Bias and Variance Trade-off. What is the need to trade-off? What is the importance of each (bias and variance)?\n",
        "\n",
        "2. Is the Logistic Regression model a regression model? If yes, what is the core working principle behind it?\n",
        "\n",
        "3. What are the metrics generally used for a classification problem? Can you build a confusion matrix and how many metrics can one derive from it?\n",
        "\n",
        "\n",
        "## Hard\n",
        "### Score - 8 points for each correct and confident answer\n",
        "\n",
        "1. Describe briefly a project you worked on and please share the GitHub repo (code). What was your underlying motivation to start off with this project?\n",
        "\n",
        "2. Discuss various preprocessing methods used in ML such as data imputation, dimensionality reduction, data normalization, and feature selection. What are various techniques or ways to solve each of the problems? Is there a global solution to tackle all these problems at once? If no, what could be the reason?\n",
        "\n",
        "3. Pick a machine learning deterministic algorithm of your choice from the below list and provide an in-detail explanation of the underlying mathematical formulation and use the sklearn library (https://scikit-learn.org/stable/) to implement it on the data of your choice from the UCI repo (https://archive.ics.uci.edu/).\n",
        "\n",
        "Algorithm List: [Linear Regression, Logistic Regression, Decision Tree Regressor/Classifier, Support Vector Regressor/Classifier]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmQiD2VdFi8P"
      },
      "source": [
        "#**Answers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1J-eaUmgFqRO"
      },
      "source": [
        "##**Easy**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqGAL-6cF6UP"
      },
      "source": [
        "###**1. What is the difference between supervised, semi-supervised, weakly supervised, and unsupervised learning?** <br>\n",
        "\n",
        "   In machine learning, the choice between supervised, semi-supervised, weakly-supervised, and unsupervised paradigms is not just a technicality but a fundamental design decision that determines model reliability, data requirements, and applicabilityâ€”especially critical in healthcare, where data is often scarce, noisy, and costly to annotate.\n",
        "\n",
        "1. **Supervised Learning:** <br>\n",
        "   **Definition:**The model learns from a fully labeled dataset {X, y}, where each input X has a corresponding, ground-truth output y. The goal is to learn a mapping f: X -> y. <br>\n",
        "   **Examples**:\n",
        "   *  **Diabetic Retinopathy Detection**: An algorithm is trained on thousands of retinal images where each image has been labeled by ophthalmologists as containing the disease or not.\n",
        "\n",
        "   * **Pneumonia Detection in X-Rays:** A model learns from X-rays that radiologists have explicitly marked as showing signs of pneumonia.\n",
        "\n",
        "   **Importance**:High accuracy with reliable labels\n",
        "\n",
        "1. **Semi-Supervised Learning:** <br>\n",
        "   **Definition:**A pragmatic hybrid where the model learns from a small amount of labeled data combined with a large amount of unlabeled data. The core idea is that the structure of the unlabeled data can improve the learning process. <br>\n",
        "   **Examples**:\n",
        "   *  **Health Record Analysis:** Using a small set of patients with confirmed heart failure to leverage a much larger database of unlabeled patient records to predict who is at risk\n",
        "\n",
        "   * **Rare Disease Diagnosis:** A semi-supervised model uses a 100,000 of unlabeled medical images to learn general features, greatly enhancing its ability to accurately identify a rare cancer from only a 100 set of labeled examples.\n",
        "\n",
        "   **Importance**:Solves the Label Scarcity Problem\n",
        "3. **Weakly Supervised Learning:** <br>\n",
        "   **Definition:**The model learns from imprecise, incomplete, or noisy labels. The labels are easier/cheaper to get but are not the perfect \"ground truth\" we would ideally want <br>\n",
        "   **Types**:\n",
        "   *  **Inexact Supervision:**\n",
        "       * **Example:** Training a model to find tumors in a whole pathology slide using only a slide-level label (e.g., \"this entire slide is cancerous\"). The model must learn to localize the tumor itself without anyone telling it exactly which pixels are cancerous.\n",
        "\n",
        "   * **Noisy Supervision:**\n",
        "\n",
        "      *  **Example:** Using text from radiology reports (e.g., \"the lung shows opacities consistent with pneumonia\") as a noisy label for the associated chest X-ray. The text is a label, but it's not as precise as a radiologist drawing a box around the infection.\n",
        "\n",
        "   **Importance**:Most real-world hospital data is weakly labeled\n",
        "\n",
        "\n",
        "\n",
        "4. **Unsupervised Learning:** <br>\n",
        "    **Definition:** The model learns patterns from data that has no labels at all. Its goal is to find hidden structure, groupings, or patterns within the data itself. Common tasks are clustering , dimensionality reduction, and anomaly detection. <br>\n",
        "\n",
        "    **Examples**:\n",
        "   * **Cancer Subtyping:** Analyzing genetic data from thousands of breast cancer patients to discover new subtypes that are genetically distinct, which could lead to more personalized therapies.\n",
        "\n",
        "   * **Patient Stratification:** Clustering EHR data to identify groups of patients with similar comorbidities and outcomes, which can help hospitals manage population health\n",
        "\n",
        "   **Importance**:Enables hypothesis generation when ground-truth labels are missing.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdUSiT-TF4Sl"
      },
      "source": [
        "\n",
        "   **The chart illustrates the *spectrum of machine learning paradigms* based on their *label dependency* and highlights their relevance in healthcare applications**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMS3xyRC-UQO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "outputId": "9bbec3da-057e-4831-a43d-67131a821316"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "categories = [\"Supervised\", \"Semi-Supervised\", \"Weakly-Supervised\", \"Unsupervised\"]\n",
        "labels = [\n",
        "    \"All data labeled\\n(Pneumonia detection)\",\n",
        "    \"Few labeled + many unlabeled\\n(Skin lesion classification)\",\n",
        "    \"Noisy/Inexact labels\\n(ICD codes as labels)\",\n",
        "    \"No labels\\n(Cancer subtype discovery)\"\n",
        "]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,6))\n",
        "ax.bar(categories, [4,3,2,1], color=[\"#4CAF50\",\"#2196F3\",\"#FF9800\",\"#9C27B0\"])\n",
        "\n",
        "# Add text labels\n",
        "for i, label in enumerate(labels):\n",
        "    ax.text(i, 0.5, label, ha='center', va='bottom', fontsize=10, wrap=True)\n",
        "\n",
        "ax.set_title(\"Differences between ML Paradigms in Healthcare\", fontsize=14, fontweight='bold')\n",
        "ax.set_ylabel(\"Label Dependency (High â†’ Low)\")\n",
        "ax.set_xlabel(\"Learning Paradigm\")\n",
        "ax.set_ylim(0,5)\n",
        "#ax.get_yaxis().set_visible(False)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5Z1C4LhDW_d"
      },
      "source": [
        "### **Interpretation of the Visualization:**\n",
        "1. **Supervised Learning**: Requires fully labeled datasets. While effective (e.g., pneumonia detection from X-rays), it suffers from **annotation bottlenecks** since radiologist labeling is expensive and time-consuming.  \n",
        "2. **Semi-Supervised Learning**: Combines a small fraction of labeled data with large pools of unlabeled data. This is especially powerful in **dermatology** or **pathology**, where only a few expert-labeled images are available, but unlabeled data is abundant.  \n",
        "3. **Weakly-Supervised Learning**: Leverages noisy or inexact labels, such as **ICD codes** from electronic health records (EHRs). While this scales to millions of records, label noise can reduce accuracy unless advanced methods (e.g., noise-robust training) are applied.  \n",
        "4. **Unsupervised Learning**: Works entirely without labels and is key for **knowledge discovery**. For example, clustering genomic data can reveal novel cancer subtypes, enabling **personalized medicine**.\n",
        "\n",
        "### ðŸ”¬ Research Significance\n",
        "\n",
        "Healthcare data is often:\n",
        "- **Scarce in expert annotations**,  \n",
        "- **Rich in unlabeled modalities** (EHRs, genomic data, medical imaging), and  \n",
        "- **Prone to noisy labels** from large-scale hospital systems.  \n",
        "\n",
        "Thus, **semi-supervised and weakly-supervised paradigms** are highly impactful in healthcare, bridging the gap between **clinical reality (limited labels)** and **AI-driven decision support systems**.  \n",
        "\n",
        "This visualization emphasizes the **trade-off between label quality and scalability** and motivates why **next-generation healthcare AI systems** must go beyond purely supervised learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDZkrPP1v8BD"
      },
      "source": [
        "2. **Can you explain the concept of overfitting? How can you avoid it? Answer the question from a traditional ML perspective** <br>\n",
        "###**Overfitting:**\n",
        "Overfitting occurs when a model learns the training data too well, including its statistical noise, outliers, and random fluctuations, instead of the underlying true distribution. This results in a model with very high performance on the training data but poor performance on unseen test data (poor generalization). It is a sign of high variance, meaning the model's performance is highly sensitive to the specific training set it saw.\n",
        "\n",
        "  **Why it's a Critical Problem in Healthcare:** An overfit model is dangerously misleading. It might achieve 99% accuracy on hospital records from 2015-2020 but fail catastrophically on data from 2021 or from a different hospital. Deploying such a model could lead to misdiagnosis, incorrect treatment recommendations, and ultimately, patient harm. Ensuring robustness and generalization is a matter of clinical safety, not just technical performance.\n",
        "###**Avoiding Overfitting (Traditional ML Perspective):**\n",
        "\n",
        "    * **Simpler Models / Regularization:** Choosing a less complex model (e.g., linear model over a high-degree polynomial) intrinsically reduces overfitting. Regularization techniques (L1/Lasso, L2/Ridge) explicitly penalize model complexity by adding a term to the loss function that shrinks coefficient values towards zero. L1 can also perform feature selection.\n",
        "\n",
        "    * **Cross-Validation:** Using k-fold cross-validation provides a more robust estimate of a model's performance on unseen data than a single train-test split, helping to select models that generalize well.\n",
        "\n",
        "    * **Feature Selection/Engineering:** Reducing the number of irrelevant or redundant features (e.g., using Recursive Feature Elimination or domain knowledge) decreases the model's capacity to memorize noise.\n",
        "\n",
        "    * **More Data:** Increasing the size and diversity of the training data is one of the most effective ways to help the model learn the true data distribution rather than spurious correlations. In healthcare, this often involves multi-center studies to capture population diversity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oK72ZipXIdq1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "outputId": "29c72b57-65df-4083-85e6-cc2ebead02c8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ==============================================================\n",
        "# Overfitting Visualization (Training vs Test Error)\n",
        "# ==============================================================\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Simulate model complexity\n",
        "x = np.linspace(1, 10, 100)\n",
        "train_error = np.exp(-0.3 * x) + 0.05  # decreasing with complexity\n",
        "test_error = np.exp(-0.15 * (x - 4) ** 2) + 0.1  # U-shaped curve\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(x, train_error, label=\"Training Error\", color=\"blue\", linewidth=2)\n",
        "plt.plot(x, test_error, label=\"Test Error\", color=\"red\", linewidth=2)\n",
        "\n",
        "# Highlight overfitting zone\n",
        "plt.axvspan(6, 10, color=\"orange\", alpha=0.2, label=\"Overfitting Region\")\n",
        "\n",
        "plt.title(\"Overfitting in Machine Learning Models\", fontsize=16, fontweight=\"bold\")\n",
        "plt.xlabel(\"Model Complexity\", fontsize=12)\n",
        "plt.ylabel(\"Error\", fontsize=12)\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmxetw7bKqN1"
      },
      "source": [
        "### ðŸ”¬ Interpretation\n",
        "\n",
        "The plot shows the relationship between **training error** and **test error** as model complexity increases:\n",
        "\n",
        "- **Left (Low complexity â€“ underfitting):**  \n",
        "  The model is too simple, e.g., a linear regression predicting complex patient outcomes.  \n",
        "  Both training and test errors are high.\n",
        "\n",
        "- **Middle (Optimal complexity):**  \n",
        "  Both errors are minimized. The model generalizes well to unseen patient data.  \n",
        "\n",
        "- **Right (High complexity â€“ overfitting):**  \n",
        "  Training error is very low (memorization), but test error increases.  \n",
        "  In healthcare, this could mean a cancer detection model is **memorizing dataset-specific noise**, failing on new patient scans.\n",
        "\n",
        "ðŸ“Œ **Key Research Insight:**  \n",
        "Overfitting is especially risky in healthcare where datasets are often small and imbalanced.  \n",
        "Thus, rigorous **cross-validation**, **external validation across hospitals**, and **regularization** are essential to build clinically trustworthy models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InVh58cd2HRK"
      },
      "source": [
        "3. **What is generalization? How do you evaluate a model's ability to generalize?** <br>\n",
        "#**Generalization:**\n",
        " **Generalization** is the ability of a model to perform well on **unseen data** â€” data not used during training,after being trained on a limited training dataset.  A model that generalizes well has captured the **underlying patterns** in the data rather than memorizing noise.  \n",
        "\n",
        " -->The central challenge in ML is balancing l**earning the important patterns without memorizing the irrelevant noise**\n",
        "\n",
        " **How to Evaluate a Model's Ability to Generalize?** <br>\n",
        " we can evaluate generalization by rigorously testing the model's performance on data it was never allowed to see during training.\n",
        "\n",
        " Here is the standard process and the key techniques used:\n",
        "\n",
        " 1.**The Train-Test Split**:<br>\n",
        "The simplest method is to split your entire dataset into two parts before training:\n",
        "\n",
        "   * **Training Set:** The larger portion (e.g., 70-80%) used to train the model.\n",
        "\n",
        "   * **Test Set:** The remaining portion (e.g., 20-30%) that is locked away and never used during training. It is only used once, at the very end, to evaluate the final model's performance.\n",
        "\n",
        "  **How it evaluates generalization:** <br> The performance gap between the training set and the test set tells you a lot.\n",
        "\n",
        "    * **High Training Accuracy, Low Test Accuracy = Overfitting.**\n",
        "\n",
        "    * Similar Training and Test Accuracy = Good Generalization.\n",
        "\n",
        "    * Low Training and Low Test Accuracy = Underfitting.\n",
        "\n",
        "  **2.Cross-Validation:** <br>\n",
        "A more robust and sophisticated technique than a simple train-test split, especially for smaller datasets.\n",
        "\n",
        " * k-Fold Cross-Validation is the most common method:\n",
        "\n",
        "    * The data is randomly shuffled and split into k equal-sized groups (called \"folds\").\n",
        "\n",
        "    * The model is trained k times. Each time, a different fold is used as the test set, and the remaining k-1 folds are combined to form the training set.\n",
        "\n",
        "    * This results in k different performance scores.The final reported score is the average of these k scores.\n",
        "\n",
        "  **How it evaluates generalization:**\n",
        "\n",
        "  * It uses every data point in the dataset for both training and testing, just in different rounds, providing a more reliable estimate of performance.\n",
        "\n",
        "  * The standard deviation of the k scores indicates the model's consistency. A **low standard deviation means the model generalizes well** across different subsets of the data. A **high standard deviation means its performance is volatile** and depends heavily on which data points are in the training set.\n",
        "\n",
        " 3.**Use a Validation Set:** <br>\n",
        "In real-world workflows, you need a way to tune your model's hyperparameters (e.g., learning rate, network depth) without leaking information into the test set. This is done with a validation set.\n",
        "\n",
        " The typical split becomes:\n",
        "\n",
        " * **Training Set:** Used to train the model.\n",
        "\n",
        "  * **Validation Set:** Used to evaluate the model during training to tune hyperparameters and select the best model version. This is the \"simulated test set\" for your development cycle.\n",
        "\n",
        "  * **Test Set:** Used exactly once at the very end to provide an unbiased final evaluation of the model that was selected based on the validation set performance.\n",
        "\n",
        "  **How it evaluates generalization:** <br> The performance on the validation set guides your tuning decisions to avoid overfitting. The final test on the completely untouched test set is the ultimate test of generalization.\n",
        "\n",
        "  **Key Metrics for Evaluation** <br>\n",
        " The choice of metric is crucial and depends on the problem:\n",
        "\n",
        "    * **For Classification:** Accuracy, Precision, Recall, F1-Score, ROC-AUC.\n",
        "\n",
        "   * **For Regression:** Mean Absolute Error (MAE), Mean Squared Error (MSE), R-squared.\n",
        "\n",
        "   * **The Crucial Comparison:** Always compare the metric on the training set vs. on the test/validation set.\n",
        "\n",
        " **Summary:** How to Know if Model Generalizes Well <br>\n",
        "  The model generalizes well if:\n",
        "\n",
        "  * Performance on the test set is high (and close to the performance on the training set).\n",
        "\n",
        "  * The performance is consistent across different splits of the data (e.g., low standard deviation in k-fold cross-validation).\n",
        "\n",
        " * It performs well on real-world, out-of-sample data that it encounters after deployment.\n",
        "\n",
        "**Key Insight:** In healthcare, generalization means **robustness and trustworthiness** â€” a non-negotiable requirement for deployment in real-world clinical workflows.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIzHQPr8-BEL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "outputId": "4fb132bf-2deb-46f2-8842-e3a6ea0b4871"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ==============================================================\n",
        "# Generalization Visualization: Training vs Validation Accuracy\n",
        "# ==============================================================\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Simulated model complexities\n",
        "complexity = np.arange(1, 11)\n",
        "\n",
        "# Simulated training/validation accuracy\n",
        "train_acc = [0.55, 0.65, 0.75, 0.85, 0.92, 0.96, 0.98, 0.995, 0.998, 1.0]\n",
        "val_acc   = [0.50, 0.63, 0.74, 0.83, 0.88, 0.87, 0.84, 0.80, 0.75, 0.70]\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(complexity, train_acc, label=\"Training Accuracy\", marker=\"o\", linewidth=2, color=\"blue\")\n",
        "plt.plot(complexity, val_acc, label=\"Validation Accuracy\", marker=\"o\", linewidth=2, color=\"red\")\n",
        "\n",
        "plt.axvline(x=5, linestyle=\"--\", color=\"green\", label=\"Optimal Generalization Point\")\n",
        "\n",
        "plt.title(\"Generalization: Training vs Validation Accuracy\", fontsize=16, fontweight=\"bold\")\n",
        "plt.xlabel(\"Model Complexity\", fontsize=12)\n",
        "plt.ylabel(\"Accuracy\", fontsize=12)\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVl_MrO4elXh"
      },
      "source": [
        "### ðŸ”¬ Interpretation\n",
        "\n",
        "The visualization highlights **training vs validation accuracy** across model complexities:\n",
        "\n",
        "- **Low Complexity (1â€“3): Underfitting**  \n",
        "  Both training and validation accuracy are low â†’ model too simple, fails to capture patterns.  \n",
        "\n",
        "- **Moderate Complexity (4â€“6): Good Generalization**  \n",
        "  Training accuracy is high, validation accuracy is also high and stable â†’ model generalizes well.  \n",
        "  âœ… Point 5 is the sweet spot.  \n",
        "\n",
        "- **High Complexity (7â€“10): Overfitting**  \n",
        "  Training accuracy approaches 100%, but validation accuracy declines â†’ model memorizes training data.  \n",
        "  ðŸš« In healthcare, this could mean a diagnostic model works on one dataset but fails on real-world patient scans.  \n",
        "\n",
        "---\n",
        "\n",
        "ðŸ“Œ **Research Takeaway:**  \n",
        "Generalization is not just about accuracy â€” it is about **robustness across populations**.  \n",
        "For healthcare deployment, models should undergo:  \n",
        "- **Cross-hospital validation**  \n",
        "- **External datasets testing**  \n",
        "- **Fairness analysis across demographics**  \n",
        "\n",
        "Only then can they be trusted for real-world use in critical applications like **cancer diagnosis, drug discovery, or personalized medicine**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Medium**"
      ],
      "metadata": {
        "id": "xuXVDQCIxO8V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**1. Explain the Bias and Variance Trade-off. What is the need to trade-off? What is the importance of each (bias and variance)?**\n",
        "\n",
        "The **Bias-Variance Trade-off** is a fundamental concept in supervised machine learning that describes the relationship between a model's complexity, its error from incorrect assumptions (bias), and its error from sensitivity to small fluctuations in the training set (variance).\n",
        "\n",
        "**Bias:** Bias is the error introduced by a model that is too simple to capture the underlying patterns in the data. A model with high bias makes strong, incorrect assumptions about the data, leading to underfitting. For example, trying to fit a complex, non-linear relationship with a straight line would result in high bias. <br>\n",
        "   * **Importance:** While high bias is bad, a certain level of bias is necessary to create a model that can generalize. A model with no bias would have to be impossibly complex to represent reality perfectly.\n",
        "\n",
        "**Variance:** Variance is the error due to a model's sensitivity to small fluctuations in the training data. A model with high variance is too complex and learns the noise in the training set, leading to overfitting. For example, a very complex decision tree might learn every specific data point, making it unable to generalize to new data.\n",
        " * **Importance:** Variance represents the model's flexibility. A model with zero variance would be completely rigid and unable to learn any patterns from the data at all.\n",
        "\n",
        "The **trade-off** is the balance between these two sources of error. A simple model has high bias and low variance, while a complex model has low bias but high variance. The goal is to find a model that is just complex enough to capture the true patterns in the data without learning the noise. This minimizes the total error and maximizes the model's ability to generalize to new data.\n",
        "\n",
        "**The Need for a Trade-off:** <br>\n",
        "The need for this trade-off arises from the fundamental goal of machine learning: to build a model that performs well on unseen data (generalizes), not just the data it was trained on.\n",
        "\n",
        "* As model complexity increases, variance increases (the model fits the training data more closely) and bias decreases.\n",
        "\n",
        "* As model complexity decreases, bias increases (the model makes stronger assumptions) and variance decreases. <br>\n",
        "\n",
        "->**Low Bias + Low Variance** â†’ Ideal but rarely achievable.  \n",
        "->**High Bias + Low Variance** â†’ Model underfits (systematic errors).  \n",
        "->**Low Bias + High Variance** â†’ Model overfits (memorizes training data).  \n",
        "\n",
        "Hence, we need to **balance** bias and variance to minimize **Total Error** (generalization error).  \n",
        "\n",
        "### ðŸ¥ Healthcare Importance\n",
        "\n",
        "Bias-Variance balance is **critical in healthcare**:\n",
        "- **High Bias Example:** A simple model that underestimates rare diseases â†’ misses critical diagnoses (false negatives).  \n",
        "- **High Variance Example:** A complex model trained on one hospitalâ€™s data may misdiagnose patients from another demographic.  \n",
        "- **Balanced Trade-off:** Ensures models detect diseases accurately **across populations** without being misled by noise.  \n",
        "\n",
        "ðŸ“Œ In clinical AI, the trade-off directly affects **patient safety, trust, and regulatory approval**."
      ],
      "metadata": {
        "id": "cgQ4lx9xxR_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================\n",
        "# Bias-Variance Trade-off Visualization\n",
        "# ==============================================================\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Complexity values\n",
        "complexity = np.linspace(1, 10, 100)\n",
        "\n",
        "# Simulated curves\n",
        "bias = 1 / complexity        # Bias decreases with complexity\n",
        "variance = complexity / 10   # Variance increases with complexity\n",
        "total_error = bias + variance\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(complexity, bias, label=\"Bias^2 (Underfitting)\", linewidth=2, color=\"blue\")\n",
        "plt.plot(complexity, variance, label=\"Variance (Overfitting)\", linewidth=2, color=\"red\")\n",
        "plt.plot(complexity, total_error, label=\"Total Error\", linewidth=2, color=\"green\")\n",
        "\n",
        "# Mark optimal point\n",
        "optimal_idx = np.argmin(total_error)\n",
        "plt.axvline(x=complexity[optimal_idx], linestyle=\"--\", color=\"black\", label=\"Optimal Trade-off\")\n",
        "\n",
        "plt.title(\"Bias-Variance Trade-off\", fontsize=16, fontweight=\"bold\")\n",
        "plt.xlabel(\"Model Complexity\", fontsize=12)\n",
        "plt.ylabel(\"Error\", fontsize=12)\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "g5JKz21sxTsB",
        "outputId": "5e77d5d4-9e8a-4dc9-feff-1a4a572d329b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ”¬ Interpretation\n",
        "\n",
        "The figure illustrates the **bias-variance trade-off**:\n",
        "\n",
        "- **Left Side (Low Complexity): High Bias, Low Variance**  \n",
        "  The model underfits â†’ it cannot capture patient-specific variations (e.g., predicting everyone as \"healthy\").  \n",
        "\n",
        "- **Right Side (High Complexity): Low Bias, High Variance**  \n",
        "  The model overfits â†’ memorizes training data (hospital A patients) but fails on unseen populations (hospital B patients).  \n",
        "\n",
        "- **Middle Point: Optimal Trade-off**  \n",
        "  Both bias and variance are balanced â†’ minimal total error, best generalization.  \n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ“Š Research Perspective\n",
        "\n",
        "- **Bias is important**: Some bias is necessary to simplify real-world problems (e.g., approximating complex biological systems).  \n",
        "- **Variance is important**: Variability helps capture subtle patterns (e.g., rare genetic markers), but must be controlled.  \n",
        "- **The trade-off ensures robustness**: Especially in healthcare, where models should work reliably **across demographics, hospitals, and devices**.  \n",
        "\n",
        "ðŸ“Œ **Key Takeaway:**  \n",
        "A well-balanced model in healthcare not only achieves high accuracy but also ensures **fairness, safety, and reproducibility**, which are prerequisites for clinical deployment.\n"
      ],
      "metadata": {
        "id": "JWXGibGzxcHE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Is the Logistic Regression model a regression model? If yes, what is the core working principle behind it?** <br>\n",
        "###**Logistic Regression**:\n",
        "  **The Logistic Regression model is not a regression model; it is a classification model**. Despite its name, it is used to predict a discrete outcome, such as \"yes\" or \"no,\" \"pass\" or \"fail,\" or \"spam\" or \"not spam.\"\n",
        "\n",
        "  The **core working principle** behind it is the **sigmoid function (also known as the logistic function)**. The model takes a linear combination of input features and passes it through this function. The sigmoid function maps any real-valued number to a value between 0 and 1, which can be interpreted as a probability.\n",
        "\n",
        "  For example, a probability of 0.8 might mean there is an 80% chance of the outcome being \"yes.\" A threshold (e.g., 0.5) is then used to convert this probability into a final binary classification.\n",
        "\n",
        "  **Core Working Principle:** <br>  A Two-Stage Process\n",
        "The working principle can be elegantly broken down into two connected stages:\n",
        "\n",
        "  **Stage 1:** The Linear Regression Component\n",
        "The model first calculates a linear combination of the input features, exactly as a standard linear regression model would:<br>\n",
        "  **$ z = Î²â‚€ + Î²â‚xâ‚ + Î²â‚‚xâ‚‚ + ... + Î²â‚™xâ‚™ $**\n",
        "Where:\n",
        "\n",
        "    z is the linear score (also called the logit).\n",
        "\n",
        "  Î²â‚€ is the bias term (intercept).\n",
        "\n",
        "  Î²â‚, Î²â‚‚, ..., Î²â‚™ are the weights (coefficients) for the features xâ‚, xâ‚‚, ..., xâ‚™.\n",
        "\n",
        " This value z can range from -âˆž to +âˆž.\n",
        "\n",
        "  **Stage 2:** The Logistic (Sigmoid) Transformation\n",
        "The linear score z is then passed as input into the sigmoid function.\n",
        "$$ Ïƒ(z) =\\frac{ 1} { (1 + e^{-z})} $$\n",
        "\n",
        "  The magic of this function is that it maps any real number z to a smooth, S-shaped curve bounded between 0 and 1. This output is interpreted as the probability that the given input instance belongs to the default class (e.g., Class 1).\n",
        "$$P(Y=1 | X) =  Ïƒ(z) =\\frac{ 1} { (1 + e^{-z})} $$\n",
        "\n",
        "  **Why itâ€™s important in research/healthcare context**\n",
        "\n",
        "  Logistic Regression is interpretable â†’ coefficients tell how much each factor contributes to the outcome.\n",
        "\n",
        " It is efficient and works well for linearly separable data.\n",
        "\n",
        " In healthcare, logistic regression is often used for risk prediction (e.g., probability of disease given age, BMI, blood sugar).\n",
        "\n",
        " **Why is this so powerful?**\n",
        "\n",
        " Probabilistic Interpretation: Unlike other classifiers that just output a label, Logistic Regression provides a well-calibrated probability (e.g., \"This email has an 82% chance of being spam\"). This is invaluable for risk assessment and decision-making.\n",
        "\n",
        " Linear Decision Boundary: The transformation maintains a linear decision boundary. The model will predict Class 1 if P(Y=1 | X) >= 0.5. This happens when z >= 0. Since z is linear, the boundary where z = 0 is a line (or a hyperplane in higher dimensions).\n",
        "\n",
        " **Summary** <br>\n",
        "  To conclude, while Logistic Regression is overwhelmingly used for classification tasks, its name is apt because its internal mechanism is based on estimating the continuous log-odds of a probability through a regression framework. The sigmoid function is the crucial link that transforms this regression output into a probability, enabling its use for powerful and interpretable classification."
      ],
      "metadata": {
        "id": "o1vPLjcj4by8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.**What are the metrics generally used for a classification problem? Can you build a confusion matrix and how many metrics can one derive from it?**<br>\n",
        "\n",
        " **Common Classification Metrics:**\n",
        "\n",
        "  * Accuracy\n",
        "\n",
        "* Precision\n",
        "\n",
        "* Recall (Sensitivity)\n",
        "\n",
        "* F1-Score\n",
        "\n",
        "* Specificity\n",
        "\n",
        "* AUC-ROC (Area Under the ROC Curve)\n",
        "\n",
        "1. **Accuracy**: <br>\n",
        "Definition: Accuracy measures the overall fraction of correct predictions (both positive and negative) made by the model out of all predictions. It answers the question: \"How often is the classifier correct?\"\n",
        "\n",
        " $ Accuracy = \\frac{(TP + TN)} { (TP + TN + FP + FN)} $\n",
        "\n",
        " **When to Use:** It is a good measure only when the classes are perfectly balanced (i.e., the number of positive and negative examples in the data is roughly equal). It can be very misleading for imbalanced datasets.\n",
        "\n",
        " **Example:** If 95% of your emails are \"Not Spam\" and 5% are \"Spam\", a model that simply predicts \"Not Spam\" for every email would have a 95% accuracy, even though it is useless at actually catching spam.\n",
        "\n",
        "2. **Precision** <br>\n",
        " Precision measures the quality of a positive prediction. It answers the question: \"When the model predicts 'positive', how often is it correct?\" It is concerned with minimizing False Positives (FP).<br>\n",
        "  $ Precision = \\frac{TP} {(TP + FP)} $\n",
        "\n",
        " **When to Use:** Precision is crucial in scenarios where the cost of a False Positive is high.\n",
        "\n",
        " **Example - Spam Detection:** If an important work email is incorrectly flagged as spam (a False Positive), the consequence is high (you might miss critical information). Therefore, you want your spam classifier to have high precision, ensuring that when it does predict \"spam\", it's very likely to be correct.\n",
        "\n",
        "3. **Recall (Sensitivity or True Positive Rate - TPR)** <br>\n",
        " Recall measures the completeness of positive predictions. It answers the question: \"What proportion of all actual positive instances did the model correctly identify?\" It is concerned with minimizing False Negatives (FN).\n",
        "\n",
        "   $ Recall = \\frac{TP}  {(TP + FN)} $\n",
        "\n",
        " **When to Use:** Recall is crucial in scenarios where the cost of a False Negative is high.\n",
        "\n",
        " **Example - Disease Screening:** If a patient has a disease but the model fails to detect it (a False Negative), the consequence is catastrophic (the disease goes untreated). Therefore, a cancer screening test must have high recallâ€”it's more important to catch all possible cases, even if it means some healthy patients are initially flagged for further testing (False Positives).\n",
        "\n",
        "4. **F1-Score**\n",
        "The F1-Score is the harmonic mean of Precision and Recall. It provides a single metric that balances the two, especially useful when you need to find a compromise between minimizing both False Positives and False Negatives.\n",
        "\n",
        " $ F1-Score = \\frac{2 * (Precision * Recall)} { (Precision + Recall) } $\n",
        "\n",
        " **Why Harmonic Mean?** The harmonic mean is used instead of a simple average because it punishes extreme values. A simple average of 1.0 (perfect) and 0.0 (terrible) is 0.5, which is misleading. The harmonic mean of the same values is 0. This makes the F1-score a more conservative and reliable measure of a model's performance when dealing with class imbalance.\n",
        "\n",
        " **When to Use:** It is the best metric to use if you need a single number to evaluate a classifier and if there is an uneven class distribution (imbalance between FN and FP).\n",
        "\n",
        "5. **Specificity (True Negative Rate - TNR)**\n",
        "Specificity is the counterpart to Recall. It measures the proportion of actual negative instances that are correctly identified. It answers the question: \"What proportion of actual negatives did the model correctly identify?\"\n",
        "\n",
        " $ Specificity = \\frac{TN} {(TN + FP)} $\n",
        "\n",
        " **When to Use:** It is important in contexts where correctly identifying negatives is critical.\n",
        "\n",
        " **Example - Quality Control:** In a factory, correctly identifying non-defective products (True Negatives) is essential for efficiency. A high specificity means you are not wasting resources \"fixing\" products that are already fine.\n",
        "\n",
        "6. **AUC-ROC (Area Under the Receiver Operating Characteristic Curve)**\n",
        "The AUC-ROC curve measures the model's ability to distinguish between classes across all possible classification thresholds. It plots the True Positive Rate (Recall) against the False Positive Rate (1 - Specificity) at various threshold settings.\n",
        "\n",
        " $ False Positive Rate (FPR): \\frac{FPR = FP} { (FP + TN)}  $\n",
        "\n",
        " **Interpretation:**\n",
        "\n",
        " AUC = 1.0: Perfect classifier. It can perfectly separate all positive and negative points.\n",
        "\n",
        " AUC = 0.5: The model is no better than random guessing (the diagonal line).\n",
        "\n",
        " AUC between 0.5 and 1.0: The higher the value, the better the model is at distinguishing between the positive and negative classes.\n",
        "\n",
        " **Key Advantage:** It is threshold-invariant. It evaluates the quality of the model's predicted probabilities themselves, regardless of what threshold you choose to make a decision. This makes it excellent for comparing different models.\n",
        "\n",
        " **When to Use:** Use AUC-ROC when you care about the ranking of your predictions and the overall performance across all thresholds. It is excellent for model comparison.\n",
        "\n",
        " **The Confusion Matrix:**\n",
        "\n",
        "  A confusion matrix is a table used to describe the performance of a classification model. It allows for clear visualization of the model's correct predictions (the diagonal) and its errors (the off-diagonals).\n",
        "\n",
        "  Building a Confusion Matrix (for a binary problem):\n",
        "\n",
        "  Let's assume we have two classes: Positive (1) and Negative (0).\n",
        "\n",
        "                             Predicted Negative (0)\tPredicted Positive (1)\n",
        "        Actual Negative(0)     TN (True Negative)        FP (False Positive)\n",
        "        Actual Positive (1)\tFN (False Negative)\t   TP (True Positive)\n",
        "  <br>\n",
        "\n",
        "  **TN:**  The model correctly predicted the negative class.\n",
        "\n",
        "  **FP (Type I Error):** The model incorrectly predicted the positive class (it was actually negative).\n",
        "\n",
        "  **FN (Type II Error):** The model incorrectly predicted the negative class (it was actually positive).\n",
        "\n",
        "  **TP:** The model correctly predicted the positive class.\n",
        "\n",
        "  **Number of Derivable Metrics:**<br>\n",
        "  From the four core components of the confusion matrix (TP, TN, FP, FN), one can derive a very large number of metrics. The exact number isn't fixed, as more complex, domain-specific metrics can be created. However, the most critical and widely used performance metrics are all derived from these four values:\n",
        "\n",
        "  Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "\n",
        "  Precision = TP / (TP + FP)\n",
        "\n",
        "  Recall (Sensitivity) = TP / (TP + FN)\n",
        "\n",
        "  Specificity = TN / (TN + FP)\n",
        "\n",
        "  F1-Score = 2 * (Precision * Recall) / (Precision + Recall)\n",
        "\n",
        "  False Positive Rate (FPR) = FP / (FP + TN) = 1 - Specificity\n",
        "\n",
        "  False Negative Rate (FNR) = FN / (TP + FN) = 1 - Recall\n",
        "\n",
        "  Prevalence = (TP + FN) / (TP + TN + FP + FN)\n",
        "\n",
        "  Therefore, one can confidently state that dozens of metrics can be derived from the four fundamental values in a confusion matrix, making it the single most important tool for evaluating classification models."
      ],
      "metadata": {
        "id": "Bj4ZaGDBQi9q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Hard**"
      ],
      "metadata": {
        "id": "JA_p5U3tlnkB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.**Describe briefly a project you worked on and please share the GitHub repo (code). What was your underlying motivation to start off with this project?**\n",
        "\n",
        "As an AI engineering intern, one of the projects I've been working on is a **Customer Churn Prediction model**. **My underlying motivation for this project was to tackle a critical business problem: customer retention. Losing subscribers, or \"churn,\" is a major challenge for any business, as acquiring new customers is often far more expensive than retaining existing ones**. I wanted to build a model that could proactively identify customers at risk of leaving, allowing the business to take targeted actions to prevent churn.\n",
        "\n",
        "**Project Overview** <br>\n",
        "This project involved building a machine learning model to predict whether a customer would churn from a movie watching platform. The dataset I used included customer demographics, viewing history, subscription plan details, and genre preferences. The task was to classify customers as either \"Churn\" or \"No Churn\" based on this data.\n",
        "\n",
        "**My methodology included:**\n",
        "\n",
        "* **Data Preprocessing:** I handled missing data through imputation, converted categorical features into numerical ones, and scaled numerical features to ensure they were all on a similar scale.\n",
        "\n",
        "* **Feature Engineering:** I created new features from the existing data, such as a customer's average watch time per week and their engagement with new releases.\n",
        "\n",
        "* **Model Selection:** I experimented with several classification models, including Logistic Regression, Random Forest.\n",
        "\n",
        "* **Model Evaluation:** I evaluated the model's performance using metrics like Precision, Recall, and F1-Score, which are critical for an imbalanced dataset like this (where most customers do not churn). I focused on Recall to ensure the model was correctly identifying as many at-risk customers as possible.\n",
        "\n",
        "**GitHub Repository** <br>\n",
        "The code for this project is available on my GitHub repository. It contains the data preprocessing scripts, the model training and evaluation notebooks, and a brief report on the findings.\n",
        "\n",
        "**Link to Repository:** https://github.com/B-pallavi123/ML-AI-DS/blob/main/Major_project.ipynb\n",
        "\n",
        "My passion for this project came from seeing how machine learning could provide a tangible business benefit. The ability to move from reactive customer service to a proactive, data-driven retention strategy is a powerful application of AI, and it's what drives my interest in this field."
      ],
      "metadata": {
        "id": "gtgTdAGblpYU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Discuss various preprocessing methods used in ML such as data imputation, dimensionality reduction, data normalization, and feature selection. What are various techniques or ways to solve each of the problems? Is there a global solution to tackle all these problems at once? If no, what could be the reason?**\n",
        "  \n",
        "  Preprocessing is a crucial step in machine learning to prepare raw data for modeling. The goal is to clean and transform the data into a format that a model can understand and learn from effectively. Here's a discussion of various methods and techniques.\n",
        "\n",
        "  **Data Imputation ðŸ“Š** <br>\n",
        "  This method is used to handle missing values in a dataset. Missing data can cause errors or bias a model, so it's important to fill in these gaps.\n",
        "\n",
        "  Techniques:\n",
        "\n",
        "  * **Mean/Median/Mode Imputation:** A simple method where missing numerical values are replaced with the mean or median of the column, and categorical values are replaced with the mode.\n",
        "\n",
        "  * **K-Nearest Neighbors (k-NN) Imputation:** This technique replaces missing values with the values of the k-nearest data points, which can be more accurate than simple mean imputation.\n",
        "\n",
        "  * **MICE (Multivariate Imputation by Chained Equations):** A more advanced method that treats each feature with missing values as a target variable and uses other features to predict the missing values.\n",
        "\n",
        "  **Dimensionality Reduction ðŸ“‰** <br>\n",
        "  This method is used to reduce the number of features (columns) in a dataset. High-dimensional data can lead to a phenomenon called the \"curse of dimensionality,\" which makes models overfit and slows down training.\n",
        "\n",
        "  Techniques:\n",
        "\n",
        "  * **Principal Component Analysis (PCA)**: An unsupervised technique that transforms a set of correlated features into a smaller set of uncorrelated principal components, which capture most of the variance in the original data.\n",
        "\n",
        "  * **t-SNE (t-Distributed Stochastic Neighbor Embedding):** A non-linear technique for visualizing high-dimensional data by reducing it to two or three dimensions.\n",
        "\n",
        "  * **Linear Discriminant Analysis (LDA):** A supervised technique that finds a linear combination of features that best separates different classes.\n",
        "\n",
        "  **Data Normalization** âš–ï¸ <br>\n",
        "  This is a method for rescaling numerical features to a standard range. This is important for algorithms that are sensitive to the magnitude of feature values (e.g., k-NN, SVMs) because features with larger values can disproportionately influence the model.\n",
        "\n",
        "  Techniques:\n",
        "\n",
        "  * Min-Max Scaling: This technique rescales features to a fixed range, typically [0, 1], by subtracting the minimum value and dividing by the range.\n",
        "\n",
        "  * Z-score Standardization: This technique rescales features to have a mean of 0 and a standard deviation of 1. This is useful for algorithms that assume a Gaussian distribution.\n",
        "\n",
        "  * Feature Selection ðŸ”\n",
        "  This is the process of selecting a subset of relevant features to use in your model. The goal is to improve model performance, reduce training time, and make the model easier to interpret.\n",
        "\n",
        "  Techniques:\n",
        "\n",
        "  * **Filter Methods:** These methods use statistical measures (e.g., correlation, chi-squared test) to score and rank features, independent of the model.\n",
        "\n",
        "  * **Wrapper Methods:** These methods use a machine learning model to evaluate the performance of a subset of features. A common technique is Recursive Feature Elimination (RFE), which trains a model, removes the least important feature, and repeats the process.\n",
        "\n",
        "   * **Embedded Methods:** These methods perform feature selection as part of the model training process. Lasso (L1 regularization) is a prime example, where it shrinks the coefficients of less important features to zero, effectively removing them from the model.\n",
        "\n",
        "  **Is There a Global Solution?** <br>\n",
        "  No, there is no single global solution to tackle all these problems at once. The reason is that the optimal preprocessing strategy is highly context-dependent. The best approach for a given dataset depends on:\n",
        "\n",
        "  * **The data itself:** A dataset with normally distributed features might benefit from standardization, while a dataset with many outliers might not.\n",
        "\n",
        "  * **The model being used:** A linear model might be sensitive to normalization, while a tree-based model might be more robust.\n",
        "\n",
        "  * **The specific problem:** For a classification problem, LDA might be a good choice for dimensionality reduction, but for a regression problem, PCA would be more suitable.\n",
        "\n",
        "  Each of these preprocessing methods solves a distinct problem, and the choice of which technique to use is an art that requires a deep understanding of both the data and the models you're working with."
      ],
      "metadata": {
        "id": "V34FmL2_n1_F"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AZYy_1-d0lHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Pick a machine learning deterministic algorithm of your choice from the below list and provide an in-detail explanation of the underlying mathematical formulation and use the sklearn library (https://scikit-learn.org/stable/) to implement it on the data of your choice from the UCI repo (https://archive.ics.uci.edu/).**\n",
        "\n",
        "Algorithm List: [Linear Regression, Logistic Regression, Decision Tree Regressor/Classifier, Support Vector Regressor/Classifier]"
      ],
      "metadata": {
        "id": "gccxJ98op8-Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression:**<br> Mathematical Formulation\n",
        "Logistic Regression is a powerful algorithm for binary classification, despite its name. The core idea is to use a linear equation to predict a value, but instead of using this value directly, it's passed through a special function that maps the output to a probability between 0 and 1. This function is called the sigmoid function.\n",
        "\n",
        "The process can be broken down into two main parts:\n",
        "\n",
        "* **Linear Combination:**The model first calculates a linear combination of the input features, which is the same as in linear regression. For a given input vector X with features x\n",
        "1\n",
        "â€‹\n",
        " ,x\n",
        "2\n",
        "â€‹\n",
        " ,...,x\n",
        "n\n",
        "â€‹\n",
        " , the linear equation is:\n",
        "\n",
        " $ z=Î²\n",
        "0\n",
        "â€‹\n",
        " +Î²\n",
        "1\n",
        "â€‹\n",
        " x\n",
        "1\n",
        "â€‹\n",
        " +Î²\n",
        "2\n",
        "â€‹\n",
        " x\n",
        "2\n",
        "â€‹\n",
        " +...+Î² $\n",
        "\n",
        "â€‹\n",
        "\n",
        "\n",
        "   Here, Î²\n",
        "0\n",
        "â€‹\n",
        "  is the bias (or intercept), and Î²\n",
        "1\n",
        "â€‹\n",
        "  to Î²\n",
        "n\n",
        "â€‹\n",
        "  are the coefficients (or weights) for each feature.\n",
        "\n",
        "* **Sigmoid Function:** The value z can range from negative infinity to positive infinity. To convert this into a probability, the sigmoid function, denoted as Ïƒ(z), is used. The sigmoid function maps any real-valued number into a value between 0 and 1.\n",
        "\n",
        "  $ P(y=1âˆ£X)=Ïƒ(z)= \\frac{1}{1+e âˆ’z} $\n",
        "\n",
        "\n",
        "â€‹\n",
        "\n",
        "\n",
        "This equation gives us the probability that the output y belongs to the positive class (e.g., heart disease). A threshold (e.g., 0.5) is then applied to classify the output. If the probability is above the threshold, the output is classified as positive; otherwise, it's negative."
      ],
      "metadata": {
        "id": "WA9C9sMWzSkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()  # Upload the downloaded `kaggle.json`"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "By_7xqEHqPoY",
        "outputId": "e40441a0-702b-4712-f753-0d0d0be1ac10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ab827057-bfa4-4b7a-bd56-8989e61c0bcd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ab827057-bfa4-4b7a-bd56-8989e61c0bcd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle (1).json': b'{\"username\":\"pallavibandikari\",\"key\":\"13abfdf792138a7adb0c04c73884ea23\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle  # Install Kaggle API\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json  # Set permissions"
      ],
      "metadata": {
        "id": "EK1SSXi5sUGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d redwankarimsony/heart-disease-data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LS3SQpomsb-U",
        "outputId": "e0099515-f6a0-4fca-e8c8-2ac80dbc8919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/redwankarimsony/heart-disease-data\n",
            "License(s): copyright-authors\n",
            "Downloading heart-disease-data.zip to /content\n",
            "  0% 0.00/12.4k [00:00<?, ?B/s]\n",
            "100% 12.4k/12.4k [00:00<00:00, 60.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip heart-disease-data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FwTQ2hJtEYX",
        "outputId": "c95d374d-8276-4f8a-c20b-cc7b2863c682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  heart-disease-data.zip\n",
            "  inflating: heart_disease_uci.csv   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First, let's assume we have a cleaned DataFrame `df`\n",
        "# with the given features and a target variable 'num'.\n",
        "# The 'num' variable represents the presence of heart disease.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import warnings\n",
        "from sklearn.impute import SimpleImputer\n",
        "# Suppress all warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- 1. Create a sample dataset to simulate the provided data ---\n",
        "\n",
        "df = pd.read_csv('/content/heart_disease_uci.csv')\n",
        "\n",
        "\n",
        "df.loc[df.sample(frac=0.05).index, 'chol'] = np.nan\n",
        "\n",
        "# --- Preprocessing and Feature Engineering ---\n",
        "# Define features (X) and target (y)\n",
        "X = df.drop('num', axis=1)\n",
        "y = df['num']\n",
        "\n",
        "# The problem states binary classification, so we will convert 'num' into a binary target.\n",
        "# 0 for no heart disease, 1 for heart disease.\n",
        "y_binary = (y > 0).astype(int)\n",
        "\n",
        "# Separate numerical and categorical columns\n",
        "# We drop 'id' and 'origin' as they are not predictive\n",
        "numerical_features = ['age', 'trestbps', 'chol', 'thalch', 'oldpeak', 'ca']\n",
        "categorical_features = ['sex', 'cp', 'restecg', 'exang', 'slope', 'thal']\n",
        "\n",
        "# Create preprocessing pipelines for numerical and categorical features\n",
        "# The numerical pipeline now includes an imputer to handle missing values\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')), # <-- NEW: Impute missing values with the mean\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "# Create a column transformer to apply the preprocessing steps\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ],\n",
        "    remainder='drop'\n",
        ")\n",
        "\n",
        "# --- Data Split ---\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_binary, test_size=0.2, random_state=42, stratify=y_binary\n",
        ")\n",
        "\n",
        "# --- Overfitting Prevention (Regularization) ---\n",
        "# Logistic Regression in scikit-learn uses L2 regularization by default.\n",
        "# The 'C' parameter controls the strength of this regularization.\n",
        "# A smaller 'C' value means stronger regularization.\n",
        "# Here, we use a value of C=1.0 as a standard starting point.\n",
        "# You can also set a different penalty like 'l1'.\n",
        "\n",
        "# Create the final model pipeline with the preprocessor and the classifier\n",
        "log_reg_model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression(random_state=42, C=1.0, solver='liblinear'))\n",
        "])\n",
        "\n",
        "# Train the model on the training data\n",
        "log_reg_model.fit(X_train, y_train)\n",
        "\n",
        "# --- Final Accuracy Print and Evaluation ---\n",
        "# Predict on the test data\n",
        "y_pred = log_reg_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Print a classification report for a more detailed look at performance\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pcwzQUZvhh1",
        "outputId": "6f794cc5-d5e0-4594-c9d1-9ceb4fd058e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'age', 'sex', 'dataset', 'cp', 'trestbps', 'chol', 'fbs',\n",
            "       'restecg', 'thalch', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'num'],\n",
            "      dtype='object')\n",
            "Model Accuracy: 0.83\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.78      0.81        82\n",
            "           1       0.83      0.87      0.85       102\n",
            "\n",
            "    accuracy                           0.83       184\n",
            "   macro avg       0.83      0.83      0.83       184\n",
            "weighted avg       0.83      0.83      0.83       184\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Final Infer of the Heart Disease Data**\n",
        "\n",
        "Based on the provided code, the final infer of the Heart Disease Data refers to the process of using the trained LogisticRegression model to make predictions on the held-out test data. This process is crucial for evaluating how well the model generalizes to new, unseen data.\n",
        "\n",
        "The selected code, from **sklearn.impute import SimpleImputer** # <-- NEW: Import SimpleImputer, is a preprocessing step that helps ensure the data is clean before it's used for training or prediction. By correctly handling missing values, the imputer allows the model to make predictions without encountering errors. The final infer of the Heart Disease Data involves these steps:\n",
        "\n",
        "**Preprocessing:** The X_test data is passed through the same preprocessor pipeline that was used for the training data. This ensures that the test data is handled in the same way, with missing values imputed and features scaled.\n",
        "\n",
        "**Prediction:** The preprocessed test data is fed into the trained log_reg_model, which outputs a set of predicted labels (y_pred). These are the model's predictions for whether each patient in the test set has heart disease.\n",
        "\n",
        "**Evaluation:** The predicted labels (y_pred) are compared to the true labels (y_test) to calculate the model's accuracy and generate a detailed classification report. This final step provides a clear and objective measure of the model's performance."
      ],
      "metadata": {
        "id": "L78GffHz0q7H"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4c18Q7Ss0qe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgxkOQj-x5Hd"
      },
      "source": [
        "# Deep Learning Assessment\n",
        "## Solving Face Recognition using Deep Learning Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xHPAL3V3iLN"
      },
      "source": [
        "Most of the code is given. There is one `TODO` section where, one has to code the entire architecture in pytorch from scratch. Once the model architecture is ready all the components in code will be working. Further instructions are provided below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6RzSqFgmJSD",
        "outputId": "96e9a31f-c2c6-4624-b174-296d7c5f8867"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# Installing Libraries\n",
        "!pip install scikit-learn matplotlib Pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsFZ9F12mRXP"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Basic Imports\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "import numpy as  np\n",
        "import pandas as pd\n",
        "from scipy import linalg\n",
        "\n",
        "# Loading and plotting data\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Features\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import KernelPCA\n",
        "from sklearn.discriminant_analysis import _class_means,_class_cov\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.manifold import TSNE\n",
        "plt.ion()\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6z1llmOmT1D"
      },
      "outputs": [],
      "source": [
        "opt = {\n",
        "    'image_size': 32,\n",
        "    'is_grayscale': True,\n",
        "    'val_split': 0.75\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIyXYYk8mbko"
      },
      "outputs": [],
      "source": [
        "cfw_dict = {'Amitabhbachan': 0,\n",
        "    'AamirKhan': 1,\n",
        "    'DwayneJohnson': 2,\n",
        "    'AishwaryaRai': 3,\n",
        "    'BarackObama': 4,\n",
        "    'NarendraModi': 5,\n",
        "    'ManmohanSingh': 6,\n",
        "    'VladimirPutin': 7}\n",
        "\n",
        "imfdb_dict = {'MadhuriDixit': 0,\n",
        "     'Kajol': 1,\n",
        "     'SharukhKhan': 2,\n",
        "     'ShilpaShetty': 3,\n",
        "     'AmitabhBachan': 4,\n",
        "     'KatrinaKaif': 5,\n",
        "     'AkshayKumar': 6,\n",
        "     'Amir': 7}\n",
        "\n",
        "# Load Image using PIL for dataset\n",
        "def load_image(path):\n",
        "    im = Image.open(path).convert('L' if opt['is_grayscale'] else 'RGB')\n",
        "    im = im.resize((opt['image_size'],opt['image_size']))\n",
        "    im = np.array(im)\n",
        "    im = im/256\n",
        "    return im\n",
        "\n",
        "# Load the full data from directory\n",
        "def load_data(dir_path):\n",
        "    image_list = []\n",
        "    y_list = []\n",
        "\n",
        "    if \"CFW\" in dir_path:\n",
        "        label_dict = cfw_dict\n",
        "\n",
        "    elif \"yale\" in dir_path.lower():\n",
        "        label_dict = {}\n",
        "        for i in range(15):\n",
        "            label_dict[str(i+1)] = i\n",
        "    elif \"IMFDB\" in dir_path:\n",
        "        label_dict = imfdb_dict\n",
        "    else:\n",
        "        raise KeyError(\"Dataset not found.\")\n",
        "\n",
        "\n",
        "    for filename in sorted(os.listdir(dir_path)):\n",
        "        if filename.endswith(\".png\"):\n",
        "            im = load_image(os.path.join(dir_path,filename))\n",
        "            y = filename.split('_')[0]\n",
        "            y = label_dict[y]\n",
        "            image_list.append(im)\n",
        "            y_list.append(y)\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "    image_list = np.array(image_list)\n",
        "    y_list = np.array(y_list)\n",
        "\n",
        "    print(\"Dataset shape:\",image_list.shape)\n",
        "\n",
        "    return image_list,y_list\n",
        "\n",
        "# Display N Images in a nice format\n",
        "def disply_images(imgs,classes,row=1,col=2,w=64,h=64):\n",
        "    fig=plt.figure(figsize=(8, 8))\n",
        "    for i in range(1, col*row +1):\n",
        "        img = imgs[i-1]\n",
        "        fig.add_subplot(row, col, i)\n",
        "\n",
        "        if opt['is_grayscale']:\n",
        "            plt.imshow(img , cmap='gray')\n",
        "        else:\n",
        "            plt.imshow(img)\n",
        "\n",
        "        plt.title(\"Class:{}\".format(classes[i-1]))\n",
        "        plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6vOrbwL4Zv7"
      },
      "source": [
        "> 1. One has to download the IMFDB [datatset](https://iiitaphyd-my.sharepoint.com/:f:/g/personal/manasa_k_research_iiit_ac_in/EpwNpQwL4-JKoP4hGMnhq-0B-TxAVi4_qAleRbiewLgl1Q?e=rfKVRp) and upload to their drive.\n",
        "2. Once it's uploaded you have to sync your drive with colab.\n",
        "3. Once it is done, you have to paste the exact directory in the `dirpath` (locate the correct path for the code to execute)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Importing The DataSet From Kaggle**"
      ],
      "metadata": {
        "id": "Kua1sBYL1KdN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "4Az1xYkCMZok",
        "outputId": "094c9ab8-94e6-4e81-dba3-e8a993a79e26"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-08db8d73-ce29-4d68-8d07-0c135daa1a51\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-08db8d73-ce29-4d68-8d07-0c135daa1a51\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"pallavibandikari\",\"key\":\"13abfdf792138a7adb0c04c73884ea23\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()  # Upload the downloaded `kaggle.json`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_X7xRIP7Mje-"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle  # Install Kaggle API\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json  # Set permissions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hLFFzycMmiU",
        "outputId": "fbba3ef1-9e6e-4c2a-e2b6-d0fb2ae38795"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/atulanandjha/lfwpeople\n",
            "License(s): GNU Lesser General Public License 3.0\n",
            "Downloading lfwpeople.zip to /content\n",
            " 54% 125M/232M [00:00<00:00, 1.31GB/s]\n",
            "100% 232M/232M [00:00<00:00, 678MB/s] \n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d atulanandjha/lfwpeople"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKN-YZ-FMqmr",
        "outputId": "c4db4aa2-0840-4a52-9d7e-d32f89f0b210"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  lfwpeople.zip\n",
            "  inflating: lfw-funneled.tgz        \n",
            "  inflating: pairs.txt               \n",
            "  inflating: pairsDevTest.txt        \n",
            "  inflating: pairsDevTrain.txt       \n"
          ]
        }
      ],
      "source": [
        "!unzip lfwpeople.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQ4ANJXHPpas"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# CustomDataset class for LFW\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dir_path, transform=None):\n",
        "        self.dir_path = dir_path\n",
        "        self.transform = transform\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        self.label_dict = {}\n",
        "\n",
        "        # Get a list of all person directories\n",
        "        person_dirs = sorted([d for d in os.listdir(dir_path) if os.path.isdir(os.path.join(dir_path, d))])\n",
        "\n",
        "        # Count the number of images per person\n",
        "        person_counts = {}\n",
        "        for person_name in person_dirs:\n",
        "            person_path = os.path.join(dir_path, person_name)\n",
        "            num_images = len([f for f in os.listdir(person_path) if f.endswith((\".jpg\", \".png\"))])\n",
        "            if num_images >= 2: # We only keep people with at least 2 images\n",
        "                person_counts[person_name] = num_images\n",
        "\n",
        "        # Create a new label dictionary and populate data/labels lists for valid classes\n",
        "        valid_person_names = sorted(person_counts.keys())\n",
        "        for i, person_name in enumerate(valid_person_names):\n",
        "            self.label_dict[person_name] = i\n",
        "            person_path = os.path.join(dir_path, person_name)\n",
        "            for filename in sorted(os.listdir(person_path)):\n",
        "                if filename.endswith((\".jpg\", \".png\")):\n",
        "                    path = os.path.join(person_path, filename)\n",
        "                    self.data.append(path)\n",
        "                    self.labels.append(self.label_dict[person_name])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        # This part remains the same as your original code\n",
        "        image = image.resize((32, 32)) # Assuming opt['image_size'] is 32\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# You should define your `transformations` and `dataloader` as before,\n",
        "# but using the new dataset class.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extracting Images from .tgz file"
      ],
      "metadata": {
        "id": "nGxyFw9P2KTn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOy_BH0OSqbV",
        "outputId": "4cc86728-7a86-4833-d994-b6d3b1e34537"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1569904384.py:8: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
            "  tar.extractall(path=extracted_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully extracted LFW dataset.\n"
          ]
        }
      ],
      "source": [
        "import tarfile\n",
        "\n",
        "tar_file_path = '/content/lfw-funneled.tgz'\n",
        "extracted_path = '/content/lfw_extracted'\n",
        "\n",
        "if not os.path.exists(extracted_path):\n",
        "    with tarfile.open(tar_file_path, \"r:gz\") as tar:\n",
        "        tar.extractall(path=extracted_path)\n",
        "    print(\"Successfully extracted LFW dataset.\")\n",
        "else:\n",
        "    print(\"LFW dataset already extracted.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sscQSeN0psJX"
      },
      "source": [
        "# Example Ilustration of loading VGG-16,19 Models and Features in PyTorch\n",
        "## TODO\n",
        "> 1. Initially we have provided a pre-trained model here for VGG-16,19 as an example.\n",
        "2. Your task is to choose `1` among 3 different architectures and write the entire code only for the architecture.\n",
        "3. Later, you have to answer all the questions regardless of chosen architecture.\n",
        "\n",
        "Note: You have to recite the statements from the original paper and justify your answer with the perspective of authors. An example question answer is provided.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlmrV-F1p2yV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms, datasets\n",
        "from torch.utils.data import DataLoader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Performing Train and Validation Split"
      ],
      "metadata": {
        "id": "i248SBp12DuU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04EQUWTWTomw",
        "outputId": "5794ac3a-0075-472e-bdc7-aac2109a1fe9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes (people) in the LFW dataset: 1680\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "# The rest of your setup code\n",
        "transformations = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Use the path to the newly extracted folder\n",
        "lfw_extracted_path = \"/content/lfw_extracted/lfw_funneled\"\n",
        "dataset = CustomDataset(dir_path=lfw_extracted_path, transform=transformations)\n",
        "\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "train_indices, val_indices = train_test_split(\n",
        "    range(len(dataset)),\n",
        "    test_size=0.2,  # 20% of the data for validation\n",
        "    random_state=42,\n",
        "    stratify=dataset.labels  # Stratify to ensure same class distribution\n",
        ")\n",
        "\n",
        "# Create subsets for training and validation\n",
        "train_dataset = Subset(dataset, train_indices)\n",
        "val_dataset = Subset(dataset, val_indices)\n",
        "\n",
        "# Create new DataLoaders for training and validation\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# The number of classes will be the number of subdirectories (people)\n",
        "num_classes = len(dataset.label_dict)\n",
        "print(f\"Number of classes (people) in the LFW dataset: {num_classes}\")\n",
        "\n",
        "\n",
        "\n",
        "# Now you can create your model with the correct number of classes\n",
        "# Example: vit_model = ViT_B(num_classes=num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwcyBGXA94D-"
      },
      "source": [
        "## Example Block\n",
        "## Just for illustration, no credits will be given"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBUt4T9dp5nG"
      },
      "outputs": [],
      "source": [
        "#predefined torch model VGG-16\n",
        "vgg16 = models.vgg16(pretrained=True)\n",
        "\n",
        "#predefined torch model VGG-19\n",
        "vgg19 = models.vgg19(pretrained=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wqpCY4zNRNA"
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary\n",
        "summary(vgg16, (3,224,224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxnESV2XN4RI"
      },
      "outputs": [],
      "source": [
        "summary(vgg19, (3,224,224))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KrKM_IoFW1L"
      },
      "source": [
        "## TODO Block\n",
        "\n",
        "### Choose any `1` of the three archiectures from the below and write the code in the next subsequent cells\n",
        "\n",
        "1. VGG-16 and VGG-19 [1]\n",
        "2. ResNet-34 and Resnet-50 [2]\n",
        "3. ViT-Base [3]\n",
        "\n",
        "\n",
        "References\n",
        "\n",
        "[1] Simonyan, Karen, and Andrew Zisserman. \"Very deep convolutional networks for large-scale image recognition.\" arXiv preprint arXiv:1409.1556 (2014).URL: https://arxiv.org/abs/1409.1556\n",
        "\n",
        "[2] He, Kaiming, et al. \"Deep residual learning for image recognition.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2016. URL: https://arxiv.org/abs/1512.03385\n",
        "\n",
        "[3] Dosovitskiy, Alexey, et al. \"An image is worth 16x16 words: Transformers for image recognition at scale.\" arXiv preprint arXiv:2010.11929 (2020). URL: https://arxiv.org/abs/2010.11929"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYkpKTNEGxmS"
      },
      "source": [
        "## VGG-16, 19 Code\n",
        "\n",
        "----TODO----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7I4SsSRFV3w"
      },
      "outputs": [],
      "source": [
        "## Place your code here, archiecture should include every block detailed as per paper [1]\n",
        "# class VGG16():\n",
        "#   ## TODO ##\n",
        "\n",
        "# class VGG19():\n",
        "#   ## TODO ##\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQRVcC4hOuPG"
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary\n",
        "summary(VGG16(), (3,224,224))\n",
        "print(\"\\n########################\\n\")\n",
        "summary(VGG19(), (3,224,224))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBXIvwLQHN_r"
      },
      "source": [
        "##ResNet-34, 50 Code\n",
        "----TODO----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHYJCu0SHTLY"
      },
      "outputs": [],
      "source": [
        "## Place your code here, archiecture should include every block detailed as per paper [2]\n",
        "# class ResNet34():\n",
        "#   ## TODO ##\n",
        "\n",
        "# class ResNet50():\n",
        "#   ## TODO ##\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f75OXsQXQ4tK"
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary\n",
        "summary(ResNet34(), (3,224,224))\n",
        "print(\"\\n########################\\n\")\n",
        "summary(ResNet50(), (3,224,224))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Building  ViT-B Model"
      ],
      "metadata": {
        "id": "Huw9i-Ea168n"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvt6PTpNHiOr"
      },
      "source": [
        "##ViT-B Code\n",
        "----TODO----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ey8walTFHrjv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from einops import rearrange\n",
        "from torchsummary import summary\n",
        "\n",
        "# The original ViT paper uses a patch size of 16x16 with a 224x224 image size.\n",
        "# For the assignment's 32x32 image size, we'll use a patch size of 4x4.\n",
        "# This results in (32*32)/(4*4) = 64 patches, which is a suitable sequence length.\n",
        "\n",
        "class MultiHeadSelfAttention(nn.Module):\n",
        "    \"\"\"Multi-Head Self-Attention block as described in the ViT paper.\"\"\"\n",
        "    def __init__(self, embed_dim, num_heads, dropout=0.3): # Added dropout parameter\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = embed_dim // num_heads\n",
        "        assert (self.head_dim * num_heads == self.embed_dim), \"Embedding dimension must be divisible by number of heads\"\n",
        "\n",
        "        self.qkv_proj = nn.Linear(embed_dim, 3 * embed_dim)\n",
        "        self.o_proj = nn.Linear(embed_dim, embed_dim)\n",
        "        self.dropout_attn = nn.Dropout(dropout) # Dropout for attention weights\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, _ = x.shape\n",
        "        qkv = self.qkv_proj(x).reshape(batch_size, seq_len, self.num_heads, 3 * self.head_dim)\n",
        "        qkv = qkv.permute(0, 2, 1, 3) # (batch, heads, seq_len, head_dim)\n",
        "        q, k, v = qkv.chunk(3, dim=-1)\n",
        "\n",
        "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
        "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
        "        attn_weights = self.dropout_attn(attn_weights) # Apply dropout to attention weights\n",
        "\n",
        "        output = torch.matmul(attn_weights, v)\n",
        "        output = output.permute(0, 2, 1, 3).reshape(batch_size, seq_len, self.embed_dim)\n",
        "\n",
        "        return self.o_proj(output)\n",
        "\n",
        "class MLPBlock(nn.Module):\n",
        "    \"\"\"Feed-forward MLP block used in the Transformer Encoder.\"\"\"\n",
        "    def __init__(self, embed_dim, mlp_dim, dropout=0.1): # Added dropout parameter\n",
        "        super().__init__()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(embed_dim, mlp_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout), # Added Dropout layer\n",
        "            nn.Linear(mlp_dim, embed_dim),\n",
        "            nn.Dropout(dropout)  # Added Dropout layer\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.mlp(x)\n",
        "\n",
        "class TransformerEncoderBlock(nn.Module):\n",
        "    \"\"\"Single block of the Transformer Encoder.\"\"\"\n",
        "    def __init__(self, embed_dim, num_heads, mlp_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.attn = MultiHeadSelfAttention(embed_dim, num_heads, dropout)\n",
        "        self.mlp = MLPBlock(embed_dim, mlp_dim, dropout)\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "        self.dropout_pre_attn = nn.Dropout(dropout) # Dropout for pre-attention input\n",
        "        self.dropout_pre_mlp = nn.Dropout(dropout)  # Dropout for pre-MLP input\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.dropout_pre_attn(self.attn(self.norm1(x)))\n",
        "        x = x + self.dropout_pre_mlp(self.mlp(self.norm2(x)))\n",
        "        return x\n",
        "\n",
        "class ViT_B(nn.Module):\n",
        "    \"\"\"Vision Transformer (Base) model architecture.\"\"\"\n",
        "    def __init__(self, image_size=32, patch_size=4, num_classes=8, embed_dim=768, num_layers=12, num_heads=12, mlp_dim=3072, dropout=0.1): # Added dropout\n",
        "        super().__init__()\n",
        "        self.patch_size = patch_size\n",
        "        self.num_patches = (image_size // patch_size) ** 2\n",
        "\n",
        "        # Patch embedding layer: a convolution layer that projects patches into a vector\n",
        "        self.patch_embedding = nn.Conv2d(3, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "\n",
        "        # Learnable classification token\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n",
        "\n",
        "        # Positional embeddings to maintain spatial information\n",
        "        self.positional_embedding = nn.Parameter(torch.randn(1, self.num_patches + 1, embed_dim))\n",
        "\n",
        "        # Stack of Transformer Encoder blocks\n",
        "        self.encoder_blocks = nn.ModuleList([\n",
        "            TransformerEncoderBlock(embed_dim, num_heads, mlp_dim, dropout) for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(embed_dim),\n",
        "            nn.Linear(embed_dim, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 1. Patch embedding\n",
        "        x = self.patch_embedding(x)\n",
        "        # Reshape to a sequence of patches\n",
        "        x = rearrange(x, 'b c h w -> b (h w) c')\n",
        "\n",
        "        # 2. Add class token\n",
        "        cls_token = self.cls_token.expand(x.shape[0], -1, -1)\n",
        "        x = torch.cat((cls_token, x), dim=1)\n",
        "\n",
        "        # 3. Add positional embeddings\n",
        "        x = x + self.positional_embedding\n",
        "\n",
        "        # 4. Pass through Transformer Encoder\n",
        "        for block in self.encoder_blocks:\n",
        "            x = block(x)\n",
        "\n",
        "        # 5. Use the output of the class token for classification\n",
        "        cls_token_output = x[:, 0]\n",
        "\n",
        "        # 6. Pass to MLP head for final prediction\n",
        "        return self.mlp_head(cls_token_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKCnDmXZSTV0"
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary\n",
        "summary(ViT_B, (3,224,224))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Calling the Model"
      ],
      "metadata": {
        "id": "q5FobIoS1u0n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKko6HRXZ8k6"
      },
      "outputs": [],
      "source": [
        "vit_model = ViT_B(num_classes=num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training the Model"
      ],
      "metadata": {
        "id": "TX67MOjO10nd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0n7zv5pOsMyn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def train_model(model, data_loader, epochs=50, weight_decay=1e-3):\n",
        "    \"\"\"\n",
        "    Trains the model with L2 Regularization (Weight Decay).\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The model to be trained.\n",
        "        data_loader (DataLoader): The DataLoader for the training set.\n",
        "        epochs (int): The number of training epochs.\n",
        "        weight_decay (float): The L2 regularization penalty.\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # L2 Regularization is implemented via the 'weight_decay' parameter in the optimizer.\n",
        "    # The value has been increased from 1e-4 to 1e-3 to make the regularization stronger.\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=weight_decay)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        i = 0\n",
        "        for images, labels in data_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            print(f\"Batch {i+1}, Loss: {loss.item()}\")\n",
        "            i += 1\n",
        "        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgxQ3f6iWp1M",
        "outputId": "a3d064d5-b25c-4ce9-97e2-4c0bc9a08807"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Batch 83, Loss: 0.42857709527015686\n",
            "Batch 84, Loss: 0.5635325312614441\n",
            "Batch 85, Loss: 0.4598795175552368\n",
            "Batch 86, Loss: 0.39806824922561646\n",
            "Batch 87, Loss: 0.30884814262390137\n",
            "Batch 88, Loss: 0.3405406177043915\n",
            "Batch 89, Loss: 0.43012452125549316\n",
            "Batch 90, Loss: 0.2949785590171814\n",
            "Batch 91, Loss: 0.4229142367839813\n",
            "Batch 92, Loss: 0.4780976176261902\n",
            "Batch 93, Loss: 0.6342669129371643\n",
            "Batch 94, Loss: 0.24478036165237427\n",
            "Batch 95, Loss: 0.45154258608818054\n",
            "Batch 96, Loss: 0.4119148850440979\n",
            "Batch 97, Loss: 0.5253069400787354\n",
            "Batch 98, Loss: 0.4361570477485657\n",
            "Batch 99, Loss: 0.4147045612335205\n",
            "Batch 100, Loss: 0.6671884059906006\n",
            "Batch 101, Loss: 0.4072793126106262\n",
            "Batch 102, Loss: 0.2822303771972656\n",
            "Batch 103, Loss: 0.5440785884857178\n",
            "Batch 104, Loss: 0.6354407668113708\n",
            "Batch 105, Loss: 0.41437211632728577\n",
            "Batch 106, Loss: 0.44817546010017395\n",
            "Batch 107, Loss: 0.37107986211776733\n",
            "Batch 108, Loss: 0.378378689289093\n",
            "Batch 109, Loss: 0.4932354688644409\n",
            "Batch 110, Loss: 0.7169088125228882\n",
            "Batch 111, Loss: 0.5946465730667114\n",
            "Batch 112, Loss: 0.44648706912994385\n",
            "Batch 113, Loss: 0.5921955108642578\n",
            "Batch 114, Loss: 0.40595734119415283\n",
            "Batch 115, Loss: 0.5052112340927124\n",
            "Batch 116, Loss: 0.33017587661743164\n",
            "Batch 117, Loss: 0.5162715911865234\n",
            "Batch 118, Loss: 0.32298704981803894\n",
            "Batch 119, Loss: 0.6847847700119019\n",
            "Batch 120, Loss: 0.9488968849182129\n",
            "Batch 121, Loss: 0.3745213747024536\n",
            "Batch 122, Loss: 0.624894380569458\n",
            "Batch 123, Loss: 0.4909326434135437\n",
            "Batch 124, Loss: 0.44201064109802246\n",
            "Batch 125, Loss: 0.43021923303604126\n",
            "Batch 126, Loss: 0.3342038691043854\n",
            "Batch 127, Loss: 0.27206915616989136\n",
            "Batch 128, Loss: 0.47015154361724854\n",
            "Batch 129, Loss: 0.28090938925743103\n",
            "Batch 130, Loss: 0.7767562866210938\n",
            "Batch 131, Loss: 0.48236680030822754\n",
            "Batch 132, Loss: 0.5615861415863037\n",
            "Batch 133, Loss: 0.5046248435974121\n",
            "Batch 134, Loss: 0.4103271961212158\n",
            "Batch 135, Loss: 0.3299078941345215\n",
            "Batch 136, Loss: 0.40091314911842346\n",
            "Batch 137, Loss: 0.5832786560058594\n",
            "Batch 138, Loss: 0.5520439147949219\n",
            "Batch 139, Loss: 0.5488132238388062\n",
            "Batch 140, Loss: 0.6738579273223877\n",
            "Batch 141, Loss: 0.6429551839828491\n",
            "Batch 142, Loss: 0.7249984741210938\n",
            "Batch 143, Loss: 0.6035202741622925\n",
            "Batch 144, Loss: 0.5913184881210327\n",
            "Batch 145, Loss: 0.53121018409729\n",
            "Batch 146, Loss: 0.5910265445709229\n",
            "Batch 147, Loss: 0.4921680688858032\n",
            "Batch 148, Loss: 0.5042072534561157\n",
            "Batch 149, Loss: 0.6240274906158447\n",
            "Batch 150, Loss: 0.682866096496582\n",
            "Batch 151, Loss: 0.4846630096435547\n",
            "Batch 152, Loss: 0.855851411819458\n",
            "Batch 153, Loss: 0.5031293034553528\n",
            "Batch 154, Loss: 0.5988057851791382\n",
            "Batch 155, Loss: 0.4869921803474426\n",
            "Batch 156, Loss: 0.46413514018058777\n",
            "Batch 157, Loss: 0.42492467164993286\n",
            "Batch 158, Loss: 0.4115203022956848\n",
            "Batch 159, Loss: 0.45160573720932007\n",
            "Batch 160, Loss: 0.5745514631271362\n",
            "Batch 161, Loss: 0.42217230796813965\n",
            "Batch 162, Loss: 0.6817285418510437\n",
            "Batch 163, Loss: 0.4317821264266968\n",
            "Batch 164, Loss: 0.4076714515686035\n",
            "Batch 165, Loss: 0.5692636370658875\n",
            "Batch 166, Loss: 0.6582472324371338\n",
            "Batch 167, Loss: 0.5237831473350525\n",
            "Batch 168, Loss: 0.3297099471092224\n",
            "Batch 169, Loss: 0.5382339954376221\n",
            "Batch 170, Loss: 0.5750839710235596\n",
            "Batch 171, Loss: 0.40648093819618225\n",
            "Batch 172, Loss: 0.4667283892631531\n",
            "Batch 173, Loss: 0.7564122676849365\n",
            "Batch 174, Loss: 0.3240509033203125\n",
            "Batch 175, Loss: 0.5438483953475952\n",
            "Batch 176, Loss: 0.7383129000663757\n",
            "Batch 177, Loss: 0.43240243196487427\n",
            "Batch 178, Loss: 0.577129602432251\n",
            "Batch 179, Loss: 1.0021883249282837\n",
            "Batch 180, Loss: 0.5020524263381958\n",
            "Batch 181, Loss: 0.6438588500022888\n",
            "Batch 182, Loss: 0.5888490676879883\n",
            "Batch 183, Loss: 0.5785870552062988\n",
            "Batch 184, Loss: 0.7641964554786682\n",
            "Batch 185, Loss: 0.33543384075164795\n",
            "Batch 186, Loss: 0.5647914409637451\n",
            "Batch 187, Loss: 0.44259920716285706\n",
            "Batch 188, Loss: 0.33724457025527954\n",
            "Batch 189, Loss: 0.8574551939964294\n",
            "Batch 190, Loss: 0.31638240814208984\n",
            "Batch 191, Loss: 0.2735529839992523\n",
            "Batch 192, Loss: 0.6967501640319824\n",
            "Batch 193, Loss: 0.4583631157875061\n",
            "Batch 194, Loss: 0.5802879929542542\n",
            "Batch 195, Loss: 0.5398224592208862\n",
            "Batch 196, Loss: 0.5867316126823425\n",
            "Batch 197, Loss: 0.43689948320388794\n",
            "Batch 198, Loss: 0.7513682842254639\n",
            "Batch 199, Loss: 0.4423377513885498\n",
            "Batch 200, Loss: 0.7154473662376404\n",
            "Batch 201, Loss: 0.6881456971168518\n",
            "Batch 202, Loss: 0.379489004611969\n",
            "Batch 203, Loss: 0.47585928440093994\n",
            "Batch 204, Loss: 0.47933220863342285\n",
            "Batch 205, Loss: 0.6598236560821533\n",
            "Batch 206, Loss: 0.5664837956428528\n",
            "Batch 207, Loss: 0.43972641229629517\n",
            "Batch 208, Loss: 0.39731365442276\n",
            "Batch 209, Loss: 0.6159425973892212\n",
            "Batch 210, Loss: 0.6734530925750732\n",
            "Batch 211, Loss: 0.8492549061775208\n",
            "Batch 212, Loss: 0.6181278228759766\n",
            "Batch 213, Loss: 0.640394389629364\n",
            "Batch 214, Loss: 0.5126602649688721\n",
            "Batch 215, Loss: 0.5396945476531982\n",
            "Batch 216, Loss: 0.7969043254852295\n",
            "Batch 217, Loss: 0.5813884735107422\n",
            "Batch 218, Loss: 0.5835672616958618\n",
            "Batch 219, Loss: 0.8289190530776978\n",
            "Batch 220, Loss: 0.5841054320335388\n",
            "Batch 221, Loss: 0.6318286061286926\n",
            "Batch 222, Loss: 0.7672134637832642\n",
            "Batch 223, Loss: 0.5351442694664001\n",
            "Batch 224, Loss: 0.5037126541137695\n",
            "Batch 225, Loss: 0.639817476272583\n",
            "Batch 226, Loss: 0.6419690847396851\n",
            "Batch 227, Loss: 0.9201681613922119\n",
            "Batch 228, Loss: 0.4526093900203705\n",
            "Batch 229, Loss: 0.5632851123809814\n",
            "Batch 230, Loss: 0.1272474080324173\n",
            "Epoch 29, Loss: 0.1272474080324173\n",
            "Batch 1, Loss: 0.33412083983421326\n",
            "Batch 2, Loss: 0.40866619348526\n",
            "Batch 3, Loss: 0.41887566447257996\n",
            "Batch 4, Loss: 0.32326146960258484\n",
            "Batch 5, Loss: 0.4423765540122986\n",
            "Batch 6, Loss: 0.4299347996711731\n",
            "Batch 7, Loss: 0.5755681395530701\n",
            "Batch 8, Loss: 0.390791654586792\n",
            "Batch 9, Loss: 0.26147282123565674\n",
            "Batch 10, Loss: 0.6043092012405396\n",
            "Batch 11, Loss: 0.32773327827453613\n",
            "Batch 12, Loss: 0.6863486170768738\n",
            "Batch 13, Loss: 0.3384215533733368\n",
            "Batch 14, Loss: 0.3262227773666382\n",
            "Batch 15, Loss: 0.34747573733329773\n",
            "Batch 16, Loss: 0.19506947696208954\n",
            "Batch 17, Loss: 0.2805105149745941\n",
            "Batch 18, Loss: 0.23013737797737122\n",
            "Batch 19, Loss: 0.5897932648658752\n",
            "Batch 20, Loss: 0.16267025470733643\n",
            "Batch 21, Loss: 0.3265113830566406\n",
            "Batch 22, Loss: 0.4320146441459656\n",
            "Batch 23, Loss: 0.36771196126937866\n",
            "Batch 24, Loss: 0.39200258255004883\n",
            "Batch 25, Loss: 0.3273571729660034\n",
            "Batch 26, Loss: 0.2931072413921356\n",
            "Batch 27, Loss: 0.21735921502113342\n",
            "Batch 28, Loss: 0.28161007165908813\n",
            "Batch 29, Loss: 0.24973176419734955\n",
            "Batch 30, Loss: 0.2826974391937256\n",
            "Batch 31, Loss: 0.30305761098861694\n",
            "Batch 32, Loss: 0.7482532858848572\n",
            "Batch 33, Loss: 0.4008471369743347\n",
            "Batch 34, Loss: 0.520617663860321\n",
            "Batch 35, Loss: 0.3083251714706421\n",
            "Batch 36, Loss: 0.3643684983253479\n",
            "Batch 37, Loss: 0.552487850189209\n",
            "Batch 38, Loss: 0.3320891857147217\n",
            "Batch 39, Loss: 0.3018447458744049\n",
            "Batch 40, Loss: 0.3249656558036804\n",
            "Batch 41, Loss: 0.5262223482131958\n",
            "Batch 42, Loss: 0.29659608006477356\n",
            "Batch 43, Loss: 0.4354463815689087\n",
            "Batch 44, Loss: 0.4502190351486206\n",
            "Batch 45, Loss: 0.31032252311706543\n",
            "Batch 46, Loss: 0.48506930470466614\n",
            "Batch 47, Loss: 0.2954403758049011\n",
            "Batch 48, Loss: 0.31477120518684387\n",
            "Batch 49, Loss: 0.33865147829055786\n",
            "Batch 50, Loss: 0.3384128212928772\n",
            "Batch 51, Loss: 0.2787277102470398\n",
            "Batch 52, Loss: 0.4114157259464264\n",
            "Batch 53, Loss: 0.5125626921653748\n",
            "Batch 54, Loss: 0.3916148543357849\n",
            "Batch 55, Loss: 0.37439781427383423\n",
            "Batch 56, Loss: 0.3595382571220398\n",
            "Batch 57, Loss: 0.2884349524974823\n",
            "Batch 58, Loss: 0.2783787250518799\n",
            "Batch 59, Loss: 0.48091042041778564\n",
            "Batch 60, Loss: 0.3585336208343506\n",
            "Batch 61, Loss: 0.6030288934707642\n",
            "Batch 62, Loss: 0.4541162848472595\n",
            "Batch 63, Loss: 0.43754228949546814\n",
            "Batch 64, Loss: 0.2495945394039154\n",
            "Batch 65, Loss: 0.26637107133865356\n",
            "Batch 66, Loss: 0.3985046148300171\n",
            "Batch 67, Loss: 0.23038500547409058\n",
            "Batch 68, Loss: 0.23896527290344238\n",
            "Batch 69, Loss: 0.3983948826789856\n",
            "Batch 70, Loss: 0.3777048885822296\n",
            "Batch 71, Loss: 0.27490344643592834\n",
            "Batch 72, Loss: 0.7613354921340942\n",
            "Batch 73, Loss: 0.23542119562625885\n",
            "Batch 74, Loss: 0.24734759330749512\n",
            "Batch 75, Loss: 0.46022844314575195\n",
            "Batch 76, Loss: 0.3772030174732208\n",
            "Batch 77, Loss: 0.3042409121990204\n",
            "Batch 78, Loss: 0.35762304067611694\n",
            "Batch 79, Loss: 0.38589954376220703\n",
            "Batch 80, Loss: 0.3646008372306824\n",
            "Batch 81, Loss: 0.6268395185470581\n",
            "Batch 82, Loss: 0.3011842370033264\n",
            "Batch 83, Loss: 0.3508426547050476\n",
            "Batch 84, Loss: 0.47562628984451294\n",
            "Batch 85, Loss: 0.37213271856307983\n",
            "Batch 86, Loss: 0.485317587852478\n",
            "Batch 87, Loss: 0.4322736859321594\n",
            "Batch 88, Loss: 0.5348840951919556\n",
            "Batch 89, Loss: 0.7754313349723816\n",
            "Batch 90, Loss: 0.3199842870235443\n",
            "Batch 91, Loss: 0.44818270206451416\n",
            "Batch 92, Loss: 0.3221452236175537\n",
            "Batch 93, Loss: 0.22325804829597473\n",
            "Batch 94, Loss: 0.3698476254940033\n",
            "Batch 95, Loss: 0.5893697142601013\n",
            "Batch 96, Loss: 0.5839388370513916\n",
            "Batch 97, Loss: 0.24925237894058228\n",
            "Batch 98, Loss: 0.49889129400253296\n",
            "Batch 99, Loss: 0.6122201085090637\n",
            "Batch 100, Loss: 0.6053752899169922\n",
            "Batch 101, Loss: 0.4126845598220825\n",
            "Batch 102, Loss: 0.39010804891586304\n",
            "Batch 103, Loss: 0.35314100980758667\n",
            "Batch 104, Loss: 0.29687538743019104\n",
            "Batch 105, Loss: 0.2555789053440094\n",
            "Batch 106, Loss: 0.4480639100074768\n",
            "Batch 107, Loss: 0.5337544083595276\n",
            "Batch 108, Loss: 0.46983474493026733\n",
            "Batch 109, Loss: 0.3550798296928406\n",
            "Batch 110, Loss: 0.42390817403793335\n",
            "Batch 111, Loss: 0.48984476923942566\n",
            "Batch 112, Loss: 0.3801080286502838\n",
            "Batch 113, Loss: 0.4286228120326996\n",
            "Batch 114, Loss: 0.4211544692516327\n",
            "Batch 115, Loss: 0.2743387818336487\n",
            "Batch 116, Loss: 0.5426629185676575\n",
            "Batch 117, Loss: 0.4784734845161438\n",
            "Batch 118, Loss: 0.33715224266052246\n",
            "Batch 119, Loss: 0.41535133123397827\n",
            "Batch 120, Loss: 0.5373799800872803\n",
            "Batch 121, Loss: 0.4822160601615906\n",
            "Batch 122, Loss: 0.46492379903793335\n",
            "Batch 123, Loss: 0.2827826142311096\n",
            "Batch 124, Loss: 0.32260414958000183\n",
            "Batch 125, Loss: 0.4095146656036377\n",
            "Batch 126, Loss: 0.4289925694465637\n",
            "Batch 127, Loss: 0.28532105684280396\n",
            "Batch 128, Loss: 0.5682146549224854\n",
            "Batch 129, Loss: 0.1887156069278717\n",
            "Batch 130, Loss: 0.264065146446228\n",
            "Batch 131, Loss: 0.6060834527015686\n",
            "Batch 132, Loss: 0.42065054178237915\n",
            "Batch 133, Loss: 0.3310498297214508\n",
            "Batch 134, Loss: 0.4870645999908447\n",
            "Batch 135, Loss: 0.24778594076633453\n",
            "Batch 136, Loss: 0.4013761579990387\n",
            "Batch 137, Loss: 0.33011460304260254\n",
            "Batch 138, Loss: 0.4014204442501068\n",
            "Batch 139, Loss: 0.5215927958488464\n",
            "Batch 140, Loss: 0.43466585874557495\n",
            "Batch 141, Loss: 0.957336962223053\n",
            "Batch 142, Loss: 0.24828562140464783\n",
            "Batch 143, Loss: 0.5840514302253723\n",
            "Batch 144, Loss: 0.28650689125061035\n",
            "Batch 145, Loss: 0.4553408622741699\n",
            "Batch 146, Loss: 0.5196212530136108\n",
            "Batch 147, Loss: 0.6224319338798523\n",
            "Batch 148, Loss: 0.39842894673347473\n",
            "Batch 149, Loss: 0.4381777048110962\n",
            "Batch 150, Loss: 0.4136474132537842\n",
            "Batch 151, Loss: 0.5289629697799683\n",
            "Batch 152, Loss: 0.24943053722381592\n",
            "Batch 153, Loss: 0.5866256952285767\n",
            "Batch 154, Loss: 0.6608390808105469\n",
            "Batch 155, Loss: 0.37864458560943604\n",
            "Batch 156, Loss: 0.5101960897445679\n",
            "Batch 157, Loss: 0.34722965955734253\n",
            "Batch 158, Loss: 0.48044759035110474\n",
            "Batch 159, Loss: 0.4383006989955902\n",
            "Batch 160, Loss: 0.276214599609375\n",
            "Batch 161, Loss: 0.3135061264038086\n",
            "Batch 162, Loss: 0.2930269241333008\n",
            "Batch 163, Loss: 0.7747887969017029\n",
            "Batch 164, Loss: 0.49483758211135864\n",
            "Batch 165, Loss: 0.37072229385375977\n",
            "Batch 166, Loss: 0.42920705676078796\n",
            "Batch 167, Loss: 0.6687929034233093\n",
            "Batch 168, Loss: 0.5209596753120422\n",
            "Batch 169, Loss: 0.7773292660713196\n",
            "Batch 170, Loss: 0.4617428779602051\n",
            "Batch 171, Loss: 0.8414477705955505\n",
            "Batch 172, Loss: 0.774848222732544\n",
            "Batch 173, Loss: 0.49221038818359375\n",
            "Batch 174, Loss: 0.7334842681884766\n",
            "Batch 175, Loss: 0.422750324010849\n",
            "Batch 176, Loss: 0.2780833840370178\n",
            "Batch 177, Loss: 0.40031710267066956\n",
            "Batch 178, Loss: 0.7894906997680664\n",
            "Batch 179, Loss: 0.4507312774658203\n",
            "Batch 180, Loss: 0.646808922290802\n",
            "Batch 181, Loss: 0.5425214767456055\n",
            "Batch 182, Loss: 0.5870707035064697\n",
            "Batch 183, Loss: 0.8014129996299744\n",
            "Batch 184, Loss: 0.45415496826171875\n",
            "Batch 185, Loss: 0.5698453187942505\n",
            "Batch 186, Loss: 0.33863121271133423\n",
            "Batch 187, Loss: 0.4219491183757782\n",
            "Batch 188, Loss: 0.36872291564941406\n",
            "Batch 189, Loss: 0.2899833917617798\n",
            "Batch 190, Loss: 0.43770742416381836\n",
            "Batch 191, Loss: 0.6064324975013733\n",
            "Batch 192, Loss: 0.41086798906326294\n",
            "Batch 193, Loss: 0.6607319116592407\n",
            "Batch 194, Loss: 0.6850862503051758\n",
            "Batch 195, Loss: 0.569812536239624\n",
            "Batch 196, Loss: 0.4758901000022888\n",
            "Batch 197, Loss: 0.4646088182926178\n",
            "Batch 198, Loss: 0.477839857339859\n",
            "Batch 199, Loss: 0.7489109039306641\n",
            "Batch 200, Loss: 0.7814285755157471\n",
            "Batch 201, Loss: 0.38630086183547974\n",
            "Batch 202, Loss: 0.5405076742172241\n",
            "Batch 203, Loss: 0.637296199798584\n",
            "Batch 204, Loss: 0.4835914373397827\n",
            "Batch 205, Loss: 0.6676596403121948\n",
            "Batch 206, Loss: 0.45777884125709534\n",
            "Batch 207, Loss: 0.6052271127700806\n",
            "Batch 208, Loss: 0.3400600850582123\n",
            "Batch 209, Loss: 0.34186893701553345\n",
            "Batch 210, Loss: 0.4641414284706116\n",
            "Batch 211, Loss: 0.6356295347213745\n",
            "Batch 212, Loss: 0.6119117736816406\n",
            "Batch 213, Loss: 0.6854969263076782\n",
            "Batch 214, Loss: 0.3682149648666382\n",
            "Batch 215, Loss: 0.5815095901489258\n",
            "Batch 216, Loss: 0.6824387311935425\n",
            "Batch 217, Loss: 0.6091687083244324\n",
            "Batch 218, Loss: 0.27737128734588623\n",
            "Batch 219, Loss: 0.5456333756446838\n",
            "Batch 220, Loss: 0.8868453502655029\n",
            "Batch 221, Loss: 0.6141269207000732\n",
            "Batch 222, Loss: 0.3204059898853302\n",
            "Batch 223, Loss: 0.4658215045928955\n",
            "Batch 224, Loss: 0.4437985420227051\n",
            "Batch 225, Loss: 0.7777644395828247\n",
            "Batch 226, Loss: 0.40110713243484497\n",
            "Batch 227, Loss: 0.664157509803772\n",
            "Batch 228, Loss: 0.7287847995758057\n",
            "Batch 229, Loss: 0.6402976512908936\n",
            "Batch 230, Loss: 0.9064224362373352\n",
            "Epoch 30, Loss: 0.9064224362373352\n",
            "Batch 1, Loss: 0.27509504556655884\n",
            "Batch 2, Loss: 0.31466901302337646\n",
            "Batch 3, Loss: 0.2655351459980011\n",
            "Batch 4, Loss: 0.4405252933502197\n",
            "Batch 5, Loss: 0.6373947262763977\n",
            "Batch 6, Loss: 0.4381834864616394\n",
            "Batch 7, Loss: 0.5241925716400146\n",
            "Batch 8, Loss: 0.5914311408996582\n",
            "Batch 9, Loss: 0.5612766146659851\n",
            "Batch 10, Loss: 0.41771018505096436\n",
            "Batch 11, Loss: 0.28967660665512085\n",
            "Batch 12, Loss: 0.9010655283927917\n",
            "Batch 13, Loss: 0.4032075107097626\n",
            "Batch 14, Loss: 0.5217742919921875\n",
            "Batch 15, Loss: 0.5116127729415894\n",
            "Batch 16, Loss: 0.6537857055664062\n",
            "Batch 17, Loss: 0.37271976470947266\n",
            "Batch 18, Loss: 0.2986948490142822\n",
            "Batch 19, Loss: 0.3595207929611206\n",
            "Batch 20, Loss: 0.4872627258300781\n",
            "Batch 21, Loss: 0.2691202163696289\n",
            "Batch 22, Loss: 0.345480352640152\n",
            "Batch 23, Loss: 0.28685808181762695\n",
            "Batch 24, Loss: 0.6467302441596985\n",
            "Batch 25, Loss: 0.4108469486236572\n",
            "Batch 26, Loss: 0.6472072601318359\n",
            "Batch 27, Loss: 0.5065829753875732\n",
            "Batch 28, Loss: 0.3019176125526428\n",
            "Batch 29, Loss: 0.3896949887275696\n",
            "Batch 30, Loss: 0.403595507144928\n",
            "Batch 31, Loss: 0.38467615842819214\n",
            "Batch 32, Loss: 0.4438207447528839\n",
            "Batch 33, Loss: 0.3926282227039337\n",
            "Batch 34, Loss: 0.3554777204990387\n",
            "Batch 35, Loss: 0.2857053279876709\n",
            "Batch 36, Loss: 0.5080552101135254\n",
            "Batch 37, Loss: 0.33018922805786133\n",
            "Batch 38, Loss: 0.2978267967700958\n",
            "Batch 39, Loss: 0.42735785245895386\n",
            "Batch 40, Loss: 0.2585366666316986\n",
            "Batch 41, Loss: 0.2855744957923889\n",
            "Batch 42, Loss: 0.4315895140171051\n",
            "Batch 43, Loss: 0.2963375747203827\n",
            "Batch 44, Loss: 0.3138653337955475\n",
            "Batch 45, Loss: 0.29769742488861084\n",
            "Batch 46, Loss: 0.5166934132575989\n",
            "Batch 47, Loss: 0.5052074790000916\n",
            "Batch 48, Loss: 0.408286988735199\n",
            "Batch 49, Loss: 0.34458068013191223\n",
            "Batch 50, Loss: 0.5730220079421997\n",
            "Batch 51, Loss: 0.37097907066345215\n",
            "Batch 52, Loss: 0.18564113974571228\n",
            "Batch 53, Loss: 0.6805179119110107\n",
            "Batch 54, Loss: 0.35897010564804077\n",
            "Batch 55, Loss: 0.5179303288459778\n",
            "Batch 56, Loss: 0.4447409510612488\n",
            "Batch 57, Loss: 0.46507641673088074\n",
            "Batch 58, Loss: 0.4018002152442932\n",
            "Batch 59, Loss: 0.3372546136379242\n",
            "Batch 60, Loss: 0.24417656660079956\n",
            "Batch 61, Loss: 0.29857635498046875\n",
            "Batch 62, Loss: 0.200072780251503\n",
            "Batch 63, Loss: 0.41202089190483093\n",
            "Batch 64, Loss: 0.2631177306175232\n",
            "Batch 65, Loss: 0.2249225676059723\n",
            "Batch 66, Loss: 0.4730490744113922\n",
            "Batch 67, Loss: 0.3657316565513611\n",
            "Batch 68, Loss: 0.6150580048561096\n",
            "Batch 69, Loss: 0.454421728849411\n",
            "Batch 70, Loss: 0.464081346988678\n",
            "Batch 71, Loss: 0.5334577560424805\n",
            "Batch 72, Loss: 0.32560575008392334\n",
            "Batch 73, Loss: 0.5483527183532715\n",
            "Batch 74, Loss: 0.3101118505001068\n",
            "Batch 75, Loss: 0.49362462759017944\n",
            "Batch 76, Loss: 0.3767105042934418\n",
            "Batch 77, Loss: 0.47890543937683105\n",
            "Batch 78, Loss: 0.3451293706893921\n",
            "Batch 79, Loss: 0.45587751269340515\n",
            "Batch 80, Loss: 0.4230346977710724\n",
            "Batch 81, Loss: 0.4921610355377197\n",
            "Batch 82, Loss: 0.19166389107704163\n",
            "Batch 83, Loss: 0.28479528427124023\n",
            "Batch 84, Loss: 0.21197962760925293\n",
            "Batch 85, Loss: 0.5216875672340393\n",
            "Batch 86, Loss: 0.30706238746643066\n",
            "Batch 87, Loss: 0.370371550321579\n",
            "Batch 88, Loss: 0.3791520595550537\n",
            "Batch 89, Loss: 0.4456839859485626\n",
            "Batch 90, Loss: 0.28941795229911804\n",
            "Batch 91, Loss: 0.30816978216171265\n",
            "Batch 92, Loss: 0.33779647946357727\n",
            "Batch 93, Loss: 0.4082380533218384\n",
            "Batch 94, Loss: 0.2685510516166687\n",
            "Batch 95, Loss: 0.3523919880390167\n",
            "Batch 96, Loss: 0.5190050601959229\n",
            "Batch 97, Loss: 0.3160759210586548\n",
            "Batch 98, Loss: 0.6828619837760925\n",
            "Batch 99, Loss: 0.395272433757782\n",
            "Batch 100, Loss: 0.31067174673080444\n",
            "Batch 101, Loss: 0.3615514039993286\n",
            "Batch 102, Loss: 0.3289117217063904\n",
            "Batch 103, Loss: 0.4044768512248993\n",
            "Batch 104, Loss: 0.6905326843261719\n",
            "Batch 105, Loss: 0.608954906463623\n",
            "Batch 106, Loss: 0.43950486183166504\n",
            "Batch 107, Loss: 0.767190158367157\n",
            "Batch 108, Loss: 0.26603883504867554\n",
            "Batch 109, Loss: 0.3265250325202942\n",
            "Batch 110, Loss: 0.22414050996303558\n",
            "Batch 111, Loss: 0.31316110491752625\n",
            "Batch 112, Loss: 0.38298648595809937\n",
            "Batch 113, Loss: 0.41901299357414246\n",
            "Batch 114, Loss: 0.4057551622390747\n",
            "Batch 115, Loss: 0.5765542387962341\n",
            "Batch 116, Loss: 0.42102184891700745\n",
            "Batch 117, Loss: 0.625419020652771\n",
            "Batch 118, Loss: 0.7895259857177734\n",
            "Batch 119, Loss: 0.3918054699897766\n",
            "Batch 120, Loss: 0.30313658714294434\n",
            "Batch 121, Loss: 0.4003618061542511\n",
            "Batch 122, Loss: 0.24661865830421448\n",
            "Batch 123, Loss: 0.43957948684692383\n",
            "Batch 124, Loss: 0.23013955354690552\n",
            "Batch 125, Loss: 0.45375218987464905\n",
            "Batch 126, Loss: 0.30702024698257446\n",
            "Batch 127, Loss: 0.2903478145599365\n",
            "Batch 128, Loss: 0.4832096993923187\n",
            "Batch 129, Loss: 0.3130052983760834\n",
            "Batch 130, Loss: 0.3670514225959778\n",
            "Batch 131, Loss: 0.40355193614959717\n",
            "Batch 132, Loss: 0.553704559803009\n",
            "Batch 133, Loss: 0.35054445266723633\n",
            "Batch 134, Loss: 0.41661351919174194\n",
            "Batch 135, Loss: 0.3389270305633545\n",
            "Batch 136, Loss: 0.31366580724716187\n",
            "Batch 137, Loss: 0.6699113845825195\n",
            "Batch 138, Loss: 0.3123137652873993\n",
            "Batch 139, Loss: 0.32514917850494385\n",
            "Batch 140, Loss: 0.5583841800689697\n",
            "Batch 141, Loss: 0.597115695476532\n",
            "Batch 142, Loss: 0.4722733199596405\n",
            "Batch 143, Loss: 0.5768319368362427\n",
            "Batch 144, Loss: 0.2779594659805298\n",
            "Batch 145, Loss: 0.4144672155380249\n",
            "Batch 146, Loss: 0.34954386949539185\n",
            "Batch 147, Loss: 0.3913467824459076\n",
            "Batch 148, Loss: 0.598850429058075\n",
            "Batch 149, Loss: 0.29673251509666443\n",
            "Batch 150, Loss: 0.44940879940986633\n",
            "Batch 151, Loss: 0.5344793796539307\n",
            "Batch 152, Loss: 0.27364030480384827\n",
            "Batch 153, Loss: 0.4836798906326294\n",
            "Batch 154, Loss: 0.37432512640953064\n",
            "Batch 155, Loss: 0.33844882249832153\n",
            "Batch 156, Loss: 0.6406358480453491\n",
            "Batch 157, Loss: 0.4122908413410187\n",
            "Batch 158, Loss: 0.23875311017036438\n",
            "Batch 159, Loss: 0.32649070024490356\n",
            "Batch 160, Loss: 0.5469009280204773\n",
            "Batch 161, Loss: 0.2939126491546631\n",
            "Batch 162, Loss: 0.4065746068954468\n",
            "Batch 163, Loss: 0.34255215525627136\n",
            "Batch 164, Loss: 0.4519715905189514\n",
            "Batch 165, Loss: 0.6551368236541748\n",
            "Batch 166, Loss: 0.28592050075531006\n",
            "Batch 167, Loss: 0.46970510482788086\n",
            "Batch 168, Loss: 0.39651498198509216\n",
            "Batch 169, Loss: 0.274242103099823\n",
            "Batch 170, Loss: 0.3582409918308258\n",
            "Batch 171, Loss: 0.44993865489959717\n",
            "Batch 172, Loss: 0.46725451946258545\n",
            "Batch 173, Loss: 0.3586406707763672\n",
            "Batch 174, Loss: 0.6242318153381348\n",
            "Batch 175, Loss: 0.4676639139652252\n",
            "Batch 176, Loss: 0.35159242153167725\n",
            "Batch 177, Loss: 0.43600261211395264\n",
            "Batch 178, Loss: 0.816529393196106\n",
            "Batch 179, Loss: 0.43394795060157776\n",
            "Batch 180, Loss: 0.5305618047714233\n",
            "Batch 181, Loss: 0.3730546832084656\n",
            "Batch 182, Loss: 0.5171051621437073\n",
            "Batch 183, Loss: 0.28329354524612427\n",
            "Batch 184, Loss: 0.4699085056781769\n",
            "Batch 185, Loss: 0.5099033117294312\n",
            "Batch 186, Loss: 0.6342682242393494\n",
            "Batch 187, Loss: 0.4206457734107971\n",
            "Batch 188, Loss: 0.6216758489608765\n",
            "Batch 189, Loss: 0.47303229570388794\n",
            "Batch 190, Loss: 0.46528226137161255\n",
            "Batch 191, Loss: 0.2722620666027069\n",
            "Batch 192, Loss: 0.44850969314575195\n",
            "Batch 193, Loss: 0.2940084934234619\n",
            "Batch 194, Loss: 0.49254998564720154\n",
            "Batch 195, Loss: 0.3182949423789978\n",
            "Batch 196, Loss: 0.40191659331321716\n",
            "Batch 197, Loss: 0.44477033615112305\n",
            "Batch 198, Loss: 0.4363023638725281\n",
            "Batch 199, Loss: 0.507207989692688\n",
            "Batch 200, Loss: 0.30813416838645935\n",
            "Batch 201, Loss: 0.208862766623497\n",
            "Batch 202, Loss: 0.35200393199920654\n",
            "Batch 203, Loss: 0.5084314346313477\n",
            "Batch 204, Loss: 0.5601052045822144\n",
            "Batch 205, Loss: 0.47931528091430664\n",
            "Batch 206, Loss: 0.3861139714717865\n",
            "Batch 207, Loss: 0.40170010924339294\n",
            "Batch 208, Loss: 0.32880133390426636\n",
            "Batch 209, Loss: 0.7518666982650757\n",
            "Batch 210, Loss: 0.515810489654541\n",
            "Batch 211, Loss: 0.4168369174003601\n",
            "Batch 212, Loss: 0.48505228757858276\n",
            "Batch 213, Loss: 0.6363256573677063\n",
            "Batch 214, Loss: 0.5774160623550415\n",
            "Batch 215, Loss: 0.4589451253414154\n",
            "Batch 216, Loss: 0.5327273607254028\n",
            "Batch 217, Loss: 0.2959546446800232\n",
            "Batch 218, Loss: 0.697855532169342\n",
            "Batch 219, Loss: 0.49651578068733215\n",
            "Batch 220, Loss: 0.7051341533660889\n",
            "Batch 221, Loss: 0.45540961623191833\n",
            "Batch 222, Loss: 0.5183078050613403\n",
            "Batch 223, Loss: 0.4837317168712616\n",
            "Batch 224, Loss: 0.6450358629226685\n",
            "Batch 225, Loss: 0.29383355379104614\n",
            "Batch 226, Loss: 0.6644888520240784\n",
            "Batch 227, Loss: 0.31551143527030945\n",
            "Batch 228, Loss: 0.4607519805431366\n",
            "Batch 229, Loss: 0.45919737219810486\n",
            "Batch 230, Loss: 0.23428381979465485\n",
            "Epoch 31, Loss: 0.23428381979465485\n",
            "Batch 1, Loss: 0.22313255071640015\n",
            "Batch 2, Loss: 0.296739399433136\n",
            "Batch 3, Loss: 0.3001517653465271\n",
            "Batch 4, Loss: 0.26513150334358215\n",
            "Batch 5, Loss: 0.26997581124305725\n",
            "Batch 6, Loss: 0.18628577888011932\n",
            "Batch 7, Loss: 0.307648241519928\n",
            "Batch 8, Loss: 0.31020116806030273\n",
            "Batch 9, Loss: 0.29431748390197754\n",
            "Batch 10, Loss: 0.2527974247932434\n",
            "Batch 11, Loss: 0.3118608295917511\n",
            "Batch 12, Loss: 0.1721528321504593\n",
            "Batch 13, Loss: 0.24813146889209747\n",
            "Batch 14, Loss: 0.4640212059020996\n",
            "Batch 15, Loss: 0.1929529309272766\n",
            "Batch 16, Loss: 0.6898874640464783\n",
            "Batch 17, Loss: 0.2625950872898102\n",
            "Batch 18, Loss: 0.3148982524871826\n",
            "Batch 19, Loss: 0.1907051056623459\n",
            "Batch 20, Loss: 0.5067073106765747\n",
            "Batch 21, Loss: 0.3814941644668579\n",
            "Batch 22, Loss: 0.2987128496170044\n",
            "Batch 23, Loss: 0.35713136196136475\n",
            "Batch 24, Loss: 0.25872087478637695\n",
            "Batch 25, Loss: 0.4980452358722687\n",
            "Batch 26, Loss: 0.3555861711502075\n",
            "Batch 27, Loss: 0.44565361738204956\n",
            "Batch 28, Loss: 0.23859766125679016\n",
            "Batch 29, Loss: 0.20732749998569489\n",
            "Batch 30, Loss: 0.3859030604362488\n",
            "Batch 31, Loss: 0.274582177400589\n",
            "Batch 32, Loss: 0.21031126379966736\n",
            "Batch 33, Loss: 0.43614310026168823\n",
            "Batch 34, Loss: 0.19360068440437317\n",
            "Batch 35, Loss: 0.27151456475257874\n",
            "Batch 36, Loss: 0.6122031211853027\n",
            "Batch 37, Loss: 0.19619563221931458\n",
            "Batch 38, Loss: 0.4008316993713379\n",
            "Batch 39, Loss: 0.3099355697631836\n",
            "Batch 40, Loss: 0.311578631401062\n",
            "Batch 41, Loss: 0.18894420564174652\n",
            "Batch 42, Loss: 0.42254048585891724\n",
            "Batch 43, Loss: 0.305361270904541\n",
            "Batch 44, Loss: 0.18551582098007202\n",
            "Batch 45, Loss: 0.3596080243587494\n",
            "Batch 46, Loss: 0.21860572695732117\n",
            "Batch 47, Loss: 0.3878724277019501\n",
            "Batch 48, Loss: 0.33438587188720703\n",
            "Batch 49, Loss: 0.41147005558013916\n",
            "Batch 50, Loss: 0.1675080955028534\n",
            "Batch 51, Loss: 0.2747994661331177\n",
            "Batch 52, Loss: 0.2907823324203491\n",
            "Batch 53, Loss: 0.2947835326194763\n",
            "Batch 54, Loss: 0.4557914733886719\n",
            "Batch 55, Loss: 0.22517898678779602\n",
            "Batch 56, Loss: 0.44611209630966187\n",
            "Batch 57, Loss: 0.20357859134674072\n",
            "Batch 58, Loss: 0.5072551965713501\n",
            "Batch 59, Loss: 0.26358455419540405\n",
            "Batch 60, Loss: 0.38865792751312256\n",
            "Batch 61, Loss: 0.2639715075492859\n",
            "Batch 62, Loss: 0.19727525115013123\n",
            "Batch 63, Loss: 0.3938312828540802\n",
            "Batch 64, Loss: 0.32815518975257874\n",
            "Batch 65, Loss: 0.6080083847045898\n",
            "Batch 66, Loss: 0.29830676317214966\n",
            "Batch 67, Loss: 0.4074800908565521\n",
            "Batch 68, Loss: 0.27611827850341797\n",
            "Batch 69, Loss: 0.4238123595714569\n",
            "Batch 70, Loss: 0.2710825800895691\n",
            "Batch 71, Loss: 0.1666504293680191\n",
            "Batch 72, Loss: 0.2795259356498718\n",
            "Batch 73, Loss: 0.346208781003952\n",
            "Batch 74, Loss: 0.4486267566680908\n",
            "Batch 75, Loss: 0.40828096866607666\n",
            "Batch 76, Loss: 0.35376012325286865\n",
            "Batch 77, Loss: 0.623489499092102\n",
            "Batch 78, Loss: 0.31053152680397034\n",
            "Batch 79, Loss: 0.21281445026397705\n",
            "Batch 80, Loss: 0.23130103945732117\n",
            "Batch 81, Loss: 0.2840989828109741\n",
            "Batch 82, Loss: 0.3674139678478241\n",
            "Batch 83, Loss: 0.351572722196579\n",
            "Batch 84, Loss: 0.32669317722320557\n",
            "Batch 85, Loss: 0.3951647877693176\n",
            "Batch 86, Loss: 0.21143487095832825\n",
            "Batch 87, Loss: 0.3616221845149994\n",
            "Batch 88, Loss: 0.28083717823028564\n",
            "Batch 89, Loss: 0.31695282459259033\n",
            "Batch 90, Loss: 0.2352857142686844\n",
            "Batch 91, Loss: 0.49741822481155396\n",
            "Batch 92, Loss: 0.39329034090042114\n",
            "Batch 93, Loss: 0.3684970736503601\n",
            "Batch 94, Loss: 0.2698025107383728\n",
            "Batch 95, Loss: 0.16637492179870605\n",
            "Batch 96, Loss: 0.37550264596939087\n",
            "Batch 97, Loss: 0.2580634355545044\n",
            "Batch 98, Loss: 0.5535989999771118\n",
            "Batch 99, Loss: 0.43591636419296265\n",
            "Batch 100, Loss: 0.43133002519607544\n",
            "Batch 101, Loss: 0.3529789447784424\n",
            "Batch 102, Loss: 0.25928521156311035\n",
            "Batch 103, Loss: 0.33407747745513916\n",
            "Batch 104, Loss: 0.3688105642795563\n",
            "Batch 105, Loss: 0.546220064163208\n",
            "Batch 106, Loss: 0.38669532537460327\n",
            "Batch 107, Loss: 0.4110299050807953\n",
            "Batch 108, Loss: 0.292542427778244\n",
            "Batch 109, Loss: 0.23426321148872375\n",
            "Batch 110, Loss: 0.3712698221206665\n",
            "Batch 111, Loss: 0.41088923811912537\n",
            "Batch 112, Loss: 0.28587502241134644\n",
            "Batch 113, Loss: 0.35440781712532043\n",
            "Batch 114, Loss: 0.4263876974582672\n",
            "Batch 115, Loss: 0.28218477964401245\n",
            "Batch 116, Loss: 0.3634794354438782\n",
            "Batch 117, Loss: 0.2207924723625183\n",
            "Batch 118, Loss: 0.3924090564250946\n",
            "Batch 119, Loss: 0.2409314513206482\n",
            "Batch 120, Loss: 0.16581547260284424\n",
            "Batch 121, Loss: 0.3816399574279785\n",
            "Batch 122, Loss: 0.2602773904800415\n",
            "Batch 123, Loss: 0.2941891849040985\n",
            "Batch 124, Loss: 0.28717464208602905\n",
            "Batch 125, Loss: 0.3432239890098572\n",
            "Batch 126, Loss: 0.4353293776512146\n",
            "Batch 127, Loss: 0.2899612784385681\n",
            "Batch 128, Loss: 0.20875847339630127\n",
            "Batch 129, Loss: 0.4740731716156006\n",
            "Batch 130, Loss: 0.5311754941940308\n",
            "Batch 131, Loss: 0.39776086807250977\n",
            "Batch 132, Loss: 0.39699357748031616\n",
            "Batch 133, Loss: 0.4324939548969269\n",
            "Batch 134, Loss: 0.3954959809780121\n",
            "Batch 135, Loss: 0.43493029475212097\n",
            "Batch 136, Loss: 0.4749121069908142\n",
            "Batch 137, Loss: 0.193417489528656\n",
            "Batch 138, Loss: 0.209283709526062\n",
            "Batch 139, Loss: 0.2862991988658905\n",
            "Batch 140, Loss: 0.5160850286483765\n",
            "Batch 141, Loss: 0.27921104431152344\n",
            "Batch 142, Loss: 0.38889020681381226\n",
            "Batch 143, Loss: 0.3850138783454895\n",
            "Batch 144, Loss: 0.34621888399124146\n",
            "Batch 145, Loss: 0.4052431881427765\n",
            "Batch 146, Loss: 0.3351842164993286\n",
            "Batch 147, Loss: 0.33240699768066406\n",
            "Batch 148, Loss: 0.33985617756843567\n",
            "Batch 149, Loss: 0.42690396308898926\n",
            "Batch 150, Loss: 0.46557149291038513\n",
            "Batch 151, Loss: 0.5465050935745239\n",
            "Batch 152, Loss: 0.5109450817108154\n",
            "Batch 153, Loss: 0.26048147678375244\n",
            "Batch 154, Loss: 0.33283549547195435\n",
            "Batch 155, Loss: 0.312469482421875\n",
            "Batch 156, Loss: 0.4926271140575409\n",
            "Batch 157, Loss: 0.489838182926178\n",
            "Batch 158, Loss: 0.30228865146636963\n",
            "Batch 159, Loss: 0.5089360475540161\n",
            "Batch 160, Loss: 0.48722413182258606\n",
            "Batch 161, Loss: 0.424587607383728\n",
            "Batch 162, Loss: 0.3964512348175049\n",
            "Batch 163, Loss: 0.4517837166786194\n",
            "Batch 164, Loss: 0.3424187898635864\n",
            "Batch 165, Loss: 0.6506209373474121\n",
            "Batch 166, Loss: 0.44545072317123413\n",
            "Batch 167, Loss: 0.34618788957595825\n",
            "Batch 168, Loss: 0.4521353542804718\n",
            "Batch 169, Loss: 0.4077701270580292\n",
            "Batch 170, Loss: 0.4062355160713196\n",
            "Batch 171, Loss: 0.2576709985733032\n",
            "Batch 172, Loss: 0.487032949924469\n",
            "Batch 173, Loss: 0.34229278564453125\n",
            "Batch 174, Loss: 0.3697105944156647\n",
            "Batch 175, Loss: 0.4600565731525421\n",
            "Batch 176, Loss: 0.20219078660011292\n",
            "Batch 177, Loss: 0.29928892850875854\n",
            "Batch 178, Loss: 0.29816538095474243\n",
            "Batch 179, Loss: 0.35781964659690857\n",
            "Batch 180, Loss: 0.2251904308795929\n",
            "Batch 181, Loss: 0.4729086756706238\n",
            "Batch 182, Loss: 0.2914859354496002\n",
            "Batch 183, Loss: 0.3022846579551697\n",
            "Batch 184, Loss: 0.3515990972518921\n",
            "Batch 185, Loss: 0.4221218526363373\n",
            "Batch 186, Loss: 0.33096617460250854\n",
            "Batch 187, Loss: 0.2967143952846527\n",
            "Batch 188, Loss: 0.3630044162273407\n",
            "Batch 189, Loss: 0.3679812252521515\n",
            "Batch 190, Loss: 0.40846264362335205\n",
            "Batch 191, Loss: 0.18599531054496765\n",
            "Batch 192, Loss: 0.37827199697494507\n",
            "Batch 193, Loss: 0.22293098270893097\n",
            "Batch 194, Loss: 0.4408547878265381\n",
            "Batch 195, Loss: 0.3761215806007385\n",
            "Batch 196, Loss: 0.3843342363834381\n",
            "Batch 197, Loss: 0.18416573107242584\n",
            "Batch 198, Loss: 0.3863869607448578\n",
            "Batch 199, Loss: 0.6135944128036499\n",
            "Batch 200, Loss: 0.5793312788009644\n",
            "Batch 201, Loss: 0.4055166244506836\n",
            "Batch 202, Loss: 0.35439857840538025\n",
            "Batch 203, Loss: 0.4893057644367218\n",
            "Batch 204, Loss: 0.7196139693260193\n",
            "Batch 205, Loss: 0.3880784511566162\n",
            "Batch 206, Loss: 0.26719361543655396\n",
            "Batch 207, Loss: 0.38825780153274536\n",
            "Batch 208, Loss: 0.40226081013679504\n",
            "Batch 209, Loss: 0.4295197129249573\n",
            "Batch 210, Loss: 0.3678934872150421\n",
            "Batch 211, Loss: 0.24232107400894165\n",
            "Batch 212, Loss: 0.2461460679769516\n",
            "Batch 213, Loss: 0.450311541557312\n",
            "Batch 214, Loss: 0.43176549673080444\n",
            "Batch 215, Loss: 0.3243692219257355\n",
            "Batch 216, Loss: 0.25861185789108276\n",
            "Batch 217, Loss: 0.20903407037258148\n",
            "Batch 218, Loss: 0.39724260568618774\n",
            "Batch 219, Loss: 0.5045525431632996\n",
            "Batch 220, Loss: 0.38157790899276733\n",
            "Batch 221, Loss: 0.28673404455184937\n",
            "Batch 222, Loss: 0.43126869201660156\n",
            "Batch 223, Loss: 0.36961203813552856\n",
            "Batch 224, Loss: 0.30511239171028137\n",
            "Batch 225, Loss: 0.26684772968292236\n",
            "Batch 226, Loss: 0.42372381687164307\n",
            "Batch 227, Loss: 0.38144633173942566\n",
            "Batch 228, Loss: 0.3175817131996155\n",
            "Batch 229, Loss: 0.2951321005821228\n",
            "Batch 230, Loss: 0.2630064785480499\n",
            "Epoch 32, Loss: 0.2630064785480499\n",
            "Batch 1, Loss: 0.22729915380477905\n",
            "Batch 2, Loss: 0.22739039361476898\n",
            "Batch 3, Loss: 0.23639969527721405\n",
            "Batch 4, Loss: 0.26319679617881775\n",
            "Batch 5, Loss: 0.20055228471755981\n",
            "Batch 6, Loss: 0.2614607512950897\n",
            "Batch 7, Loss: 0.3295423984527588\n",
            "Batch 8, Loss: 0.2349393218755722\n",
            "Batch 9, Loss: 0.147180438041687\n",
            "Batch 10, Loss: 0.29520872235298157\n",
            "Batch 11, Loss: 0.19091948866844177\n",
            "Batch 12, Loss: 0.3426114022731781\n",
            "Batch 13, Loss: 0.1892605423927307\n",
            "Batch 14, Loss: 0.31891295313835144\n",
            "Batch 15, Loss: 0.2109813243150711\n",
            "Batch 16, Loss: 0.2394217848777771\n",
            "Batch 17, Loss: 0.3502596914768219\n",
            "Batch 18, Loss: 0.2740558981895447\n",
            "Batch 19, Loss: 0.24262797832489014\n",
            "Batch 20, Loss: 0.2220766842365265\n",
            "Batch 21, Loss: 0.28437021374702454\n",
            "Batch 22, Loss: 0.27546170353889465\n",
            "Batch 23, Loss: 0.19681648910045624\n",
            "Batch 24, Loss: 0.32306063175201416\n",
            "Batch 25, Loss: 0.23976321518421173\n",
            "Batch 26, Loss: 0.22647857666015625\n",
            "Batch 27, Loss: 0.23656868934631348\n",
            "Batch 28, Loss: 0.3071775734424591\n",
            "Batch 29, Loss: 0.311322420835495\n",
            "Batch 30, Loss: 0.2941877543926239\n",
            "Batch 31, Loss: 0.22677616775035858\n",
            "Batch 32, Loss: 0.18628209829330444\n",
            "Batch 33, Loss: 0.31295281648635864\n",
            "Batch 34, Loss: 0.17824015021324158\n",
            "Batch 35, Loss: 0.4098189175128937\n",
            "Batch 36, Loss: 0.20819151401519775\n",
            "Batch 37, Loss: 0.21950198709964752\n",
            "Batch 38, Loss: 0.40533044934272766\n",
            "Batch 39, Loss: 0.17753928899765015\n",
            "Batch 40, Loss: 0.14103692770004272\n",
            "Batch 41, Loss: 0.31513506174087524\n",
            "Batch 42, Loss: 0.21610182523727417\n",
            "Batch 43, Loss: 0.23897962272167206\n",
            "Batch 44, Loss: 0.29162392020225525\n",
            "Batch 45, Loss: 0.18854011595249176\n",
            "Batch 46, Loss: 0.3299987316131592\n",
            "Batch 47, Loss: 0.26084214448928833\n",
            "Batch 48, Loss: 0.20563992857933044\n",
            "Batch 49, Loss: 0.17075683176517487\n",
            "Batch 50, Loss: 0.15943297743797302\n",
            "Batch 51, Loss: 0.2374783307313919\n",
            "Batch 52, Loss: 0.29287439584732056\n",
            "Batch 53, Loss: 0.3091837167739868\n",
            "Batch 54, Loss: 0.4000700116157532\n",
            "Batch 55, Loss: 0.20658493041992188\n",
            "Batch 56, Loss: 0.1985689401626587\n",
            "Batch 57, Loss: 0.2768056392669678\n",
            "Batch 58, Loss: 0.3120957016944885\n",
            "Batch 59, Loss: 0.3090628385543823\n",
            "Batch 60, Loss: 0.18965531885623932\n",
            "Batch 61, Loss: 0.26160675287246704\n",
            "Batch 62, Loss: 0.3806003928184509\n",
            "Batch 63, Loss: 0.2816183269023895\n",
            "Batch 64, Loss: 0.3304072320461273\n",
            "Batch 65, Loss: 0.2398616224527359\n",
            "Batch 66, Loss: 0.21593403816223145\n",
            "Batch 67, Loss: 0.1872902810573578\n",
            "Batch 68, Loss: 0.2815510630607605\n",
            "Batch 69, Loss: 0.1742398887872696\n",
            "Batch 70, Loss: 0.38307446241378784\n",
            "Batch 71, Loss: 0.3117639124393463\n",
            "Batch 72, Loss: 0.19719024002552032\n",
            "Batch 73, Loss: 0.22883865237236023\n",
            "Batch 74, Loss: 0.2724936604499817\n",
            "Batch 75, Loss: 0.19836895167827606\n",
            "Batch 76, Loss: 0.17562773823738098\n",
            "Batch 77, Loss: 0.336425244808197\n",
            "Batch 78, Loss: 0.3505321145057678\n",
            "Batch 79, Loss: 0.18240058422088623\n",
            "Batch 80, Loss: 0.26995527744293213\n",
            "Batch 81, Loss: 0.2292882353067398\n",
            "Batch 82, Loss: 0.16253119707107544\n",
            "Batch 83, Loss: 0.34167900681495667\n",
            "Batch 84, Loss: 0.4289526343345642\n",
            "Batch 85, Loss: 0.3107757270336151\n",
            "Batch 86, Loss: 0.18747496604919434\n",
            "Batch 87, Loss: 0.3105921149253845\n",
            "Batch 88, Loss: 0.18019746243953705\n",
            "Batch 89, Loss: 0.2030354142189026\n",
            "Batch 90, Loss: 0.23728595674037933\n",
            "Batch 91, Loss: 0.24983495473861694\n",
            "Batch 92, Loss: 0.2833349406719208\n",
            "Batch 93, Loss: 0.2373480200767517\n",
            "Batch 94, Loss: 0.26360413432121277\n",
            "Batch 95, Loss: 0.20168322324752808\n",
            "Batch 96, Loss: 0.2149096131324768\n",
            "Batch 97, Loss: 0.318682998418808\n",
            "Batch 98, Loss: 0.21315832436084747\n",
            "Batch 99, Loss: 0.24323464930057526\n",
            "Batch 100, Loss: 0.20213088393211365\n",
            "Batch 101, Loss: 0.20888575911521912\n",
            "Batch 102, Loss: 0.31124216318130493\n",
            "Batch 103, Loss: 0.23670679330825806\n",
            "Batch 104, Loss: 0.3331676125526428\n",
            "Batch 105, Loss: 0.28910133242607117\n",
            "Batch 106, Loss: 0.2770549952983856\n",
            "Batch 107, Loss: 0.24458760023117065\n",
            "Batch 108, Loss: 0.3999179005622864\n",
            "Batch 109, Loss: 0.38191255927085876\n",
            "Batch 110, Loss: 0.24089202284812927\n",
            "Batch 111, Loss: 0.24869506061077118\n",
            "Batch 112, Loss: 0.2418186366558075\n",
            "Batch 113, Loss: 0.2031698226928711\n",
            "Batch 114, Loss: 0.4146784842014313\n",
            "Batch 115, Loss: 0.22916588187217712\n",
            "Batch 116, Loss: 0.3071393370628357\n",
            "Batch 117, Loss: 0.28319501876831055\n",
            "Batch 118, Loss: 0.4673394560813904\n",
            "Batch 119, Loss: 0.2730861008167267\n",
            "Batch 120, Loss: 0.17206571996212006\n",
            "Batch 121, Loss: 0.2966177761554718\n",
            "Batch 122, Loss: 0.19305749237537384\n",
            "Batch 123, Loss: 0.2231377363204956\n",
            "Batch 124, Loss: 0.13789613544940948\n",
            "Batch 125, Loss: 0.2677399218082428\n",
            "Batch 126, Loss: 0.3644506633281708\n",
            "Batch 127, Loss: 0.30782467126846313\n",
            "Batch 128, Loss: 0.2652396261692047\n",
            "Batch 129, Loss: 0.4664769768714905\n",
            "Batch 130, Loss: 0.39152228832244873\n",
            "Batch 131, Loss: 0.34433048963546753\n",
            "Batch 132, Loss: 0.21347945928573608\n",
            "Batch 133, Loss: 0.2287922352552414\n",
            "Batch 134, Loss: 0.17734506726264954\n",
            "Batch 135, Loss: 0.20395143330097198\n",
            "Batch 136, Loss: 0.41504091024398804\n",
            "Batch 137, Loss: 0.6077554225921631\n",
            "Batch 138, Loss: 0.5017155408859253\n",
            "Batch 139, Loss: 0.47038063406944275\n",
            "Batch 140, Loss: 0.513688862323761\n",
            "Batch 141, Loss: 0.22617784142494202\n",
            "Batch 142, Loss: 0.2623226046562195\n",
            "Batch 143, Loss: 0.18370193243026733\n",
            "Batch 144, Loss: 0.3399387300014496\n",
            "Batch 145, Loss: 0.24342645704746246\n",
            "Batch 146, Loss: 0.43163740634918213\n",
            "Batch 147, Loss: 0.36257681250572205\n",
            "Batch 148, Loss: 0.3087036609649658\n",
            "Batch 149, Loss: 0.4015825390815735\n",
            "Batch 150, Loss: 0.3444406986236572\n",
            "Batch 151, Loss: 0.20944800972938538\n",
            "Batch 152, Loss: 0.27207422256469727\n",
            "Batch 153, Loss: 0.5698545575141907\n",
            "Batch 154, Loss: 0.3120920956134796\n",
            "Batch 155, Loss: 0.47834286093711853\n",
            "Batch 156, Loss: 0.26009097695350647\n",
            "Batch 157, Loss: 0.1725499927997589\n",
            "Batch 158, Loss: 0.3304692506790161\n",
            "Batch 159, Loss: 0.20314103364944458\n",
            "Batch 160, Loss: 0.39449477195739746\n",
            "Batch 161, Loss: 0.31734901666641235\n",
            "Batch 162, Loss: 0.27639061212539673\n",
            "Batch 163, Loss: 0.27808836102485657\n",
            "Batch 164, Loss: 0.2726967930793762\n",
            "Batch 165, Loss: 0.35891348123550415\n",
            "Batch 166, Loss: 0.27292105555534363\n",
            "Batch 167, Loss: 0.5748639106750488\n",
            "Batch 168, Loss: 0.414253830909729\n",
            "Batch 169, Loss: 0.560357928276062\n",
            "Batch 170, Loss: 0.3728558421134949\n",
            "Batch 171, Loss: 0.2606844902038574\n",
            "Batch 172, Loss: 0.2843322157859802\n",
            "Batch 173, Loss: 0.3142407536506653\n",
            "Batch 174, Loss: 0.41311830282211304\n",
            "Batch 175, Loss: 0.4443680942058563\n",
            "Batch 176, Loss: 0.4046356678009033\n",
            "Batch 177, Loss: 0.19287532567977905\n",
            "Batch 178, Loss: 0.43086525797843933\n",
            "Batch 179, Loss: 0.35934507846832275\n",
            "Batch 180, Loss: 0.27602821588516235\n",
            "Batch 181, Loss: 0.3693888783454895\n",
            "Batch 182, Loss: 0.20994505286216736\n",
            "Batch 183, Loss: 0.33492976427078247\n",
            "Batch 184, Loss: 0.3938186764717102\n",
            "Batch 185, Loss: 0.4011206030845642\n",
            "Batch 186, Loss: 0.2945575714111328\n",
            "Batch 187, Loss: 0.3055233657360077\n",
            "Batch 188, Loss: 0.6795938014984131\n",
            "Batch 189, Loss: 0.26746445894241333\n",
            "Batch 190, Loss: 0.33817562460899353\n",
            "Batch 191, Loss: 0.39206281304359436\n",
            "Batch 192, Loss: 0.22502946853637695\n",
            "Batch 193, Loss: 0.4289049506187439\n",
            "Batch 194, Loss: 0.3892274498939514\n",
            "Batch 195, Loss: 0.46075963973999023\n",
            "Batch 196, Loss: 0.37344515323638916\n",
            "Batch 197, Loss: 0.2789314091205597\n",
            "Batch 198, Loss: 0.35289445519447327\n",
            "Batch 199, Loss: 0.3719831705093384\n",
            "Batch 200, Loss: 0.4260749816894531\n",
            "Batch 201, Loss: 0.32336199283599854\n",
            "Batch 202, Loss: 0.1943376362323761\n",
            "Batch 203, Loss: 0.5021811127662659\n",
            "Batch 204, Loss: 0.3477979004383087\n",
            "Batch 205, Loss: 0.5901166200637817\n",
            "Batch 206, Loss: 0.3915417492389679\n",
            "Batch 207, Loss: 0.3784026801586151\n",
            "Batch 208, Loss: 0.3570866286754608\n",
            "Batch 209, Loss: 0.2827520966529846\n",
            "Batch 210, Loss: 0.30500614643096924\n",
            "Batch 211, Loss: 0.5304303169250488\n",
            "Batch 212, Loss: 0.6048463582992554\n",
            "Batch 213, Loss: 0.5356964468955994\n",
            "Batch 214, Loss: 0.16918732225894928\n",
            "Batch 215, Loss: 0.4245675802230835\n",
            "Batch 216, Loss: 0.35064780712127686\n",
            "Batch 217, Loss: 0.843498170375824\n",
            "Batch 218, Loss: 0.44287869334220886\n",
            "Batch 219, Loss: 0.30314773321151733\n",
            "Batch 220, Loss: 0.3898724615573883\n",
            "Batch 221, Loss: 0.244308203458786\n",
            "Batch 222, Loss: 0.36591029167175293\n",
            "Batch 223, Loss: 0.5197931528091431\n",
            "Batch 224, Loss: 0.4746386706829071\n",
            "Batch 225, Loss: 0.45176374912261963\n",
            "Batch 226, Loss: 0.30322569608688354\n",
            "Batch 227, Loss: 0.4456956386566162\n",
            "Batch 228, Loss: 0.38643762469291687\n",
            "Batch 229, Loss: 0.6421496868133545\n",
            "Batch 230, Loss: 0.255331426858902\n",
            "Epoch 33, Loss: 0.255331426858902\n",
            "Batch 1, Loss: 0.1507340967655182\n",
            "Batch 2, Loss: 0.24376940727233887\n",
            "Batch 3, Loss: 0.18609502911567688\n",
            "Batch 4, Loss: 0.20647567510604858\n",
            "Batch 5, Loss: 0.25764745473861694\n",
            "Batch 6, Loss: 0.6030626893043518\n",
            "Batch 7, Loss: 0.2525607943534851\n",
            "Batch 8, Loss: 0.18774940073490143\n",
            "Batch 9, Loss: 0.12503577768802643\n",
            "Batch 10, Loss: 0.4277336597442627\n",
            "Batch 11, Loss: 0.2367877960205078\n",
            "Batch 12, Loss: 0.348787784576416\n",
            "Batch 13, Loss: 0.5749744176864624\n",
            "Batch 14, Loss: 0.3210732638835907\n",
            "Batch 15, Loss: 0.2947031259536743\n",
            "Batch 16, Loss: 0.28645411133766174\n",
            "Batch 17, Loss: 0.17346778512001038\n",
            "Batch 18, Loss: 0.35499364137649536\n",
            "Batch 19, Loss: 0.3605654835700989\n",
            "Batch 20, Loss: 0.19851639866828918\n",
            "Batch 21, Loss: 0.3432595729827881\n",
            "Batch 22, Loss: 0.32656505703926086\n",
            "Batch 23, Loss: 0.47924476861953735\n",
            "Batch 24, Loss: 0.22718341648578644\n",
            "Batch 25, Loss: 0.31165364384651184\n",
            "Batch 26, Loss: 0.21902994811534882\n",
            "Batch 27, Loss: 0.24887122213840485\n",
            "Batch 28, Loss: 0.35584557056427\n",
            "Batch 29, Loss: 0.35699957609176636\n",
            "Batch 30, Loss: 0.4625696837902069\n",
            "Batch 31, Loss: 0.2303263247013092\n",
            "Batch 32, Loss: 0.27799516916275024\n",
            "Batch 33, Loss: 0.3055964708328247\n",
            "Batch 34, Loss: 0.3960588276386261\n",
            "Batch 35, Loss: 0.29655537009239197\n",
            "Batch 36, Loss: 0.2197180986404419\n",
            "Batch 37, Loss: 0.3557124137878418\n",
            "Batch 38, Loss: 0.1860610842704773\n",
            "Batch 39, Loss: 0.12742674350738525\n",
            "Batch 40, Loss: 0.30325257778167725\n",
            "Batch 41, Loss: 0.2739487886428833\n",
            "Batch 42, Loss: 0.16740772128105164\n",
            "Batch 43, Loss: 0.10441464930772781\n",
            "Batch 44, Loss: 0.243287593126297\n",
            "Batch 45, Loss: 0.284295916557312\n",
            "Batch 46, Loss: 0.32579922676086426\n",
            "Batch 47, Loss: 0.1979997456073761\n",
            "Batch 48, Loss: 0.29013121128082275\n",
            "Batch 49, Loss: 0.2688736319541931\n",
            "Batch 50, Loss: 0.18693190813064575\n",
            "Batch 51, Loss: 0.4055227041244507\n",
            "Batch 52, Loss: 0.48237019777297974\n",
            "Batch 53, Loss: 0.2539113759994507\n",
            "Batch 54, Loss: 0.21739256381988525\n",
            "Batch 55, Loss: 0.38354822993278503\n",
            "Batch 56, Loss: 0.30969706177711487\n",
            "Batch 57, Loss: 0.2634890675544739\n",
            "Batch 58, Loss: 0.2620224952697754\n",
            "Batch 59, Loss: 0.28104323148727417\n",
            "Batch 60, Loss: 0.2376052439212799\n",
            "Batch 61, Loss: 0.24870002269744873\n",
            "Batch 62, Loss: 0.2534664571285248\n",
            "Batch 63, Loss: 0.28754204511642456\n",
            "Batch 64, Loss: 0.25555741786956787\n",
            "Batch 65, Loss: 0.2702372372150421\n",
            "Batch 66, Loss: 0.5053173303604126\n",
            "Batch 67, Loss: 0.2998073995113373\n",
            "Batch 68, Loss: 0.3081640601158142\n",
            "Batch 69, Loss: 0.29888716340065\n",
            "Batch 70, Loss: 0.2802129089832306\n",
            "Batch 71, Loss: 0.22266919910907745\n",
            "Batch 72, Loss: 0.23213639855384827\n",
            "Batch 73, Loss: 0.1871163249015808\n",
            "Batch 74, Loss: 0.49001896381378174\n",
            "Batch 75, Loss: 0.4075521230697632\n",
            "Batch 76, Loss: 0.495257705450058\n",
            "Batch 77, Loss: 0.28328216075897217\n",
            "Batch 78, Loss: 0.45011383295059204\n",
            "Batch 79, Loss: 0.1796705573797226\n",
            "Batch 80, Loss: 0.23511669039726257\n",
            "Batch 81, Loss: 0.206345796585083\n",
            "Batch 82, Loss: 0.37668097019195557\n",
            "Batch 83, Loss: 0.24450621008872986\n",
            "Batch 84, Loss: 0.24383291602134705\n",
            "Batch 85, Loss: 0.2993607521057129\n",
            "Batch 86, Loss: 0.309437096118927\n",
            "Batch 87, Loss: 0.2921142578125\n",
            "Batch 88, Loss: 0.2376905083656311\n",
            "Batch 89, Loss: 0.247327521443367\n",
            "Batch 90, Loss: 0.2650865912437439\n",
            "Batch 91, Loss: 0.3184971511363983\n",
            "Batch 92, Loss: 0.2134566605091095\n",
            "Batch 93, Loss: 0.3483312129974365\n",
            "Batch 94, Loss: 0.3819441795349121\n",
            "Batch 95, Loss: 0.36529242992401123\n",
            "Batch 96, Loss: 0.2739745080471039\n",
            "Batch 97, Loss: 0.34608274698257446\n",
            "Batch 98, Loss: 0.5156480669975281\n",
            "Batch 99, Loss: 0.2917863726615906\n",
            "Batch 100, Loss: 0.19100242853164673\n",
            "Batch 101, Loss: 0.34862062335014343\n",
            "Batch 102, Loss: 0.17185167968273163\n",
            "Batch 103, Loss: 0.2447558343410492\n",
            "Batch 104, Loss: 0.22271135449409485\n",
            "Batch 105, Loss: 0.24269798398017883\n",
            "Batch 106, Loss: 0.27536195516586304\n",
            "Batch 107, Loss: 0.2946628928184509\n",
            "Batch 108, Loss: 0.3561006784439087\n",
            "Batch 109, Loss: 0.1502031683921814\n",
            "Batch 110, Loss: 0.26703810691833496\n",
            "Batch 111, Loss: 0.2223891019821167\n",
            "Batch 112, Loss: 0.3405197262763977\n",
            "Batch 113, Loss: 0.16251489520072937\n",
            "Batch 114, Loss: 0.1716003119945526\n",
            "Batch 115, Loss: 0.24280908703804016\n",
            "Batch 116, Loss: 0.15085062384605408\n",
            "Batch 117, Loss: 0.2464383840560913\n",
            "Batch 118, Loss: 0.3510296940803528\n",
            "Batch 119, Loss: 0.40408360958099365\n",
            "Batch 120, Loss: 0.3634588122367859\n",
            "Batch 121, Loss: 0.4074315130710602\n",
            "Batch 122, Loss: 0.24916675686836243\n",
            "Batch 123, Loss: 0.2949908971786499\n",
            "Batch 124, Loss: 0.5411474704742432\n",
            "Batch 125, Loss: 0.23545707762241364\n",
            "Batch 126, Loss: 0.25179123878479004\n",
            "Batch 127, Loss: 0.3204783499240875\n",
            "Batch 128, Loss: 0.24795466661453247\n",
            "Batch 129, Loss: 0.2797321081161499\n",
            "Batch 130, Loss: 0.40520185232162476\n",
            "Batch 131, Loss: 0.29622188210487366\n",
            "Batch 132, Loss: 0.42373716831207275\n",
            "Batch 133, Loss: 0.37264829874038696\n",
            "Batch 134, Loss: 0.3249269127845764\n",
            "Batch 135, Loss: 0.33320116996765137\n",
            "Batch 136, Loss: 0.3295908570289612\n",
            "Batch 137, Loss: 0.45022231340408325\n",
            "Batch 138, Loss: 0.31191587448120117\n",
            "Batch 139, Loss: 0.27231740951538086\n",
            "Batch 140, Loss: 0.549468994140625\n",
            "Batch 141, Loss: 0.4650672972202301\n",
            "Batch 142, Loss: 0.38622626662254333\n",
            "Batch 143, Loss: 0.3540589511394501\n",
            "Batch 144, Loss: 0.3485506772994995\n",
            "Batch 145, Loss: 0.29687660932540894\n",
            "Batch 146, Loss: 0.19802403450012207\n",
            "Batch 147, Loss: 0.3082168698310852\n",
            "Batch 148, Loss: 0.5144438743591309\n",
            "Batch 149, Loss: 0.26789000630378723\n",
            "Batch 150, Loss: 0.2678941488265991\n",
            "Batch 151, Loss: 0.4774819612503052\n",
            "Batch 152, Loss: 0.2671806812286377\n",
            "Batch 153, Loss: 0.27810192108154297\n",
            "Batch 154, Loss: 0.22392569482326508\n",
            "Batch 155, Loss: 0.2687819004058838\n",
            "Batch 156, Loss: 0.2939353585243225\n",
            "Batch 157, Loss: 0.21900323033332825\n",
            "Batch 158, Loss: 0.3523111939430237\n",
            "Batch 159, Loss: 0.3899637460708618\n",
            "Batch 160, Loss: 0.3777254819869995\n",
            "Batch 161, Loss: 0.24406656622886658\n",
            "Batch 162, Loss: 0.4985416531562805\n",
            "Batch 163, Loss: 0.27647167444229126\n",
            "Batch 164, Loss: 0.41393744945526123\n",
            "Batch 165, Loss: 0.14762452244758606\n",
            "Batch 166, Loss: 0.4999403655529022\n",
            "Batch 167, Loss: 0.20177002251148224\n",
            "Batch 168, Loss: 0.40899044275283813\n",
            "Batch 169, Loss: 0.2835380733013153\n",
            "Batch 170, Loss: 0.3636879324913025\n",
            "Batch 171, Loss: 0.3709557354450226\n",
            "Batch 172, Loss: 0.47189468145370483\n",
            "Batch 173, Loss: 0.28729504346847534\n",
            "Batch 174, Loss: 0.27376705408096313\n",
            "Batch 175, Loss: 0.27110040187835693\n",
            "Batch 176, Loss: 0.40673887729644775\n",
            "Batch 177, Loss: 0.3860909938812256\n",
            "Batch 178, Loss: 0.28986871242523193\n",
            "Batch 179, Loss: 0.3589756488800049\n",
            "Batch 180, Loss: 0.401332288980484\n",
            "Batch 181, Loss: 0.44201040267944336\n",
            "Batch 182, Loss: 0.22691042721271515\n",
            "Batch 183, Loss: 0.559967041015625\n",
            "Batch 184, Loss: 0.3829559087753296\n",
            "Batch 185, Loss: 0.3963314890861511\n",
            "Batch 186, Loss: 0.3536950945854187\n",
            "Batch 187, Loss: 0.33064091205596924\n",
            "Batch 188, Loss: 0.20797722041606903\n",
            "Batch 189, Loss: 0.25042325258255005\n",
            "Batch 190, Loss: 0.2888031601905823\n",
            "Batch 191, Loss: 0.4790894389152527\n",
            "Batch 192, Loss: 0.28461408615112305\n",
            "Batch 193, Loss: 0.35432547330856323\n",
            "Batch 194, Loss: 0.3173237442970276\n",
            "Batch 195, Loss: 0.3975120782852173\n",
            "Batch 196, Loss: 0.20783841609954834\n",
            "Batch 197, Loss: 0.29088252782821655\n",
            "Batch 198, Loss: 0.17979669570922852\n",
            "Batch 199, Loss: 0.25273263454437256\n",
            "Batch 200, Loss: 0.26989197731018066\n",
            "Batch 201, Loss: 0.3447023630142212\n",
            "Batch 202, Loss: 0.34138426184654236\n",
            "Batch 203, Loss: 0.3060930371284485\n",
            "Batch 204, Loss: 0.5277720093727112\n",
            "Batch 205, Loss: 0.6899784803390503\n",
            "Batch 206, Loss: 0.2522411644458771\n",
            "Batch 207, Loss: 0.5269289016723633\n",
            "Batch 208, Loss: 0.40223461389541626\n",
            "Batch 209, Loss: 0.3041488826274872\n",
            "Batch 210, Loss: 0.42816877365112305\n",
            "Batch 211, Loss: 0.3695412576198578\n",
            "Batch 212, Loss: 0.24966800212860107\n",
            "Batch 213, Loss: 0.25871044397354126\n",
            "Batch 214, Loss: 0.4565203785896301\n",
            "Batch 215, Loss: 0.33330264687538147\n",
            "Batch 216, Loss: 0.3368280827999115\n",
            "Batch 217, Loss: 0.5012568235397339\n",
            "Batch 218, Loss: 0.3088521361351013\n",
            "Batch 219, Loss: 0.5253084897994995\n",
            "Batch 220, Loss: 0.25613901019096375\n",
            "Batch 221, Loss: 0.3211714029312134\n",
            "Batch 222, Loss: 0.32593485713005066\n",
            "Batch 223, Loss: 0.2222379744052887\n",
            "Batch 224, Loss: 0.3530493378639221\n",
            "Batch 225, Loss: 0.3549732267856598\n",
            "Batch 226, Loss: 0.33598828315734863\n",
            "Batch 227, Loss: 0.5513930320739746\n",
            "Batch 228, Loss: 0.31929320096969604\n",
            "Batch 229, Loss: 0.46037453413009644\n",
            "Batch 230, Loss: 0.3018099367618561\n",
            "Epoch 34, Loss: 0.3018099367618561\n",
            "Batch 1, Loss: 0.1906173825263977\n",
            "Batch 2, Loss: 0.16348589956760406\n",
            "Batch 3, Loss: 0.16617175936698914\n",
            "Batch 4, Loss: 0.24823342263698578\n",
            "Batch 5, Loss: 0.16338282823562622\n",
            "Batch 6, Loss: 0.13355673849582672\n",
            "Batch 7, Loss: 0.19660696387290955\n",
            "Batch 8, Loss: 0.46408170461654663\n",
            "Batch 9, Loss: 0.20047904551029205\n",
            "Batch 10, Loss: 0.2672964930534363\n",
            "Batch 11, Loss: 0.23078042268753052\n",
            "Batch 12, Loss: 0.13596157729625702\n",
            "Batch 13, Loss: 0.29936450719833374\n",
            "Batch 14, Loss: 0.23492711782455444\n",
            "Batch 15, Loss: 0.20203286409378052\n",
            "Batch 16, Loss: 0.46245795488357544\n",
            "Batch 17, Loss: 0.15695667266845703\n",
            "Batch 18, Loss: 0.1511770486831665\n",
            "Batch 19, Loss: 0.14782078564167023\n",
            "Batch 20, Loss: 0.30649662017822266\n",
            "Batch 21, Loss: 0.21570318937301636\n",
            "Batch 22, Loss: 0.2643775939941406\n",
            "Batch 23, Loss: 0.17028534412384033\n",
            "Batch 24, Loss: 0.16567319631576538\n",
            "Batch 25, Loss: 0.3526962995529175\n",
            "Batch 26, Loss: 0.24872925877571106\n",
            "Batch 27, Loss: 0.3819773495197296\n",
            "Batch 28, Loss: 0.18750862777233124\n",
            "Batch 29, Loss: 0.3187783658504486\n",
            "Batch 30, Loss: 0.37243717908859253\n",
            "Batch 31, Loss: 0.20805227756500244\n",
            "Batch 32, Loss: 0.15733876824378967\n",
            "Batch 33, Loss: 0.303459495306015\n",
            "Batch 34, Loss: 0.19538551568984985\n",
            "Batch 35, Loss: 0.31374984979629517\n",
            "Batch 36, Loss: 0.2177981436252594\n",
            "Batch 37, Loss: 0.32515040040016174\n",
            "Batch 38, Loss: 0.21873196959495544\n",
            "Batch 39, Loss: 0.17013096809387207\n",
            "Batch 40, Loss: 0.3289579153060913\n",
            "Batch 41, Loss: 0.14721891283988953\n",
            "Batch 42, Loss: 0.44256460666656494\n",
            "Batch 43, Loss: 0.3214499056339264\n",
            "Batch 44, Loss: 0.16739505529403687\n",
            "Batch 45, Loss: 0.13872291147708893\n",
            "Batch 46, Loss: 0.253669798374176\n",
            "Batch 47, Loss: 0.2313697338104248\n",
            "Batch 48, Loss: 0.20140790939331055\n",
            "Batch 49, Loss: 0.3270971179008484\n",
            "Batch 50, Loss: 0.1471400260925293\n",
            "Batch 51, Loss: 0.22367443144321442\n",
            "Batch 52, Loss: 0.29684683680534363\n",
            "Batch 53, Loss: 0.17500564455986023\n",
            "Batch 54, Loss: 0.19415634870529175\n",
            "Batch 55, Loss: 0.22902262210845947\n",
            "Batch 56, Loss: 0.17240050435066223\n",
            "Batch 57, Loss: 0.16759231686592102\n",
            "Batch 58, Loss: 0.47083792090415955\n",
            "Batch 59, Loss: 0.23736287653446198\n",
            "Batch 60, Loss: 0.20544105768203735\n",
            "Batch 61, Loss: 0.1429106891155243\n",
            "Batch 62, Loss: 0.16715571284294128\n",
            "Batch 63, Loss: 0.23254108428955078\n",
            "Batch 64, Loss: 0.21738173067569733\n",
            "Batch 65, Loss: 0.14589886367321014\n",
            "Batch 66, Loss: 0.2416391670703888\n",
            "Batch 67, Loss: 0.3840196132659912\n",
            "Batch 68, Loss: 0.3609406650066376\n",
            "Batch 69, Loss: 0.22657492756843567\n",
            "Batch 70, Loss: 0.26815956830978394\n",
            "Batch 71, Loss: 0.3423576056957245\n",
            "Batch 72, Loss: 0.3064068555831909\n",
            "Batch 73, Loss: 0.23363696038722992\n",
            "Batch 74, Loss: 0.15669956803321838\n",
            "Batch 75, Loss: 0.1309027373790741\n",
            "Batch 76, Loss: 0.32807737588882446\n",
            "Batch 77, Loss: 0.19170144200325012\n",
            "Batch 78, Loss: 0.1883716881275177\n",
            "Batch 79, Loss: 0.32848140597343445\n",
            "Batch 80, Loss: 0.17355215549468994\n",
            "Batch 81, Loss: 0.28579509258270264\n",
            "Batch 82, Loss: 0.17865388095378876\n",
            "Batch 83, Loss: 0.246924489736557\n",
            "Batch 84, Loss: 0.25210243463516235\n",
            "Batch 85, Loss: 0.12023089081048965\n",
            "Batch 86, Loss: 0.15677914023399353\n",
            "Batch 87, Loss: 0.3484823703765869\n",
            "Batch 88, Loss: 0.32106542587280273\n",
            "Batch 89, Loss: 0.11672225594520569\n",
            "Batch 90, Loss: 0.18364638090133667\n",
            "Batch 91, Loss: 0.15473279356956482\n",
            "Batch 92, Loss: 0.2841406762599945\n",
            "Batch 93, Loss: 0.18330955505371094\n",
            "Batch 94, Loss: 0.24276168644428253\n",
            "Batch 95, Loss: 0.17178957164287567\n",
            "Batch 96, Loss: 0.3053179979324341\n",
            "Batch 97, Loss: 0.2084147036075592\n",
            "Batch 98, Loss: 0.2797921895980835\n",
            "Batch 99, Loss: 0.18118949234485626\n",
            "Batch 100, Loss: 0.16984964907169342\n",
            "Batch 101, Loss: 0.1705823838710785\n",
            "Batch 102, Loss: 0.2704373002052307\n",
            "Batch 103, Loss: 0.41791778802871704\n",
            "Batch 104, Loss: 0.3065339922904968\n",
            "Batch 105, Loss: 0.23049335181713104\n",
            "Batch 106, Loss: 0.1892157942056656\n",
            "Batch 107, Loss: 0.28683531284332275\n",
            "Batch 108, Loss: 0.26227349042892456\n",
            "Batch 109, Loss: 0.1363728642463684\n",
            "Batch 110, Loss: 0.15605519711971283\n",
            "Batch 111, Loss: 0.5178335905075073\n",
            "Batch 112, Loss: 0.37416398525238037\n",
            "Batch 113, Loss: 0.2099991738796234\n",
            "Batch 114, Loss: 0.12248428910970688\n",
            "Batch 115, Loss: 0.2554934620857239\n",
            "Batch 116, Loss: 0.2245938777923584\n",
            "Batch 117, Loss: 0.3297007977962494\n",
            "Batch 118, Loss: 0.22050008177757263\n",
            "Batch 119, Loss: 0.385318398475647\n",
            "Batch 120, Loss: 0.23739436268806458\n",
            "Batch 121, Loss: 0.29179513454437256\n",
            "Batch 122, Loss: 0.23575244843959808\n",
            "Batch 123, Loss: 0.38836368918418884\n",
            "Batch 124, Loss: 0.10827889293432236\n",
            "Batch 125, Loss: 0.35425466299057007\n",
            "Batch 126, Loss: 0.29730433225631714\n",
            "Batch 127, Loss: 0.43604791164398193\n",
            "Batch 128, Loss: 0.17701439559459686\n",
            "Batch 129, Loss: 0.26933684945106506\n",
            "Batch 130, Loss: 0.19640564918518066\n",
            "Batch 131, Loss: 0.35787564516067505\n",
            "Batch 132, Loss: 0.31378695368766785\n",
            "Batch 133, Loss: 0.12645678222179413\n",
            "Batch 134, Loss: 0.2610233724117279\n",
            "Batch 135, Loss: 0.37381061911582947\n",
            "Batch 136, Loss: 0.18134137988090515\n",
            "Batch 137, Loss: 0.2605593204498291\n",
            "Batch 138, Loss: 0.43555814027786255\n",
            "Batch 139, Loss: 0.23485060036182404\n",
            "Batch 140, Loss: 0.26487860083580017\n",
            "Batch 141, Loss: 0.2766296863555908\n",
            "Batch 142, Loss: 0.46037304401397705\n",
            "Batch 143, Loss: 0.2671436667442322\n",
            "Batch 144, Loss: 0.2579447627067566\n",
            "Batch 145, Loss: 0.18215996026992798\n",
            "Batch 146, Loss: 0.26463770866394043\n",
            "Batch 147, Loss: 0.20160157978534698\n",
            "Batch 148, Loss: 0.30184847116470337\n",
            "Batch 149, Loss: 0.36877191066741943\n",
            "Batch 150, Loss: 0.17311988770961761\n",
            "Batch 151, Loss: 0.4214639961719513\n",
            "Batch 152, Loss: 0.16790974140167236\n",
            "Batch 153, Loss: 0.2681170701980591\n",
            "Batch 154, Loss: 0.3843405544757843\n",
            "Batch 155, Loss: 0.2930108904838562\n",
            "Batch 156, Loss: 0.33406245708465576\n",
            "Batch 157, Loss: 0.1918659210205078\n",
            "Batch 158, Loss: 0.37656331062316895\n",
            "Batch 159, Loss: 0.26077064871788025\n",
            "Batch 160, Loss: 0.43482470512390137\n",
            "Batch 161, Loss: 0.22744880616664886\n",
            "Batch 162, Loss: 0.2560982406139374\n",
            "Batch 163, Loss: 0.14445087313652039\n",
            "Batch 164, Loss: 0.28445056080818176\n",
            "Batch 165, Loss: 0.321130633354187\n",
            "Batch 166, Loss: 0.41435882449150085\n",
            "Batch 167, Loss: 0.18152809143066406\n",
            "Batch 168, Loss: 0.4164882302284241\n",
            "Batch 169, Loss: 0.2639005184173584\n",
            "Batch 170, Loss: 0.3029114603996277\n",
            "Batch 171, Loss: 0.40713784098625183\n",
            "Batch 172, Loss: 0.4354473352432251\n",
            "Batch 173, Loss: 0.3334740102291107\n",
            "Batch 174, Loss: 0.3604744076728821\n",
            "Batch 175, Loss: 0.1777912676334381\n",
            "Batch 176, Loss: 0.2563311755657196\n",
            "Batch 177, Loss: 0.4807659983634949\n",
            "Batch 178, Loss: 0.39375072717666626\n",
            "Batch 179, Loss: 0.34716537594795227\n",
            "Batch 180, Loss: 0.2569833993911743\n",
            "Batch 181, Loss: 0.32570475339889526\n",
            "Batch 182, Loss: 0.3176150321960449\n",
            "Batch 183, Loss: 0.3525974154472351\n",
            "Batch 184, Loss: 0.28379714488983154\n",
            "Batch 185, Loss: 0.3081960380077362\n",
            "Batch 186, Loss: 0.3274220824241638\n",
            "Batch 187, Loss: 0.23938778042793274\n",
            "Batch 188, Loss: 0.20978066325187683\n",
            "Batch 189, Loss: 0.3083733916282654\n",
            "Batch 190, Loss: 0.6166979074478149\n",
            "Batch 191, Loss: 0.27373284101486206\n",
            "Batch 192, Loss: 0.2714308500289917\n",
            "Batch 193, Loss: 0.4515415132045746\n",
            "Batch 194, Loss: 0.41202694177627563\n",
            "Batch 195, Loss: 0.22892403602600098\n",
            "Batch 196, Loss: 0.38500115275382996\n",
            "Batch 197, Loss: 0.3955841064453125\n",
            "Batch 198, Loss: 0.29206934571266174\n",
            "Batch 199, Loss: 0.2899453938007355\n",
            "Batch 200, Loss: 0.2752086818218231\n",
            "Batch 201, Loss: 0.35274386405944824\n",
            "Batch 202, Loss: 0.23057076334953308\n",
            "Batch 203, Loss: 0.3773728013038635\n",
            "Batch 204, Loss: 0.4105769395828247\n",
            "Batch 205, Loss: 0.3529219925403595\n",
            "Batch 206, Loss: 0.22698819637298584\n",
            "Batch 207, Loss: 0.2960848808288574\n",
            "Batch 208, Loss: 0.22292372584342957\n",
            "Batch 209, Loss: 0.3201799988746643\n",
            "Batch 210, Loss: 0.30905455350875854\n",
            "Batch 211, Loss: 0.1849963366985321\n",
            "Batch 212, Loss: 0.3714320659637451\n",
            "Batch 213, Loss: 0.3835054934024811\n",
            "Batch 214, Loss: 0.48278307914733887\n",
            "Batch 215, Loss: 0.2529726028442383\n",
            "Batch 216, Loss: 0.3515864312648773\n",
            "Batch 217, Loss: 0.3735511302947998\n",
            "Batch 218, Loss: 0.4000040590763092\n",
            "Batch 219, Loss: 0.3271900713443756\n",
            "Batch 220, Loss: 0.40786200761795044\n",
            "Batch 221, Loss: 0.5317792892456055\n",
            "Batch 222, Loss: 0.24683570861816406\n",
            "Batch 223, Loss: 0.47480830550193787\n",
            "Batch 224, Loss: 0.2742922306060791\n",
            "Batch 225, Loss: 0.45519912242889404\n",
            "Batch 226, Loss: 0.3117593228816986\n",
            "Batch 227, Loss: 0.35117560625076294\n",
            "Batch 228, Loss: 0.42272424697875977\n",
            "Batch 229, Loss: 0.7360833287239075\n",
            "Batch 230, Loss: 1.5558829307556152\n",
            "Epoch 35, Loss: 1.5558829307556152\n",
            "Batch 1, Loss: 0.28525757789611816\n",
            "Batch 2, Loss: 0.3680765926837921\n",
            "Batch 3, Loss: 0.3555281162261963\n",
            "Batch 4, Loss: 0.5378120541572571\n",
            "Batch 5, Loss: 0.6177557706832886\n",
            "Batch 6, Loss: 0.427327036857605\n",
            "Batch 7, Loss: 0.3106602430343628\n",
            "Batch 8, Loss: 0.3919188976287842\n",
            "Batch 9, Loss: 0.38138288259506226\n",
            "Batch 10, Loss: 0.29104891419410706\n",
            "Batch 11, Loss: 0.36795109510421753\n",
            "Batch 12, Loss: 0.4376088082790375\n",
            "Batch 13, Loss: 0.26291704177856445\n",
            "Batch 14, Loss: 0.5131567716598511\n",
            "Batch 15, Loss: 0.41699618101119995\n",
            "Batch 16, Loss: 0.392378568649292\n",
            "Batch 17, Loss: 0.6455062627792358\n",
            "Batch 18, Loss: 0.4496023654937744\n",
            "Batch 19, Loss: 0.3243689239025116\n",
            "Batch 20, Loss: 0.27274519205093384\n",
            "Batch 21, Loss: 0.2350466549396515\n",
            "Batch 22, Loss: 0.4675947427749634\n",
            "Batch 23, Loss: 0.4478311836719513\n",
            "Batch 24, Loss: 0.4973817765712738\n",
            "Batch 25, Loss: 0.32990047335624695\n",
            "Batch 26, Loss: 0.27403610944747925\n",
            "Batch 27, Loss: 0.24767489731311798\n",
            "Batch 28, Loss: 0.1939040720462799\n",
            "Batch 29, Loss: 0.43787819147109985\n",
            "Batch 30, Loss: 0.35885342955589294\n",
            "Batch 31, Loss: 0.20872913300991058\n",
            "Batch 32, Loss: 0.1869449019432068\n",
            "Batch 33, Loss: 0.17578667402267456\n",
            "Batch 34, Loss: 0.3766385316848755\n",
            "Batch 35, Loss: 0.43943604826927185\n",
            "Batch 36, Loss: 0.4867546558380127\n",
            "Batch 37, Loss: 0.2775045335292816\n",
            "Batch 38, Loss: 0.30449607968330383\n",
            "Batch 39, Loss: 0.41849687695503235\n",
            "Batch 40, Loss: 0.33675479888916016\n",
            "Batch 41, Loss: 0.23114454746246338\n",
            "Batch 42, Loss: 0.28969302773475647\n",
            "Batch 43, Loss: 0.2618970572948456\n",
            "Batch 44, Loss: 0.16167433559894562\n",
            "Batch 45, Loss: 0.30285847187042236\n",
            "Batch 46, Loss: 0.38570642471313477\n",
            "Batch 47, Loss: 0.33566421270370483\n",
            "Batch 48, Loss: 0.32360345125198364\n",
            "Batch 49, Loss: 0.3093702793121338\n",
            "Batch 50, Loss: 0.2974183261394501\n",
            "Batch 51, Loss: 0.27036505937576294\n",
            "Batch 52, Loss: 0.24086853861808777\n",
            "Batch 53, Loss: 0.2399950474500656\n",
            "Batch 54, Loss: 0.28961870074272156\n",
            "Batch 55, Loss: 0.29262983798980713\n",
            "Batch 56, Loss: 0.2654457986354828\n",
            "Batch 57, Loss: 0.188920259475708\n",
            "Batch 58, Loss: 0.2210438847541809\n",
            "Batch 59, Loss: 0.2511296570301056\n",
            "Batch 60, Loss: 0.23780030012130737\n",
            "Batch 61, Loss: 0.4850546419620514\n",
            "Batch 62, Loss: 0.16190609335899353\n",
            "Batch 63, Loss: 0.15664850175380707\n",
            "Batch 64, Loss: 0.33737605810165405\n",
            "Batch 65, Loss: 0.2604875862598419\n",
            "Batch 66, Loss: 0.5294830799102783\n",
            "Batch 67, Loss: 0.2880557179450989\n",
            "Batch 68, Loss: 0.3074803948402405\n",
            "Batch 69, Loss: 0.2524943947792053\n",
            "Batch 70, Loss: 0.2536289691925049\n",
            "Batch 71, Loss: 0.2888255715370178\n",
            "Batch 72, Loss: 0.2228497862815857\n",
            "Batch 73, Loss: 0.41309159994125366\n",
            "Batch 74, Loss: 0.20815789699554443\n",
            "Batch 75, Loss: 0.2147304117679596\n",
            "Batch 76, Loss: 0.46482834219932556\n",
            "Batch 77, Loss: 0.2856781482696533\n",
            "Batch 78, Loss: 0.48946231603622437\n",
            "Batch 79, Loss: 0.2313651740550995\n",
            "Batch 80, Loss: 0.5535967350006104\n",
            "Batch 81, Loss: 0.29484283924102783\n",
            "Batch 82, Loss: 0.20974019169807434\n",
            "Batch 83, Loss: 0.24761605262756348\n",
            "Batch 84, Loss: 0.15496371686458588\n",
            "Batch 85, Loss: 0.20624130964279175\n",
            "Batch 86, Loss: 0.1908513605594635\n",
            "Batch 87, Loss: 0.21944236755371094\n",
            "Batch 88, Loss: 0.24927262961864471\n",
            "Batch 89, Loss: 0.23361465334892273\n",
            "Batch 90, Loss: 0.35215094685554504\n",
            "Batch 91, Loss: 0.23798346519470215\n",
            "Batch 92, Loss: 0.1784367859363556\n",
            "Batch 93, Loss: 0.27155980467796326\n",
            "Batch 94, Loss: 0.15181505680084229\n",
            "Batch 95, Loss: 0.387569785118103\n",
            "Batch 96, Loss: 0.2530910074710846\n",
            "Batch 97, Loss: 0.28080517053604126\n",
            "Batch 98, Loss: 0.27963656187057495\n",
            "Batch 99, Loss: 0.21451163291931152\n",
            "Batch 100, Loss: 0.212031289935112\n",
            "Batch 101, Loss: 0.39601951837539673\n",
            "Batch 102, Loss: 0.23170095682144165\n",
            "Batch 103, Loss: 0.2399570494890213\n",
            "Batch 104, Loss: 0.38481080532073975\n",
            "Batch 105, Loss: 0.29700928926467896\n",
            "Batch 106, Loss: 0.48435813188552856\n",
            "Batch 107, Loss: 0.17942675948143005\n",
            "Batch 108, Loss: 0.14925768971443176\n",
            "Batch 109, Loss: 0.37208807468414307\n",
            "Batch 110, Loss: 0.3965449929237366\n",
            "Batch 111, Loss: 0.3262270390987396\n",
            "Batch 112, Loss: 0.14206543564796448\n",
            "Batch 113, Loss: 0.21618813276290894\n",
            "Batch 114, Loss: 0.3191758990287781\n",
            "Batch 115, Loss: 0.20768150687217712\n",
            "Batch 116, Loss: 0.22762301564216614\n",
            "Batch 117, Loss: 0.4316786825656891\n",
            "Batch 118, Loss: 0.3513695001602173\n",
            "Batch 119, Loss: 0.38550153374671936\n",
            "Batch 120, Loss: 0.3608001470565796\n",
            "Batch 121, Loss: 0.18360120058059692\n",
            "Batch 122, Loss: 0.2582748532295227\n",
            "Batch 123, Loss: 0.18515095114707947\n",
            "Batch 124, Loss: 0.35643741488456726\n",
            "Batch 125, Loss: 0.26963725686073303\n",
            "Batch 126, Loss: 0.19653287529945374\n",
            "Batch 127, Loss: 0.2042236030101776\n",
            "Batch 128, Loss: 0.2631794810295105\n",
            "Batch 129, Loss: 0.23876892030239105\n",
            "Batch 130, Loss: 0.2842501401901245\n",
            "Batch 131, Loss: 0.23977388441562653\n",
            "Batch 132, Loss: 0.1473192572593689\n",
            "Batch 133, Loss: 0.19868387281894684\n",
            "Batch 134, Loss: 0.17129293084144592\n",
            "Batch 135, Loss: 0.4377090334892273\n",
            "Batch 136, Loss: 0.19807755947113037\n",
            "Batch 137, Loss: 0.31310370564460754\n",
            "Batch 138, Loss: 0.2171785533428192\n",
            "Batch 139, Loss: 0.30721694231033325\n",
            "Batch 140, Loss: 0.22451841831207275\n",
            "Batch 141, Loss: 0.3926483988761902\n",
            "Batch 142, Loss: 0.3770614266395569\n",
            "Batch 143, Loss: 0.286717027425766\n",
            "Batch 144, Loss: 0.23395469784736633\n",
            "Batch 145, Loss: 0.3314594030380249\n",
            "Batch 146, Loss: 0.3909342586994171\n",
            "Batch 147, Loss: 0.34037113189697266\n",
            "Batch 148, Loss: 0.26145970821380615\n",
            "Batch 149, Loss: 0.2428237795829773\n",
            "Batch 150, Loss: 0.21325555443763733\n",
            "Batch 151, Loss: 0.6069541573524475\n",
            "Batch 152, Loss: 0.2567518949508667\n",
            "Batch 153, Loss: 0.46217602491378784\n",
            "Batch 154, Loss: 0.24108564853668213\n",
            "Batch 155, Loss: 0.20511892437934875\n",
            "Batch 156, Loss: 0.27919524908065796\n",
            "Batch 157, Loss: 0.32590413093566895\n",
            "Batch 158, Loss: 0.20468395948410034\n",
            "Batch 159, Loss: 0.2209634631872177\n",
            "Batch 160, Loss: 0.3075201213359833\n",
            "Batch 161, Loss: 0.43348097801208496\n",
            "Batch 162, Loss: 0.2817418575286865\n",
            "Batch 163, Loss: 0.4147602915763855\n",
            "Batch 164, Loss: 0.46119406819343567\n",
            "Batch 165, Loss: 0.5158869028091431\n",
            "Batch 166, Loss: 0.26571011543273926\n",
            "Batch 167, Loss: 0.18278834223747253\n",
            "Batch 168, Loss: 0.3083014488220215\n",
            "Batch 169, Loss: 0.45018166303634644\n",
            "Batch 170, Loss: 0.5352786183357239\n",
            "Batch 171, Loss: 0.2343611717224121\n",
            "Batch 172, Loss: 0.21417154371738434\n",
            "Batch 173, Loss: 0.3920309543609619\n",
            "Batch 174, Loss: 0.36779308319091797\n",
            "Batch 175, Loss: 0.2272724211215973\n",
            "Batch 176, Loss: 0.43068045377731323\n",
            "Batch 177, Loss: 0.3176509737968445\n",
            "Batch 178, Loss: 0.5428034663200378\n",
            "Batch 179, Loss: 0.3168296813964844\n",
            "Batch 180, Loss: 0.28664106130599976\n",
            "Batch 181, Loss: 0.2687748670578003\n",
            "Batch 182, Loss: 0.20165172219276428\n",
            "Batch 183, Loss: 0.7842903733253479\n",
            "Batch 184, Loss: 0.5013409852981567\n",
            "Batch 185, Loss: 0.33828848600387573\n",
            "Batch 186, Loss: 0.4633454978466034\n",
            "Batch 187, Loss: 0.25183770060539246\n",
            "Batch 188, Loss: 0.6669368743896484\n",
            "Batch 189, Loss: 0.4480326175689697\n",
            "Batch 190, Loss: 0.3328962028026581\n",
            "Batch 191, Loss: 0.5236659049987793\n",
            "Batch 192, Loss: 0.25868338346481323\n",
            "Batch 193, Loss: 0.4406015872955322\n",
            "Batch 194, Loss: 0.2592753469944\n",
            "Batch 195, Loss: 0.6002680063247681\n",
            "Batch 196, Loss: 0.40343526005744934\n",
            "Batch 197, Loss: 0.4907799959182739\n",
            "Batch 198, Loss: 0.41714152693748474\n",
            "Batch 199, Loss: 0.2978860139846802\n",
            "Batch 200, Loss: 0.28952786326408386\n",
            "Batch 201, Loss: 0.40875959396362305\n",
            "Batch 202, Loss: 0.3009348511695862\n",
            "Batch 203, Loss: 0.35306715965270996\n",
            "Batch 204, Loss: 0.2005738615989685\n",
            "Batch 205, Loss: 0.5690692663192749\n",
            "Batch 206, Loss: 0.2970576882362366\n",
            "Batch 207, Loss: 0.408833384513855\n",
            "Batch 208, Loss: 0.39017102122306824\n",
            "Batch 209, Loss: 0.6924599409103394\n",
            "Batch 210, Loss: 0.8218567967414856\n",
            "Batch 211, Loss: 0.4503418803215027\n",
            "Batch 212, Loss: 0.40548408031463623\n",
            "Batch 213, Loss: 0.3533889651298523\n",
            "Batch 214, Loss: 0.6125072240829468\n",
            "Batch 215, Loss: 0.3580228090286255\n",
            "Batch 216, Loss: 0.39810800552368164\n",
            "Batch 217, Loss: 0.2537233233451843\n",
            "Batch 218, Loss: 0.283703088760376\n",
            "Batch 219, Loss: 0.34486377239227295\n",
            "Batch 220, Loss: 0.3363805413246155\n",
            "Batch 221, Loss: 0.33812645077705383\n",
            "Batch 222, Loss: 0.4682386517524719\n",
            "Batch 223, Loss: 0.35331952571868896\n",
            "Batch 224, Loss: 0.3882145285606384\n",
            "Batch 225, Loss: 0.22775915265083313\n",
            "Batch 226, Loss: 0.26878947019577026\n",
            "Batch 227, Loss: 0.35454297065734863\n",
            "Batch 228, Loss: 0.4083826541900635\n",
            "Batch 229, Loss: 0.33543479442596436\n",
            "Batch 230, Loss: 0.25065943598747253\n",
            "Epoch 36, Loss: 0.25065943598747253\n",
            "Batch 1, Loss: 0.19847626984119415\n",
            "Batch 2, Loss: 0.1882154941558838\n",
            "Batch 3, Loss: 0.21930330991744995\n",
            "Batch 4, Loss: 0.15224838256835938\n",
            "Batch 5, Loss: 0.3720667064189911\n",
            "Batch 6, Loss: 0.21007174253463745\n",
            "Batch 7, Loss: 0.2949673533439636\n",
            "Batch 8, Loss: 0.33138975501060486\n",
            "Batch 9, Loss: 0.16400155425071716\n",
            "Batch 10, Loss: 0.1913190633058548\n",
            "Batch 11, Loss: 0.5157681107521057\n",
            "Batch 12, Loss: 0.1793864369392395\n",
            "Batch 13, Loss: 0.2919795513153076\n",
            "Batch 14, Loss: 0.25514477491378784\n",
            "Batch 15, Loss: 0.29309478402137756\n",
            "Batch 16, Loss: 0.17430171370506287\n",
            "Batch 17, Loss: 0.18100902438163757\n",
            "Batch 18, Loss: 0.20333817601203918\n",
            "Batch 19, Loss: 0.22977180778980255\n",
            "Batch 20, Loss: 0.24926498532295227\n",
            "Batch 21, Loss: 0.2788035571575165\n",
            "Batch 22, Loss: 0.2449982613325119\n",
            "Batch 23, Loss: 0.15816189348697662\n",
            "Batch 24, Loss: 0.24683259427547455\n",
            "Batch 25, Loss: 0.1785334050655365\n",
            "Batch 26, Loss: 0.23812252283096313\n",
            "Batch 27, Loss: 0.20010384917259216\n",
            "Batch 28, Loss: 0.309630811214447\n",
            "Batch 29, Loss: 0.23246382176876068\n",
            "Batch 30, Loss: 0.11435133963823318\n",
            "Batch 31, Loss: 0.2536267340183258\n",
            "Batch 32, Loss: 0.2861054837703705\n",
            "Batch 33, Loss: 0.18891024589538574\n",
            "Batch 34, Loss: 0.3325185477733612\n",
            "Batch 35, Loss: 0.23087355494499207\n",
            "Batch 36, Loss: 0.24601642787456512\n",
            "Batch 37, Loss: 0.22815008461475372\n",
            "Batch 38, Loss: 0.3016331195831299\n",
            "Batch 39, Loss: 0.18106010556221008\n",
            "Batch 40, Loss: 0.15805555880069733\n",
            "Batch 41, Loss: 0.22038227319717407\n",
            "Batch 42, Loss: 0.24883168935775757\n",
            "Batch 43, Loss: 0.18425075709819794\n",
            "Batch 44, Loss: 0.1837865561246872\n",
            "Batch 45, Loss: 0.18202315270900726\n",
            "Batch 46, Loss: 0.1858515590429306\n",
            "Batch 47, Loss: 0.1670658439397812\n",
            "Batch 48, Loss: 0.19550493359565735\n",
            "Batch 49, Loss: 0.1980205625295639\n",
            "Batch 50, Loss: 0.24991074204444885\n",
            "Batch 51, Loss: 0.24828974902629852\n",
            "Batch 52, Loss: 0.2408597767353058\n",
            "Batch 53, Loss: 0.29230597615242004\n",
            "Batch 54, Loss: 0.23334039747714996\n",
            "Batch 55, Loss: 0.16412410140037537\n",
            "Batch 56, Loss: 0.42256489396095276\n",
            "Batch 57, Loss: 0.33698856830596924\n",
            "Batch 58, Loss: 0.22709032893180847\n",
            "Batch 59, Loss: 0.3192947208881378\n",
            "Batch 60, Loss: 0.15706196427345276\n",
            "Batch 61, Loss: 0.29278653860092163\n",
            "Batch 62, Loss: 0.3001406192779541\n",
            "Batch 63, Loss: 0.21131229400634766\n",
            "Batch 64, Loss: 0.19211600720882416\n",
            "Batch 65, Loss: 0.24121885001659393\n",
            "Batch 66, Loss: 0.13182960450649261\n",
            "Batch 67, Loss: 0.19459876418113708\n",
            "Batch 68, Loss: 0.16212958097457886\n",
            "Batch 69, Loss: 0.19455334544181824\n",
            "Batch 70, Loss: 0.31432250142097473\n",
            "Batch 71, Loss: 0.1447201818227768\n",
            "Batch 72, Loss: 0.21729710698127747\n",
            "Batch 73, Loss: 0.23315495252609253\n",
            "Batch 74, Loss: 0.2237277328968048\n",
            "Batch 75, Loss: 0.27436313033103943\n",
            "Batch 76, Loss: 0.26173651218414307\n",
            "Batch 77, Loss: 0.2131396234035492\n",
            "Batch 78, Loss: 0.35424715280532837\n",
            "Batch 79, Loss: 0.18095247447490692\n",
            "Batch 80, Loss: 0.25278252363204956\n",
            "Batch 81, Loss: 0.3380187153816223\n",
            "Batch 82, Loss: 0.22956818342208862\n",
            "Batch 83, Loss: 0.28789830207824707\n",
            "Batch 84, Loss: 0.16836169362068176\n",
            "Batch 85, Loss: 0.19038249552249908\n",
            "Batch 86, Loss: 0.20238877832889557\n",
            "Batch 87, Loss: 0.2863158583641052\n",
            "Batch 88, Loss: 0.1183076873421669\n",
            "Batch 89, Loss: 0.23914052546024323\n",
            "Batch 90, Loss: 0.12446840107440948\n",
            "Batch 91, Loss: 0.14293542504310608\n",
            "Batch 92, Loss: 0.11331161856651306\n",
            "Batch 93, Loss: 0.2692756652832031\n",
            "Batch 94, Loss: 0.3048044443130493\n",
            "Batch 95, Loss: 0.2336888611316681\n",
            "Batch 96, Loss: 0.23381757736206055\n",
            "Batch 97, Loss: 0.26088494062423706\n",
            "Batch 98, Loss: 0.2424948513507843\n",
            "Batch 99, Loss: 0.2935030460357666\n",
            "Batch 100, Loss: 0.16127918660640717\n",
            "Batch 101, Loss: 0.16073180735111237\n",
            "Batch 102, Loss: 0.2334471046924591\n",
            "Batch 103, Loss: 0.290439248085022\n",
            "Batch 104, Loss: 0.3105411231517792\n",
            "Batch 105, Loss: 0.3025227189064026\n",
            "Batch 106, Loss: 0.2605712115764618\n",
            "Batch 107, Loss: 0.270110547542572\n",
            "Batch 108, Loss: 0.13724343478679657\n",
            "Batch 109, Loss: 0.35179010033607483\n",
            "Batch 110, Loss: 0.24074454605579376\n",
            "Batch 111, Loss: 0.12670905888080597\n",
            "Batch 112, Loss: 0.27784717082977295\n",
            "Batch 113, Loss: 0.13247884809970856\n",
            "Batch 114, Loss: 0.5919655561447144\n",
            "Batch 115, Loss: 0.16882677376270294\n",
            "Batch 116, Loss: 0.40576088428497314\n",
            "Batch 117, Loss: 0.1611633598804474\n",
            "Batch 118, Loss: 0.1980234533548355\n",
            "Batch 119, Loss: 0.16104859113693237\n",
            "Batch 120, Loss: 0.15457314252853394\n",
            "Batch 121, Loss: 0.2508040964603424\n",
            "Batch 122, Loss: 0.41230177879333496\n",
            "Batch 123, Loss: 0.4309696555137634\n",
            "Batch 124, Loss: 0.24350416660308838\n",
            "Batch 125, Loss: 0.29179689288139343\n",
            "Batch 126, Loss: 0.23711782693862915\n",
            "Batch 127, Loss: 0.24373550713062286\n",
            "Batch 128, Loss: 0.16645658016204834\n",
            "Batch 129, Loss: 0.22179459035396576\n",
            "Batch 130, Loss: 0.3526719808578491\n",
            "Batch 131, Loss: 0.3138832449913025\n",
            "Batch 132, Loss: 0.3201330900192261\n",
            "Batch 133, Loss: 0.14121577143669128\n",
            "Batch 134, Loss: 0.23361656069755554\n",
            "Batch 135, Loss: 0.3799862861633301\n",
            "Batch 136, Loss: 0.31212547421455383\n",
            "Batch 137, Loss: 0.20179930329322815\n",
            "Batch 138, Loss: 0.32946091890335083\n",
            "Batch 139, Loss: 0.1959601789712906\n",
            "Batch 140, Loss: 0.2763795852661133\n",
            "Batch 141, Loss: 0.16777458786964417\n",
            "Batch 142, Loss: 0.24508750438690186\n",
            "Batch 143, Loss: 0.18462930619716644\n",
            "Batch 144, Loss: 0.15402407944202423\n",
            "Batch 145, Loss: 0.3327938914299011\n",
            "Batch 146, Loss: 0.4159837067127228\n",
            "Batch 147, Loss: 0.3501097857952118\n",
            "Batch 148, Loss: 0.24296461045742035\n",
            "Batch 149, Loss: 0.23588290810585022\n",
            "Batch 150, Loss: 0.26264727115631104\n",
            "Batch 151, Loss: 0.18251900374889374\n",
            "Batch 152, Loss: 0.20493939518928528\n",
            "Batch 153, Loss: 0.31761258840560913\n",
            "Batch 154, Loss: 0.2512895464897156\n",
            "Batch 155, Loss: 0.2221517562866211\n",
            "Batch 156, Loss: 0.44904622435569763\n",
            "Batch 157, Loss: 0.30383315682411194\n",
            "Batch 158, Loss: 0.2160150557756424\n",
            "Batch 159, Loss: 0.17959851026535034\n",
            "Batch 160, Loss: 0.15500149130821228\n",
            "Batch 161, Loss: 0.38385093212127686\n",
            "Batch 162, Loss: 0.21793228387832642\n",
            "Batch 163, Loss: 0.3665260076522827\n",
            "Batch 164, Loss: 0.3871973752975464\n",
            "Batch 165, Loss: 0.46744000911712646\n",
            "Batch 166, Loss: 0.20692488551139832\n",
            "Batch 167, Loss: 0.23389548063278198\n",
            "Batch 168, Loss: 0.19475939869880676\n",
            "Batch 169, Loss: 0.1787918210029602\n",
            "Batch 170, Loss: 0.246526837348938\n",
            "Batch 171, Loss: 0.46940258145332336\n",
            "Batch 172, Loss: 0.47995027899742126\n",
            "Batch 173, Loss: 0.2238377332687378\n",
            "Batch 174, Loss: 0.28727829456329346\n",
            "Batch 175, Loss: 0.2974517345428467\n",
            "Batch 176, Loss: 0.30737748742103577\n",
            "Batch 177, Loss: 0.20209693908691406\n",
            "Batch 178, Loss: 0.21651792526245117\n",
            "Batch 179, Loss: 0.2670838534832001\n",
            "Batch 180, Loss: 0.20488972961902618\n",
            "Batch 181, Loss: 0.38822850584983826\n",
            "Batch 182, Loss: 0.38364607095718384\n",
            "Batch 183, Loss: 0.3860550820827484\n",
            "Batch 184, Loss: 0.16575244069099426\n",
            "Batch 185, Loss: 0.3314969539642334\n",
            "Batch 186, Loss: 0.36544671654701233\n",
            "Batch 187, Loss: 0.44355514645576477\n",
            "Batch 188, Loss: 0.3315282464027405\n",
            "Batch 189, Loss: 0.43310439586639404\n",
            "Batch 190, Loss: 0.31602978706359863\n",
            "Batch 191, Loss: 0.4499315023422241\n",
            "Batch 192, Loss: 0.22894461452960968\n",
            "Batch 193, Loss: 0.420506089925766\n",
            "Batch 194, Loss: 0.2246120125055313\n",
            "Batch 195, Loss: 0.40962672233581543\n",
            "Batch 196, Loss: 0.36558789014816284\n",
            "Batch 197, Loss: 0.3452899754047394\n",
            "Batch 198, Loss: 0.37204790115356445\n",
            "Batch 199, Loss: 0.3147064447402954\n",
            "Batch 200, Loss: 0.4110516905784607\n",
            "Batch 201, Loss: 0.21517089009284973\n",
            "Batch 202, Loss: 0.3892340660095215\n",
            "Batch 203, Loss: 0.25494861602783203\n",
            "Batch 204, Loss: 0.33333468437194824\n",
            "Batch 205, Loss: 0.42752504348754883\n",
            "Batch 206, Loss: 0.39415764808654785\n",
            "Batch 207, Loss: 0.2535538375377655\n",
            "Batch 208, Loss: 0.4296932816505432\n",
            "Batch 209, Loss: 0.3119528889656067\n",
            "Batch 210, Loss: 0.30460643768310547\n",
            "Batch 211, Loss: 0.2914358973503113\n",
            "Batch 212, Loss: 0.5102003216743469\n",
            "Batch 213, Loss: 0.3313431739807129\n",
            "Batch 214, Loss: 0.274148553609848\n",
            "Batch 215, Loss: 0.2133382260799408\n",
            "Batch 216, Loss: 0.2532568573951721\n",
            "Batch 217, Loss: 0.26155444979667664\n",
            "Batch 218, Loss: 0.4254453778266907\n",
            "Batch 219, Loss: 0.33045175671577454\n",
            "Batch 220, Loss: 0.2552936375141144\n",
            "Batch 221, Loss: 0.29391103982925415\n",
            "Batch 222, Loss: 0.36621177196502686\n",
            "Batch 223, Loss: 0.2036290019750595\n",
            "Batch 224, Loss: 0.5908849239349365\n",
            "Batch 225, Loss: 0.3968101143836975\n",
            "Batch 226, Loss: 0.21904951333999634\n",
            "Batch 227, Loss: 0.3392419219017029\n",
            "Batch 228, Loss: 0.4445907175540924\n",
            "Batch 229, Loss: 0.22624793648719788\n",
            "Batch 230, Loss: 0.2199857383966446\n",
            "Epoch 37, Loss: 0.2199857383966446\n",
            "Batch 1, Loss: 0.21266372501850128\n",
            "Batch 2, Loss: 0.31205347180366516\n",
            "Batch 3, Loss: 0.39117637276649475\n",
            "Batch 4, Loss: 0.32334548234939575\n",
            "Batch 5, Loss: 0.15164317190647125\n",
            "Batch 6, Loss: 0.1995742917060852\n",
            "Batch 7, Loss: 0.3355095386505127\n",
            "Batch 8, Loss: 0.16937266290187836\n",
            "Batch 9, Loss: 0.13937948644161224\n",
            "Batch 10, Loss: 0.12591540813446045\n",
            "Batch 11, Loss: 0.15689346194267273\n",
            "Batch 12, Loss: 0.16040357947349548\n",
            "Batch 13, Loss: 0.1859353482723236\n",
            "Batch 14, Loss: 0.19064700603485107\n",
            "Batch 15, Loss: 0.20832745730876923\n",
            "Batch 16, Loss: 0.24309389293193817\n",
            "Batch 17, Loss: 0.16720974445343018\n",
            "Batch 18, Loss: 0.2317950427532196\n",
            "Batch 19, Loss: 0.21966086328029633\n",
            "Batch 20, Loss: 0.10146334767341614\n",
            "Batch 21, Loss: 0.23973944783210754\n",
            "Batch 22, Loss: 0.17079541087150574\n",
            "Batch 23, Loss: 0.09339479357004166\n",
            "Batch 24, Loss: 0.33263203501701355\n",
            "Batch 25, Loss: 0.26713186502456665\n",
            "Batch 26, Loss: 0.16622023284435272\n",
            "Batch 27, Loss: 0.12302611023187637\n",
            "Batch 28, Loss: 0.15281182527542114\n",
            "Batch 29, Loss: 0.15299858152866364\n",
            "Batch 30, Loss: 0.23560716211795807\n",
            "Batch 31, Loss: 0.17329353094100952\n",
            "Batch 32, Loss: 0.25071465969085693\n",
            "Batch 33, Loss: 0.22842289507389069\n",
            "Batch 34, Loss: 0.2529776096343994\n",
            "Batch 35, Loss: 0.21760204434394836\n",
            "Batch 36, Loss: 0.2226731777191162\n",
            "Batch 37, Loss: 0.16556599736213684\n",
            "Batch 38, Loss: 0.201511412858963\n",
            "Batch 39, Loss: 0.10428988188505173\n",
            "Batch 40, Loss: 0.15629330277442932\n",
            "Batch 41, Loss: 0.12494580447673798\n",
            "Batch 42, Loss: 0.31617939472198486\n",
            "Batch 43, Loss: 0.24497459828853607\n",
            "Batch 44, Loss: 0.17694276571273804\n",
            "Batch 45, Loss: 0.2575721740722656\n",
            "Batch 46, Loss: 0.20575997233390808\n",
            "Batch 47, Loss: 0.10139046609401703\n",
            "Batch 48, Loss: 0.26268959045410156\n",
            "Batch 49, Loss: 0.11725619435310364\n",
            "Batch 50, Loss: 0.14037299156188965\n",
            "Batch 51, Loss: 0.1886739730834961\n",
            "Batch 52, Loss: 0.18707284331321716\n",
            "Batch 53, Loss: 0.25263673067092896\n",
            "Batch 54, Loss: 0.3228606581687927\n",
            "Batch 55, Loss: 0.23437625169754028\n",
            "Batch 56, Loss: 0.15455298125743866\n",
            "Batch 57, Loss: 0.41310620307922363\n",
            "Batch 58, Loss: 0.20370955765247345\n",
            "Batch 59, Loss: 0.2548738718032837\n",
            "Batch 60, Loss: 0.21901296079158783\n",
            "Batch 61, Loss: 0.2889287769794464\n",
            "Batch 62, Loss: 0.24942606687545776\n",
            "Batch 63, Loss: 0.2097281515598297\n",
            "Batch 64, Loss: 0.1916644275188446\n",
            "Batch 65, Loss: 0.29580092430114746\n",
            "Batch 66, Loss: 0.14493875205516815\n",
            "Batch 67, Loss: 0.13808195292949677\n",
            "Batch 68, Loss: 0.18734458088874817\n",
            "Batch 69, Loss: 0.1331462264060974\n",
            "Batch 70, Loss: 0.2671436667442322\n",
            "Batch 71, Loss: 0.2288971245288849\n",
            "Batch 72, Loss: 0.35615408420562744\n",
            "Batch 73, Loss: 0.17371279001235962\n",
            "Batch 74, Loss: 0.3326123356819153\n",
            "Batch 75, Loss: 0.16866463422775269\n",
            "Batch 76, Loss: 0.1675620675086975\n",
            "Batch 77, Loss: 0.22688686847686768\n",
            "Batch 78, Loss: 0.22492042183876038\n",
            "Batch 79, Loss: 0.3142043352127075\n",
            "Batch 80, Loss: 0.21656155586242676\n",
            "Batch 81, Loss: 0.262847900390625\n",
            "Batch 82, Loss: 0.2865139842033386\n",
            "Batch 83, Loss: 0.37045007944107056\n",
            "Batch 84, Loss: 0.1514115184545517\n",
            "Batch 85, Loss: 0.18029969930648804\n",
            "Batch 86, Loss: 0.21948400139808655\n",
            "Batch 87, Loss: 0.2535597085952759\n",
            "Batch 88, Loss: 0.2750712037086487\n",
            "Batch 89, Loss: 0.16551241278648376\n",
            "Batch 90, Loss: 0.11417257785797119\n",
            "Batch 91, Loss: 0.41558313369750977\n",
            "Batch 92, Loss: 0.47828808426856995\n",
            "Batch 93, Loss: 0.22194932401180267\n",
            "Batch 94, Loss: 0.1578749418258667\n",
            "Batch 95, Loss: 0.10124857723712921\n",
            "Batch 96, Loss: 0.33581236004829407\n",
            "Batch 97, Loss: 0.2200823426246643\n",
            "Batch 98, Loss: 0.15117596089839935\n",
            "Batch 99, Loss: 0.16744786500930786\n",
            "Batch 100, Loss: 0.332725465297699\n",
            "Batch 101, Loss: 0.14877821505069733\n",
            "Batch 102, Loss: 0.15922462940216064\n",
            "Batch 103, Loss: 0.23505403101444244\n",
            "Batch 104, Loss: 0.15582600235939026\n",
            "Batch 105, Loss: 0.20303267240524292\n",
            "Batch 106, Loss: 0.2625959515571594\n",
            "Batch 107, Loss: 0.28091099858283997\n",
            "Batch 108, Loss: 0.24126629531383514\n",
            "Batch 109, Loss: 0.22728963196277618\n",
            "Batch 110, Loss: 0.26264870166778564\n",
            "Batch 111, Loss: 0.2884658873081207\n",
            "Batch 112, Loss: 0.20071308314800262\n",
            "Batch 113, Loss: 0.20862621068954468\n",
            "Batch 114, Loss: 0.3143950402736664\n",
            "Batch 115, Loss: 0.15524545311927795\n",
            "Batch 116, Loss: 0.26213401556015015\n",
            "Batch 117, Loss: 0.18302400410175323\n",
            "Batch 118, Loss: 0.15324462950229645\n",
            "Batch 119, Loss: 0.24186623096466064\n",
            "Batch 120, Loss: 0.47394803166389465\n",
            "Batch 121, Loss: 0.30906596779823303\n",
            "Batch 122, Loss: 0.14330053329467773\n",
            "Batch 123, Loss: 0.22507159411907196\n",
            "Batch 124, Loss: 0.16346563398838043\n",
            "Batch 125, Loss: 0.2071124166250229\n",
            "Batch 126, Loss: 0.15503539144992828\n",
            "Batch 127, Loss: 0.1699368953704834\n",
            "Batch 128, Loss: 0.28692150115966797\n",
            "Batch 129, Loss: 0.2411929965019226\n",
            "Batch 130, Loss: 0.3590027689933777\n",
            "Batch 131, Loss: 0.1810193657875061\n",
            "Batch 132, Loss: 0.2615481913089752\n",
            "Batch 133, Loss: 0.21003001928329468\n",
            "Batch 134, Loss: 0.3051222562789917\n",
            "Batch 135, Loss: 0.17973460257053375\n",
            "Batch 136, Loss: 0.21399201452732086\n",
            "Batch 137, Loss: 0.3156816065311432\n",
            "Batch 138, Loss: 0.20859456062316895\n",
            "Batch 139, Loss: 0.17658454179763794\n",
            "Batch 140, Loss: 0.22547118365764618\n",
            "Batch 141, Loss: 0.1774362325668335\n",
            "Batch 142, Loss: 0.19689950346946716\n",
            "Batch 143, Loss: 0.18565647304058075\n",
            "Batch 144, Loss: 0.36917030811309814\n",
            "Batch 145, Loss: 0.14786356687545776\n",
            "Batch 146, Loss: 0.15263721346855164\n",
            "Batch 147, Loss: 0.16855992376804352\n",
            "Batch 148, Loss: 0.3057478666305542\n",
            "Batch 149, Loss: 0.260262668132782\n",
            "Batch 150, Loss: 0.22235265374183655\n",
            "Batch 151, Loss: 0.1659465730190277\n",
            "Batch 152, Loss: 0.13477842509746552\n",
            "Batch 153, Loss: 0.20508426427841187\n",
            "Batch 154, Loss: 0.2488030195236206\n",
            "Batch 155, Loss: 0.19187162816524506\n",
            "Batch 156, Loss: 0.17680200934410095\n",
            "Batch 157, Loss: 0.17478539049625397\n",
            "Batch 158, Loss: 0.2573472857475281\n",
            "Batch 159, Loss: 0.19903352856636047\n",
            "Batch 160, Loss: 0.1920829862356186\n",
            "Batch 161, Loss: 0.1348523050546646\n",
            "Batch 162, Loss: 0.27432921528816223\n",
            "Batch 163, Loss: 0.09828266501426697\n",
            "Batch 164, Loss: 0.2184446156024933\n",
            "Batch 165, Loss: 0.4409869313240051\n",
            "Batch 166, Loss: 0.23472082614898682\n",
            "Batch 167, Loss: 0.15019601583480835\n",
            "Batch 168, Loss: 0.3759956955909729\n",
            "Batch 169, Loss: 0.32753652334213257\n",
            "Batch 170, Loss: 0.14755266904830933\n",
            "Batch 171, Loss: 0.2438359409570694\n",
            "Batch 172, Loss: 0.16405537724494934\n",
            "Batch 173, Loss: 0.19781850278377533\n",
            "Batch 174, Loss: 0.2135031521320343\n",
            "Batch 175, Loss: 0.37304508686065674\n",
            "Batch 176, Loss: 0.1916939616203308\n",
            "Batch 177, Loss: 0.2455172836780548\n",
            "Batch 178, Loss: 0.18807902932167053\n",
            "Batch 179, Loss: 0.282693088054657\n",
            "Batch 180, Loss: 0.1826196014881134\n",
            "Batch 181, Loss: 0.18658101558685303\n",
            "Batch 182, Loss: 0.30483001470565796\n",
            "Batch 183, Loss: 0.1593923568725586\n",
            "Batch 184, Loss: 0.29001253843307495\n",
            "Batch 185, Loss: 0.27654406428337097\n",
            "Batch 186, Loss: 0.2610494792461395\n",
            "Batch 187, Loss: 0.23534470796585083\n",
            "Batch 188, Loss: 0.2407548725605011\n",
            "Batch 189, Loss: 0.27073225378990173\n",
            "Batch 190, Loss: 0.2022593915462494\n",
            "Batch 191, Loss: 0.24190445244312286\n",
            "Batch 192, Loss: 0.31555888056755066\n",
            "Batch 193, Loss: 0.15043579041957855\n",
            "Batch 194, Loss: 0.2810628116130829\n",
            "Batch 195, Loss: 0.193137064576149\n",
            "Batch 196, Loss: 0.2253032922744751\n",
            "Batch 197, Loss: 0.25314703583717346\n",
            "Batch 198, Loss: 0.4217994511127472\n",
            "Batch 199, Loss: 0.2776077687740326\n",
            "Batch 200, Loss: 0.3508279323577881\n",
            "Batch 201, Loss: 0.14676576852798462\n",
            "Batch 202, Loss: 0.3117384612560272\n",
            "Batch 203, Loss: 0.3472015857696533\n",
            "Batch 204, Loss: 0.2116948664188385\n",
            "Batch 205, Loss: 0.6124482750892639\n",
            "Batch 206, Loss: 0.28567296266555786\n",
            "Batch 207, Loss: 0.4469550549983978\n",
            "Batch 208, Loss: 0.1340150237083435\n",
            "Batch 209, Loss: 0.26931634545326233\n",
            "Batch 210, Loss: 0.21681727468967438\n",
            "Batch 211, Loss: 0.1750754714012146\n",
            "Batch 212, Loss: 0.4516909122467041\n",
            "Batch 213, Loss: 0.3392484188079834\n",
            "Batch 214, Loss: 0.3048591613769531\n",
            "Batch 215, Loss: 0.295362263917923\n",
            "Batch 216, Loss: 0.2353307455778122\n",
            "Batch 217, Loss: 0.19119124114513397\n",
            "Batch 218, Loss: 0.2642305791378021\n",
            "Batch 219, Loss: 0.2581554651260376\n",
            "Batch 220, Loss: 0.27017906308174133\n",
            "Batch 221, Loss: 0.277246356010437\n",
            "Batch 222, Loss: 0.16411815583705902\n",
            "Batch 223, Loss: 0.29610931873321533\n",
            "Batch 224, Loss: 0.5009791254997253\n",
            "Batch 225, Loss: 0.2125667929649353\n",
            "Batch 226, Loss: 0.3209809362888336\n",
            "Batch 227, Loss: 0.20925986766815186\n",
            "Batch 228, Loss: 0.30106449127197266\n",
            "Batch 229, Loss: 0.16821058094501495\n",
            "Batch 230, Loss: 0.03339585289359093\n",
            "Epoch 38, Loss: 0.03339585289359093\n",
            "Batch 1, Loss: 0.17748427391052246\n",
            "Batch 2, Loss: 0.08367381989955902\n",
            "Batch 3, Loss: 0.21436740458011627\n",
            "Batch 4, Loss: 0.14619889855384827\n",
            "Batch 5, Loss: 0.17961391806602478\n",
            "Batch 6, Loss: 0.17854315042495728\n",
            "Batch 7, Loss: 0.11909757554531097\n",
            "Batch 8, Loss: 0.10855883359909058\n",
            "Batch 9, Loss: 0.19575566053390503\n",
            "Batch 10, Loss: 0.09899310767650604\n",
            "Batch 11, Loss: 0.12285411357879639\n",
            "Batch 12, Loss: 0.17862944304943085\n",
            "Batch 13, Loss: 0.23345929384231567\n",
            "Batch 14, Loss: 0.2572014033794403\n",
            "Batch 15, Loss: 0.11231741309165955\n",
            "Batch 16, Loss: 0.12376251816749573\n",
            "Batch 17, Loss: 0.09850534051656723\n",
            "Batch 18, Loss: 0.14587073028087616\n",
            "Batch 19, Loss: 0.31479889154434204\n",
            "Batch 20, Loss: 0.22344458103179932\n",
            "Batch 21, Loss: 0.18946245312690735\n",
            "Batch 22, Loss: 0.1578395962715149\n",
            "Batch 23, Loss: 0.14774832129478455\n",
            "Batch 24, Loss: 0.13333742320537567\n",
            "Batch 25, Loss: 0.10134574770927429\n",
            "Batch 26, Loss: 0.13584482669830322\n",
            "Batch 27, Loss: 0.143152117729187\n",
            "Batch 28, Loss: 0.1187128871679306\n",
            "Batch 29, Loss: 0.15844306349754333\n",
            "Batch 30, Loss: 0.24984443187713623\n",
            "Batch 31, Loss: 0.1241600513458252\n",
            "Batch 32, Loss: 0.17870962619781494\n",
            "Batch 33, Loss: 0.1138220950961113\n",
            "Batch 34, Loss: 0.15837284922599792\n",
            "Batch 35, Loss: 0.16813534498214722\n",
            "Batch 36, Loss: 0.08744184672832489\n",
            "Batch 37, Loss: 0.10964798182249069\n",
            "Batch 38, Loss: 0.14103296399116516\n",
            "Batch 39, Loss: 0.1693660020828247\n",
            "Batch 40, Loss: 0.20905160903930664\n",
            "Batch 41, Loss: 0.28619781136512756\n",
            "Batch 42, Loss: 0.27824294567108154\n",
            "Batch 43, Loss: 0.13373123109340668\n",
            "Batch 44, Loss: 0.17809250950813293\n",
            "Batch 45, Loss: 0.1723562479019165\n",
            "Batch 46, Loss: 0.1310601383447647\n",
            "Batch 47, Loss: 0.19813382625579834\n",
            "Batch 48, Loss: 0.20584945380687714\n",
            "Batch 49, Loss: 0.23034203052520752\n",
            "Batch 50, Loss: 0.0888897180557251\n",
            "Batch 51, Loss: 0.12972691655158997\n",
            "Batch 52, Loss: 0.2563486695289612\n",
            "Batch 53, Loss: 0.12611667811870575\n",
            "Batch 54, Loss: 0.3055683374404907\n",
            "Batch 55, Loss: 0.1386106014251709\n",
            "Batch 56, Loss: 0.1339040994644165\n",
            "Batch 57, Loss: 0.12017254531383514\n",
            "Batch 58, Loss: 0.16264311969280243\n",
            "Batch 59, Loss: 0.23266658186912537\n",
            "Batch 60, Loss: 0.32302045822143555\n",
            "Batch 61, Loss: 0.1707223802804947\n",
            "Batch 62, Loss: 0.15730158984661102\n",
            "Batch 63, Loss: 0.22165828943252563\n",
            "Batch 64, Loss: 0.30801746249198914\n",
            "Batch 65, Loss: 0.11514787375926971\n",
            "Batch 66, Loss: 0.24245846271514893\n",
            "Batch 67, Loss: 0.15314942598342896\n",
            "Batch 68, Loss: 0.2472265511751175\n",
            "Batch 69, Loss: 0.12965290248394012\n",
            "Batch 70, Loss: 0.1831085979938507\n",
            "Batch 71, Loss: 0.11630192399024963\n",
            "Batch 72, Loss: 0.3122992515563965\n",
            "Batch 73, Loss: 0.12659257650375366\n",
            "Batch 74, Loss: 0.12069635838270187\n",
            "Batch 75, Loss: 0.19893616437911987\n",
            "Batch 76, Loss: 0.1968107968568802\n",
            "Batch 77, Loss: 0.15149807929992676\n",
            "Batch 78, Loss: 0.11991450190544128\n",
            "Batch 79, Loss: 0.14432919025421143\n",
            "Batch 80, Loss: 0.25846827030181885\n",
            "Batch 81, Loss: 0.13925251364707947\n",
            "Batch 82, Loss: 0.12982170283794403\n",
            "Batch 83, Loss: 0.11177665740251541\n",
            "Batch 84, Loss: 0.1606690138578415\n",
            "Batch 85, Loss: 0.1560899019241333\n",
            "Batch 86, Loss: 0.20889481902122498\n",
            "Batch 87, Loss: 0.2214483767747879\n",
            "Batch 88, Loss: 0.08584959805011749\n",
            "Batch 89, Loss: 0.10665876418352127\n",
            "Batch 90, Loss: 0.22845450043678284\n",
            "Batch 91, Loss: 0.20142300426959991\n",
            "Batch 92, Loss: 0.29451555013656616\n",
            "Batch 93, Loss: 0.11169598996639252\n",
            "Batch 94, Loss: 0.324087917804718\n",
            "Batch 95, Loss: 0.2858595550060272\n",
            "Batch 96, Loss: 0.1335783153772354\n",
            "Batch 97, Loss: 0.12449412792921066\n",
            "Batch 98, Loss: 0.17793992161750793\n",
            "Batch 99, Loss: 0.15457822382450104\n",
            "Batch 100, Loss: 0.182224303483963\n",
            "Batch 101, Loss: 0.1877513825893402\n",
            "Batch 102, Loss: 0.23615838587284088\n",
            "Batch 103, Loss: 0.2129451334476471\n",
            "Batch 104, Loss: 0.17570985853672028\n",
            "Batch 105, Loss: 0.1752709448337555\n",
            "Batch 106, Loss: 0.17361460626125336\n",
            "Batch 107, Loss: 0.20465362071990967\n",
            "Batch 108, Loss: 0.1715673804283142\n",
            "Batch 109, Loss: 0.10450898855924606\n",
            "Batch 110, Loss: 0.12107902020215988\n",
            "Batch 111, Loss: 0.17961768805980682\n",
            "Batch 112, Loss: 0.12509885430335999\n",
            "Batch 113, Loss: 0.1796470731496811\n",
            "Batch 114, Loss: 0.13631287217140198\n",
            "Batch 115, Loss: 0.1357097178697586\n",
            "Batch 116, Loss: 0.20776225626468658\n",
            "Batch 117, Loss: 0.15362612903118134\n",
            "Batch 118, Loss: 0.14141248166561127\n",
            "Batch 119, Loss: 0.2733045518398285\n",
            "Batch 120, Loss: 0.11266010254621506\n",
            "Batch 121, Loss: 0.2689726650714874\n",
            "Batch 122, Loss: 0.16118332743644714\n",
            "Batch 123, Loss: 0.1908893883228302\n",
            "Batch 124, Loss: 0.17139825224876404\n",
            "Batch 125, Loss: 0.20297279953956604\n",
            "Batch 126, Loss: 0.13832303881645203\n",
            "Batch 127, Loss: 0.23157255351543427\n",
            "Batch 128, Loss: 0.20962783694267273\n",
            "Batch 129, Loss: 0.19367361068725586\n",
            "Batch 130, Loss: 0.1576564460992813\n",
            "Batch 131, Loss: 0.4108165502548218\n",
            "Batch 132, Loss: 0.2001892775297165\n",
            "Batch 133, Loss: 0.3553072214126587\n",
            "Batch 134, Loss: 0.16848516464233398\n",
            "Batch 135, Loss: 0.22355897724628448\n",
            "Batch 136, Loss: 0.2476961612701416\n",
            "Batch 137, Loss: 0.2521389424800873\n",
            "Batch 138, Loss: 0.21934841573238373\n",
            "Batch 139, Loss: 0.15449613332748413\n",
            "Batch 140, Loss: 0.15311050415039062\n",
            "Batch 141, Loss: 0.19504037499427795\n",
            "Batch 142, Loss: 0.13633930683135986\n",
            "Batch 143, Loss: 0.15150350332260132\n",
            "Batch 144, Loss: 0.18920359015464783\n",
            "Batch 145, Loss: 0.17055943608283997\n",
            "Batch 146, Loss: 0.1778288334608078\n",
            "Batch 147, Loss: 0.18643738329410553\n",
            "Batch 148, Loss: 0.13764850795269012\n",
            "Batch 149, Loss: 0.30575287342071533\n",
            "Batch 150, Loss: 0.1784813106060028\n",
            "Batch 151, Loss: 0.23738855123519897\n",
            "Batch 152, Loss: 0.1499776989221573\n",
            "Batch 153, Loss: 0.24011988937854767\n",
            "Batch 154, Loss: 0.14355410635471344\n",
            "Batch 155, Loss: 0.18998362123966217\n",
            "Batch 156, Loss: 0.16102349758148193\n",
            "Batch 157, Loss: 0.24138015508651733\n",
            "Batch 158, Loss: 0.22549422085285187\n",
            "Batch 159, Loss: 0.20287349820137024\n",
            "Batch 160, Loss: 0.19198697805404663\n",
            "Batch 161, Loss: 0.11219021677970886\n",
            "Batch 162, Loss: 0.11206957697868347\n",
            "Batch 163, Loss: 0.15013180673122406\n",
            "Batch 164, Loss: 0.16080635786056519\n",
            "Batch 165, Loss: 0.18209141492843628\n",
            "Batch 166, Loss: 0.14858120679855347\n",
            "Batch 167, Loss: 0.22705724835395813\n",
            "Batch 168, Loss: 0.22144168615341187\n",
            "Batch 169, Loss: 0.25004613399505615\n",
            "Batch 170, Loss: 0.23589715361595154\n",
            "Batch 171, Loss: 0.31866246461868286\n",
            "Batch 172, Loss: 0.20796184241771698\n",
            "Batch 173, Loss: 0.2544919550418854\n",
            "Batch 174, Loss: 0.1812206208705902\n",
            "Batch 175, Loss: 0.2292773574590683\n",
            "Batch 176, Loss: 0.11163108050823212\n",
            "Batch 177, Loss: 0.2462421953678131\n",
            "Batch 178, Loss: 0.255475789308548\n",
            "Batch 179, Loss: 0.15922874212265015\n",
            "Batch 180, Loss: 0.1626584380865097\n",
            "Batch 181, Loss: 0.24750916659832\n",
            "Batch 182, Loss: 0.37463217973709106\n",
            "Batch 183, Loss: 0.17868070304393768\n",
            "Batch 184, Loss: 0.18105679750442505\n",
            "Batch 185, Loss: 0.18803444504737854\n",
            "Batch 186, Loss: 0.2271893173456192\n",
            "Batch 187, Loss: 0.26558828353881836\n",
            "Batch 188, Loss: 0.17840024828910828\n",
            "Batch 189, Loss: 0.24815011024475098\n",
            "Batch 190, Loss: 0.25503483414649963\n",
            "Batch 191, Loss: 0.26027968525886536\n",
            "Batch 192, Loss: 0.20161426067352295\n",
            "Batch 193, Loss: 0.13266721367835999\n",
            "Batch 194, Loss: 0.21714720129966736\n",
            "Batch 195, Loss: 0.15571856498718262\n",
            "Batch 196, Loss: 0.27751004695892334\n",
            "Batch 197, Loss: 0.19095437228679657\n",
            "Batch 198, Loss: 0.22690162062644958\n",
            "Batch 199, Loss: 0.27425330877304077\n",
            "Batch 200, Loss: 0.1613723635673523\n",
            "Batch 201, Loss: 0.22429759800434113\n",
            "Batch 202, Loss: 0.21988528966903687\n",
            "Batch 203, Loss: 0.23110973834991455\n",
            "Batch 204, Loss: 0.26958760619163513\n",
            "Batch 205, Loss: 0.27495038509368896\n",
            "Batch 206, Loss: 0.20530469715595245\n",
            "Batch 207, Loss: 0.1923040896654129\n",
            "Batch 208, Loss: 0.20309263467788696\n",
            "Batch 209, Loss: 0.3180447518825531\n",
            "Batch 210, Loss: 0.15132933855056763\n",
            "Batch 211, Loss: 0.2118765264749527\n",
            "Batch 212, Loss: 0.20661549270153046\n",
            "Batch 213, Loss: 0.14558999240398407\n",
            "Batch 214, Loss: 0.35997873544692993\n",
            "Batch 215, Loss: 0.3374956548213959\n",
            "Batch 216, Loss: 0.2888687551021576\n",
            "Batch 217, Loss: 0.26702386140823364\n",
            "Batch 218, Loss: 0.22206082940101624\n",
            "Batch 219, Loss: 0.2929229140281677\n",
            "Batch 220, Loss: 0.2235851287841797\n",
            "Batch 221, Loss: 0.17584890127182007\n",
            "Batch 222, Loss: 0.24386245012283325\n",
            "Batch 223, Loss: 0.3085234761238098\n",
            "Batch 224, Loss: 0.24616660177707672\n",
            "Batch 225, Loss: 0.15892267227172852\n",
            "Batch 226, Loss: 0.38607609272003174\n",
            "Batch 227, Loss: 0.18091566860675812\n",
            "Batch 228, Loss: 0.13861772418022156\n",
            "Batch 229, Loss: 0.23180034756660461\n",
            "Batch 230, Loss: 0.1680089682340622\n",
            "Epoch 39, Loss: 0.1680089682340622\n",
            "Batch 1, Loss: 0.09299765527248383\n",
            "Batch 2, Loss: 0.15244562923908234\n",
            "Batch 3, Loss: 0.1526542454957962\n",
            "Batch 4, Loss: 0.10831859707832336\n",
            "Batch 5, Loss: 0.29569607973098755\n",
            "Batch 6, Loss: 0.1500154733657837\n",
            "Batch 7, Loss: 0.1459866166114807\n",
            "Batch 8, Loss: 0.14013247191905975\n",
            "Batch 9, Loss: 0.15668439865112305\n",
            "Batch 10, Loss: 0.12625518441200256\n",
            "Batch 11, Loss: 0.1352466344833374\n",
            "Batch 12, Loss: 0.11665452271699905\n",
            "Batch 13, Loss: 0.21888187527656555\n",
            "Batch 14, Loss: 0.22280417382717133\n",
            "Batch 15, Loss: 0.1960652470588684\n",
            "Batch 16, Loss: 0.22065073251724243\n",
            "Batch 17, Loss: 0.10682832449674606\n",
            "Batch 18, Loss: 0.32174935936927795\n",
            "Batch 19, Loss: 0.1820591241121292\n",
            "Batch 20, Loss: 0.12780600786209106\n",
            "Batch 21, Loss: 0.09483906626701355\n",
            "Batch 22, Loss: 0.175685316324234\n",
            "Batch 23, Loss: 0.1276194006204605\n",
            "Batch 24, Loss: 0.14411979913711548\n",
            "Batch 25, Loss: 0.13393540680408478\n",
            "Batch 26, Loss: 0.13063624501228333\n",
            "Batch 27, Loss: 0.18519654870033264\n",
            "Batch 28, Loss: 0.14363688230514526\n",
            "Batch 29, Loss: 0.1680932641029358\n",
            "Batch 30, Loss: 0.13243013620376587\n",
            "Batch 31, Loss: 0.15062016248703003\n",
            "Batch 32, Loss: 0.09102223068475723\n",
            "Batch 33, Loss: 0.1480039656162262\n",
            "Batch 34, Loss: 0.1430560052394867\n",
            "Batch 35, Loss: 0.1925666332244873\n",
            "Batch 36, Loss: 0.15879040956497192\n",
            "Batch 37, Loss: 0.1096949428319931\n",
            "Batch 38, Loss: 0.1716802418231964\n",
            "Batch 39, Loss: 0.15154802799224854\n",
            "Batch 40, Loss: 0.16979429125785828\n",
            "Batch 41, Loss: 0.09721846133470535\n",
            "Batch 42, Loss: 0.09932568669319153\n",
            "Batch 43, Loss: 0.16540250182151794\n",
            "Batch 44, Loss: 0.1908169388771057\n",
            "Batch 45, Loss: 0.16867518424987793\n",
            "Batch 46, Loss: 0.16007733345031738\n",
            "Batch 47, Loss: 0.07937901467084885\n",
            "Batch 48, Loss: 0.09949231892824173\n",
            "Batch 49, Loss: 0.1633068025112152\n",
            "Batch 50, Loss: 0.10689069330692291\n",
            "Batch 51, Loss: 0.14284557104110718\n",
            "Batch 52, Loss: 0.15484963357448578\n",
            "Batch 53, Loss: 0.1518353670835495\n",
            "Batch 54, Loss: 0.13745108246803284\n",
            "Batch 55, Loss: 0.35085687041282654\n",
            "Batch 56, Loss: 0.10305727273225784\n",
            "Batch 57, Loss: 0.05829402059316635\n",
            "Batch 58, Loss: 0.15976467728614807\n",
            "Batch 59, Loss: 0.10690419375896454\n",
            "Batch 60, Loss: 0.20613357424736023\n",
            "Batch 61, Loss: 0.0898451954126358\n",
            "Batch 62, Loss: 0.1343674510717392\n",
            "Batch 63, Loss: 0.20620733499526978\n",
            "Batch 64, Loss: 0.16509456932544708\n",
            "Batch 65, Loss: 0.18598273396492004\n",
            "Batch 66, Loss: 0.14703680574893951\n",
            "Batch 67, Loss: 0.1744350790977478\n",
            "Batch 68, Loss: 0.12009331583976746\n",
            "Batch 69, Loss: 0.1404477208852768\n",
            "Batch 70, Loss: 0.14828862249851227\n",
            "Batch 71, Loss: 0.17403727769851685\n",
            "Batch 72, Loss: 0.17333389818668365\n",
            "Batch 73, Loss: 0.1662699282169342\n",
            "Batch 74, Loss: 0.10289014130830765\n",
            "Batch 75, Loss: 0.10873952507972717\n",
            "Batch 76, Loss: 0.2407546043395996\n",
            "Batch 77, Loss: 0.119646817445755\n",
            "Batch 78, Loss: 0.09196479618549347\n",
            "Batch 79, Loss: 0.20949269831180573\n",
            "Batch 80, Loss: 0.1873987317085266\n",
            "Batch 81, Loss: 0.3000175952911377\n",
            "Batch 82, Loss: 0.14488312602043152\n",
            "Batch 83, Loss: 0.15894216299057007\n",
            "Batch 84, Loss: 0.22018197178840637\n",
            "Batch 85, Loss: 0.24857857823371887\n",
            "Batch 86, Loss: 0.19511455297470093\n",
            "Batch 87, Loss: 0.13494236767292023\n",
            "Batch 88, Loss: 0.1278567612171173\n",
            "Batch 89, Loss: 0.21910761296749115\n",
            "Batch 90, Loss: 0.10662104189395905\n",
            "Batch 91, Loss: 0.1166626513004303\n",
            "Batch 92, Loss: 0.17914006114006042\n",
            "Batch 93, Loss: 0.09569484740495682\n",
            "Batch 94, Loss: 0.1372254341840744\n",
            "Batch 95, Loss: 0.17725783586502075\n",
            "Batch 96, Loss: 0.17402219772338867\n",
            "Batch 97, Loss: 0.1105196475982666\n",
            "Batch 98, Loss: 0.1413666307926178\n",
            "Batch 99, Loss: 0.1822017878293991\n",
            "Batch 100, Loss: 0.20195384323596954\n",
            "Batch 101, Loss: 0.08180440962314606\n",
            "Batch 102, Loss: 0.1655678153038025\n",
            "Batch 103, Loss: 0.15732033550739288\n",
            "Batch 104, Loss: 0.29345282912254333\n",
            "Batch 105, Loss: 0.18246808648109436\n",
            "Batch 106, Loss: 0.14996902644634247\n",
            "Batch 107, Loss: 0.2862861454486847\n",
            "Batch 108, Loss: 0.12608647346496582\n",
            "Batch 109, Loss: 0.17488792538642883\n",
            "Batch 110, Loss: 0.1387498378753662\n",
            "Batch 111, Loss: 0.2528008818626404\n",
            "Batch 112, Loss: 0.24397777020931244\n",
            "Batch 113, Loss: 0.23911413550376892\n",
            "Batch 114, Loss: 0.19661664962768555\n",
            "Batch 115, Loss: 0.1171817034482956\n",
            "Batch 116, Loss: 0.1329975575208664\n",
            "Batch 117, Loss: 0.11907078325748444\n",
            "Batch 118, Loss: 0.08414651453495026\n",
            "Batch 119, Loss: 0.1868879199028015\n",
            "Batch 120, Loss: 0.18617045879364014\n",
            "Batch 121, Loss: 0.2331310659646988\n",
            "Batch 122, Loss: 0.1835423856973648\n",
            "Batch 123, Loss: 0.10576669126749039\n",
            "Batch 124, Loss: 0.17861023545265198\n",
            "Batch 125, Loss: 0.14305223524570465\n",
            "Batch 126, Loss: 0.16462761163711548\n",
            "Batch 127, Loss: 0.33997827768325806\n",
            "Batch 128, Loss: 0.1295257806777954\n",
            "Batch 129, Loss: 0.23468829691410065\n",
            "Batch 130, Loss: 0.09154240041971207\n",
            "Batch 131, Loss: 0.1507100760936737\n",
            "Batch 132, Loss: 0.20663639903068542\n",
            "Batch 133, Loss: 0.20097273588180542\n",
            "Batch 134, Loss: 0.12755773961544037\n",
            "Batch 135, Loss: 0.21977585554122925\n",
            "Batch 136, Loss: 0.18442402780056\n",
            "Batch 137, Loss: 0.1497001349925995\n",
            "Batch 138, Loss: 0.15251167118549347\n",
            "Batch 139, Loss: 0.17658768594264984\n",
            "Batch 140, Loss: 0.17379255592823029\n",
            "Batch 141, Loss: 0.2885347306728363\n",
            "Batch 142, Loss: 0.21932215988636017\n",
            "Batch 143, Loss: 0.12677891552448273\n",
            "Batch 144, Loss: 0.2020309865474701\n",
            "Batch 145, Loss: 0.11719071120023727\n",
            "Batch 146, Loss: 0.1627391129732132\n",
            "Batch 147, Loss: 0.16283732652664185\n",
            "Batch 148, Loss: 0.2167016565799713\n",
            "Batch 149, Loss: 0.16109415888786316\n",
            "Batch 150, Loss: 0.1827823519706726\n",
            "Batch 151, Loss: 0.22884997725486755\n",
            "Batch 152, Loss: 0.17511624097824097\n",
            "Batch 153, Loss: 0.13369566202163696\n",
            "Batch 154, Loss: 0.21450360119342804\n",
            "Batch 155, Loss: 0.29677149653434753\n",
            "Batch 156, Loss: 0.20326466858386993\n",
            "Batch 157, Loss: 0.15294472873210907\n",
            "Batch 158, Loss: 0.2819632887840271\n",
            "Batch 159, Loss: 0.1205015704035759\n",
            "Batch 160, Loss: 0.2395356297492981\n",
            "Batch 161, Loss: 0.2310992181301117\n",
            "Batch 162, Loss: 0.17063167691230774\n",
            "Batch 163, Loss: 0.2810991108417511\n",
            "Batch 164, Loss: 0.19032233953475952\n",
            "Batch 165, Loss: 0.13046586513519287\n",
            "Batch 166, Loss: 0.17244161665439606\n",
            "Batch 167, Loss: 0.22074595093727112\n",
            "Batch 168, Loss: 0.29455113410949707\n",
            "Batch 169, Loss: 0.12124605476856232\n",
            "Batch 170, Loss: 0.2932060956954956\n",
            "Batch 171, Loss: 0.20302602648735046\n",
            "Batch 172, Loss: 0.1623043715953827\n",
            "Batch 173, Loss: 0.3103187680244446\n",
            "Batch 174, Loss: 0.17922858893871307\n",
            "Batch 175, Loss: 0.252741277217865\n",
            "Batch 176, Loss: 0.13616874814033508\n",
            "Batch 177, Loss: 0.24293631315231323\n",
            "Batch 178, Loss: 0.2789008617401123\n",
            "Batch 179, Loss: 0.19092626869678497\n",
            "Batch 180, Loss: 0.11330025643110275\n",
            "Batch 181, Loss: 0.1345665156841278\n",
            "Batch 182, Loss: 0.27279287576675415\n",
            "Batch 183, Loss: 0.22277668118476868\n",
            "Batch 184, Loss: 0.20360596477985382\n",
            "Batch 185, Loss: 0.21014434099197388\n",
            "Batch 186, Loss: 0.21584421396255493\n",
            "Batch 187, Loss: 0.11708682030439377\n",
            "Batch 188, Loss: 0.2543252408504486\n",
            "Batch 189, Loss: 0.14645835757255554\n",
            "Batch 190, Loss: 0.13416124880313873\n",
            "Batch 191, Loss: 0.2701996862888336\n",
            "Batch 192, Loss: 0.17482948303222656\n",
            "Batch 193, Loss: 0.26228365302085876\n",
            "Batch 194, Loss: 0.2667611539363861\n",
            "Batch 195, Loss: 0.2935754358768463\n",
            "Batch 196, Loss: 0.2529654800891876\n",
            "Batch 197, Loss: 0.2288396954536438\n",
            "Batch 198, Loss: 0.1340053677558899\n",
            "Batch 199, Loss: 0.30366337299346924\n",
            "Batch 200, Loss: 0.12817543745040894\n",
            "Batch 201, Loss: 0.21675610542297363\n",
            "Batch 202, Loss: 0.3088313341140747\n",
            "Batch 203, Loss: 0.20158329606056213\n",
            "Batch 204, Loss: 0.25929054617881775\n",
            "Batch 205, Loss: 0.14715243875980377\n",
            "Batch 206, Loss: 0.1620379090309143\n",
            "Batch 207, Loss: 0.2658230662345886\n",
            "Batch 208, Loss: 0.29750457406044006\n",
            "Batch 209, Loss: 0.3627663254737854\n",
            "Batch 210, Loss: 0.23518642783164978\n",
            "Batch 211, Loss: 0.29778510332107544\n",
            "Batch 212, Loss: 0.22580115497112274\n",
            "Batch 213, Loss: 0.268485426902771\n",
            "Batch 214, Loss: 0.176004558801651\n",
            "Batch 215, Loss: 0.4212343692779541\n",
            "Batch 216, Loss: 0.29410260915756226\n",
            "Batch 217, Loss: 0.15236492455005646\n",
            "Batch 218, Loss: 0.2081129401922226\n",
            "Batch 219, Loss: 0.23277699947357178\n",
            "Batch 220, Loss: 0.47442877292633057\n",
            "Batch 221, Loss: 0.5341157913208008\n",
            "Batch 222, Loss: 0.4898451268672943\n",
            "Batch 223, Loss: 0.24886122345924377\n",
            "Batch 224, Loss: 0.16748124361038208\n",
            "Batch 225, Loss: 0.17613014578819275\n",
            "Batch 226, Loss: 0.17284776270389557\n",
            "Batch 227, Loss: 0.2206619679927826\n",
            "Batch 228, Loss: 0.2564466595649719\n",
            "Batch 229, Loss: 0.31707122921943665\n",
            "Batch 230, Loss: 0.09921267628669739\n",
            "Epoch 40, Loss: 0.09921267628669739\n",
            "Batch 1, Loss: 0.15881501138210297\n",
            "Batch 2, Loss: 0.22564488649368286\n",
            "Batch 3, Loss: 0.17863640189170837\n",
            "Batch 4, Loss: 0.2553406357765198\n",
            "Batch 5, Loss: 0.17022749781608582\n",
            "Batch 6, Loss: 0.10864712297916412\n",
            "Batch 7, Loss: 0.1266181617975235\n",
            "Batch 8, Loss: 0.13967852294445038\n",
            "Batch 9, Loss: 0.1415255218744278\n",
            "Batch 10, Loss: 0.18382146954536438\n",
            "Batch 11, Loss: 0.11120586097240448\n",
            "Batch 12, Loss: 0.14670352637767792\n",
            "Batch 13, Loss: 0.15566930174827576\n",
            "Batch 14, Loss: 0.12264829874038696\n",
            "Batch 15, Loss: 0.25212275981903076\n",
            "Batch 16, Loss: 0.08773081004619598\n",
            "Batch 17, Loss: 0.2379644811153412\n",
            "Batch 18, Loss: 0.22313998639583588\n",
            "Batch 19, Loss: 0.15999948978424072\n",
            "Batch 20, Loss: 0.14522352814674377\n",
            "Batch 21, Loss: 0.16226065158843994\n",
            "Batch 22, Loss: 0.1378304660320282\n",
            "Batch 23, Loss: 0.21330401301383972\n",
            "Batch 24, Loss: 0.1530473381280899\n",
            "Batch 25, Loss: 0.1472788155078888\n",
            "Batch 26, Loss: 0.1357603222131729\n",
            "Batch 27, Loss: 0.14539384841918945\n",
            "Batch 28, Loss: 0.11962659657001495\n",
            "Batch 29, Loss: 0.22231195867061615\n",
            "Batch 30, Loss: 0.252507746219635\n",
            "Batch 31, Loss: 0.1352287381887436\n",
            "Batch 32, Loss: 0.1652625948190689\n",
            "Batch 33, Loss: 0.2539597153663635\n",
            "Batch 34, Loss: 0.10860870778560638\n",
            "Batch 35, Loss: 0.0752154290676117\n",
            "Batch 36, Loss: 0.0894978940486908\n",
            "Batch 37, Loss: 0.13506703078746796\n",
            "Batch 38, Loss: 0.18580316007137299\n",
            "Batch 39, Loss: 0.22082534432411194\n",
            "Batch 40, Loss: 0.06376320123672485\n",
            "Batch 41, Loss: 0.13151897490024567\n",
            "Batch 42, Loss: 0.1931382119655609\n",
            "Batch 43, Loss: 0.14349716901779175\n",
            "Batch 44, Loss: 0.1018691211938858\n",
            "Batch 45, Loss: 0.14652353525161743\n",
            "Batch 46, Loss: 0.13865813612937927\n",
            "Batch 47, Loss: 0.18054723739624023\n",
            "Batch 48, Loss: 0.18354666233062744\n",
            "Batch 49, Loss: 0.16695019602775574\n",
            "Batch 50, Loss: 0.25114431977272034\n",
            "Batch 51, Loss: 0.1198616698384285\n",
            "Batch 52, Loss: 0.17268145084381104\n",
            "Batch 53, Loss: 0.1857096254825592\n",
            "Batch 54, Loss: 0.11695515364408493\n",
            "Batch 55, Loss: 0.13514026999473572\n",
            "Batch 56, Loss: 0.1102365106344223\n",
            "Batch 57, Loss: 0.24277125298976898\n",
            "Batch 58, Loss: 0.190311461687088\n",
            "Batch 59, Loss: 0.15791818499565125\n",
            "Batch 60, Loss: 0.15838195383548737\n",
            "Batch 61, Loss: 0.1415019929409027\n",
            "Batch 62, Loss: 0.10427882522344589\n",
            "Batch 63, Loss: 0.14036250114440918\n",
            "Batch 64, Loss: 0.18022862076759338\n",
            "Batch 65, Loss: 0.11847500503063202\n",
            "Batch 66, Loss: 0.17482109367847443\n",
            "Batch 67, Loss: 0.11042265594005585\n",
            "Batch 68, Loss: 0.22984974086284637\n",
            "Batch 69, Loss: 0.1429022252559662\n",
            "Batch 70, Loss: 0.24613341689109802\n",
            "Batch 71, Loss: 0.14516016840934753\n",
            "Batch 72, Loss: 0.14272069931030273\n",
            "Batch 73, Loss: 0.1207827478647232\n",
            "Batch 74, Loss: 0.14371488988399506\n",
            "Batch 75, Loss: 0.20053578913211823\n",
            "Batch 76, Loss: 0.13996611535549164\n",
            "Batch 77, Loss: 0.3205801844596863\n",
            "Batch 78, Loss: 0.10841446369886398\n",
            "Batch 79, Loss: 0.11909197270870209\n",
            "Batch 80, Loss: 0.1545271873474121\n",
            "Batch 81, Loss: 0.10214825719594955\n",
            "Batch 82, Loss: 0.12832224369049072\n",
            "Batch 83, Loss: 0.1784306913614273\n",
            "Batch 84, Loss: 0.15247906744480133\n",
            "Batch 85, Loss: 0.22069701552391052\n",
            "Batch 86, Loss: 0.23154479265213013\n",
            "Batch 87, Loss: 0.1267341524362564\n",
            "Batch 88, Loss: 0.11932734400033951\n",
            "Batch 89, Loss: 0.14797277748584747\n",
            "Batch 90, Loss: 0.2641434669494629\n",
            "Batch 91, Loss: 0.18640361726284027\n",
            "Batch 92, Loss: 0.23518626391887665\n",
            "Batch 93, Loss: 0.1406537890434265\n",
            "Batch 94, Loss: 0.1504473090171814\n",
            "Batch 95, Loss: 0.1443551480770111\n",
            "Batch 96, Loss: 0.29635941982269287\n",
            "Batch 97, Loss: 0.34150707721710205\n",
            "Batch 98, Loss: 0.2691284418106079\n",
            "Batch 99, Loss: 0.14475451409816742\n",
            "Batch 100, Loss: 0.19606278836727142\n",
            "Batch 101, Loss: 0.15623439848423004\n",
            "Batch 102, Loss: 0.1557980477809906\n",
            "Batch 103, Loss: 0.20953166484832764\n",
            "Batch 104, Loss: 0.21240754425525665\n",
            "Batch 105, Loss: 0.17328688502311707\n",
            "Batch 106, Loss: 0.15719647705554962\n",
            "Batch 107, Loss: 0.20470793545246124\n",
            "Batch 108, Loss: 0.22420240938663483\n",
            "Batch 109, Loss: 0.2568913996219635\n",
            "Batch 110, Loss: 0.16235172748565674\n",
            "Batch 111, Loss: 0.252071738243103\n",
            "Batch 112, Loss: 0.2468584030866623\n",
            "Batch 113, Loss: 0.15912429988384247\n",
            "Batch 114, Loss: 0.2939402759075165\n",
            "Batch 115, Loss: 0.2243800312280655\n",
            "Batch 116, Loss: 0.09358653426170349\n",
            "Batch 117, Loss: 0.2408616840839386\n",
            "Batch 118, Loss: 0.28846120834350586\n",
            "Batch 119, Loss: 0.17703695595264435\n",
            "Batch 120, Loss: 0.1668190211057663\n",
            "Batch 121, Loss: 0.15671777725219727\n",
            "Batch 122, Loss: 0.24820880591869354\n",
            "Batch 123, Loss: 0.46006345748901367\n",
            "Batch 124, Loss: 0.2700253427028656\n",
            "Batch 125, Loss: 0.1713508665561676\n",
            "Batch 126, Loss: 0.1789833903312683\n",
            "Batch 127, Loss: 0.14542295038700104\n",
            "Batch 128, Loss: 0.14259786903858185\n",
            "Batch 129, Loss: 0.14774513244628906\n",
            "Batch 130, Loss: 0.1542101502418518\n",
            "Batch 131, Loss: 0.33632898330688477\n",
            "Batch 132, Loss: 0.12255245447158813\n",
            "Batch 133, Loss: 0.13222137093544006\n",
            "Batch 134, Loss: 0.17869743704795837\n",
            "Batch 135, Loss: 0.20306065678596497\n",
            "Batch 136, Loss: 0.24693846702575684\n",
            "Batch 137, Loss: 0.2222195565700531\n",
            "Batch 138, Loss: 0.17415925860404968\n",
            "Batch 139, Loss: 0.20655246078968048\n",
            "Batch 140, Loss: 0.3040514588356018\n",
            "Batch 141, Loss: 0.15986482799053192\n",
            "Batch 142, Loss: 0.1589912623167038\n",
            "Batch 143, Loss: 0.13529567420482635\n",
            "Batch 144, Loss: 0.26392996311187744\n",
            "Batch 145, Loss: 0.22854694724082947\n",
            "Batch 146, Loss: 0.2555692791938782\n",
            "Batch 147, Loss: 0.24639232456684113\n",
            "Batch 148, Loss: 0.2092532068490982\n",
            "Batch 149, Loss: 0.1775873899459839\n",
            "Batch 150, Loss: 0.18597343564033508\n",
            "Batch 151, Loss: 0.26704373955726624\n",
            "Batch 152, Loss: 0.35741299390792847\n",
            "Batch 153, Loss: 0.15683725476264954\n",
            "Batch 154, Loss: 0.1867261677980423\n",
            "Batch 155, Loss: 0.20081835985183716\n",
            "Batch 156, Loss: 0.13000527024269104\n",
            "Batch 157, Loss: 0.18534588813781738\n",
            "Batch 158, Loss: 0.3459455370903015\n",
            "Batch 159, Loss: 0.23897410929203033\n",
            "Batch 160, Loss: 0.16888582706451416\n",
            "Batch 161, Loss: 0.15506511926651\n",
            "Batch 162, Loss: 0.11226392537355423\n",
            "Batch 163, Loss: 0.2648451030254364\n",
            "Batch 164, Loss: 0.19580645859241486\n",
            "Batch 165, Loss: 0.19448919594287872\n",
            "Batch 166, Loss: 0.2774488031864166\n",
            "Batch 167, Loss: 0.2695889472961426\n",
            "Batch 168, Loss: 0.2739976644515991\n",
            "Batch 169, Loss: 0.23465394973754883\n",
            "Batch 170, Loss: 0.26859861612319946\n",
            "Batch 171, Loss: 0.18648789823055267\n",
            "Batch 172, Loss: 0.2684299349784851\n",
            "Batch 173, Loss: 0.2484792172908783\n",
            "Batch 174, Loss: 0.19522428512573242\n",
            "Batch 175, Loss: 0.3413431644439697\n",
            "Batch 176, Loss: 0.15508805215358734\n",
            "Batch 177, Loss: 0.1751096546649933\n",
            "Batch 178, Loss: 0.22892653942108154\n",
            "Batch 179, Loss: 0.16162684559822083\n",
            "Batch 180, Loss: 0.20033515989780426\n",
            "Batch 181, Loss: 0.18205446004867554\n",
            "Batch 182, Loss: 0.4209868311882019\n",
            "Batch 183, Loss: 0.31984177231788635\n",
            "Batch 184, Loss: 0.24343985319137573\n",
            "Batch 185, Loss: 0.24479325115680695\n",
            "Batch 186, Loss: 0.1706601083278656\n",
            "Batch 187, Loss: 0.20644034445285797\n",
            "Batch 188, Loss: 0.11287841945886612\n",
            "Batch 189, Loss: 0.18878576159477234\n",
            "Batch 190, Loss: 0.33965250849723816\n",
            "Batch 191, Loss: 0.21298827230930328\n",
            "Batch 192, Loss: 0.2257058471441269\n",
            "Batch 193, Loss: 0.21760226786136627\n",
            "Batch 194, Loss: 0.3002375364303589\n",
            "Batch 195, Loss: 0.26404887437820435\n",
            "Batch 196, Loss: 0.18277843296527863\n",
            "Batch 197, Loss: 0.21176676452159882\n",
            "Batch 198, Loss: 0.20925308763980865\n",
            "Batch 199, Loss: 0.32718056440353394\n",
            "Batch 200, Loss: 0.3344365954399109\n",
            "Batch 201, Loss: 0.293033242225647\n",
            "Batch 202, Loss: 0.26252031326293945\n",
            "Batch 203, Loss: 0.24701766669750214\n",
            "Batch 204, Loss: 0.2453533560037613\n",
            "Batch 205, Loss: 0.2759198546409607\n",
            "Batch 206, Loss: 0.200068861246109\n",
            "Batch 207, Loss: 0.15686285495758057\n",
            "Batch 208, Loss: 0.33631378412246704\n",
            "Batch 209, Loss: 0.1979694366455078\n",
            "Batch 210, Loss: 0.44225436449050903\n",
            "Batch 211, Loss: 0.24811753630638123\n",
            "Batch 212, Loss: 0.3475785255432129\n",
            "Batch 213, Loss: 0.15049795806407928\n",
            "Batch 214, Loss: 0.16135600209236145\n",
            "Batch 215, Loss: 0.2923949360847473\n",
            "Batch 216, Loss: 0.181128591299057\n",
            "Batch 217, Loss: 0.1642361581325531\n",
            "Batch 218, Loss: 0.23224380612373352\n",
            "Batch 219, Loss: 0.30394506454467773\n",
            "Batch 220, Loss: 0.24930670857429504\n",
            "Batch 221, Loss: 0.29983198642730713\n",
            "Batch 222, Loss: 0.16310065984725952\n",
            "Batch 223, Loss: 0.22357578575611115\n",
            "Batch 224, Loss: 0.2042139768600464\n",
            "Batch 225, Loss: 0.31770288944244385\n",
            "Batch 226, Loss: 0.2784241735935211\n",
            "Batch 227, Loss: 0.29973214864730835\n",
            "Batch 228, Loss: 0.20528644323349\n",
            "Batch 229, Loss: 0.195020854473114\n",
            "Batch 230, Loss: 0.8329240679740906\n",
            "Epoch 41, Loss: 0.8329240679740906\n",
            "Batch 1, Loss: 0.10763739049434662\n",
            "Batch 2, Loss: 0.11277896910905838\n",
            "Batch 3, Loss: 0.5562388896942139\n",
            "Batch 4, Loss: 0.6571665406227112\n",
            "Batch 5, Loss: 0.6126609444618225\n",
            "Batch 6, Loss: 0.3236275017261505\n",
            "Batch 7, Loss: 0.40360957384109497\n",
            "Batch 8, Loss: 0.49125269055366516\n",
            "Batch 9, Loss: 0.3838108777999878\n",
            "Batch 10, Loss: 0.2783654034137726\n",
            "Batch 11, Loss: 0.9158574342727661\n",
            "Batch 12, Loss: 0.3484154939651489\n",
            "Batch 13, Loss: 0.2737686336040497\n",
            "Batch 14, Loss: 0.2310495674610138\n",
            "Batch 15, Loss: 0.34184563159942627\n",
            "Batch 16, Loss: 0.4233015775680542\n",
            "Batch 17, Loss: 0.36908501386642456\n",
            "Batch 18, Loss: 0.16871076822280884\n",
            "Batch 19, Loss: 0.6310204267501831\n",
            "Batch 20, Loss: 0.2993529438972473\n",
            "Batch 21, Loss: 0.32489776611328125\n",
            "Batch 22, Loss: 0.1929073929786682\n",
            "Batch 23, Loss: 0.3249409794807434\n",
            "Batch 24, Loss: 0.22723835706710815\n",
            "Batch 25, Loss: 0.26539719104766846\n",
            "Batch 26, Loss: 0.29837799072265625\n",
            "Batch 27, Loss: 0.1706012785434723\n",
            "Batch 28, Loss: 0.36205172538757324\n",
            "Batch 29, Loss: 0.19109290838241577\n",
            "Batch 30, Loss: 0.3867799639701843\n",
            "Batch 31, Loss: 0.4395766854286194\n",
            "Batch 32, Loss: 0.282275915145874\n",
            "Batch 33, Loss: 0.2101845145225525\n",
            "Batch 34, Loss: 0.14352527260780334\n",
            "Batch 35, Loss: 0.20377494394779205\n",
            "Batch 36, Loss: 0.21051879227161407\n",
            "Batch 37, Loss: 0.3734014332294464\n",
            "Batch 38, Loss: 0.3047633767127991\n",
            "Batch 39, Loss: 0.2735251188278198\n",
            "Batch 40, Loss: 0.2806113362312317\n",
            "Batch 41, Loss: 0.25890058279037476\n",
            "Batch 42, Loss: 0.32994160056114197\n",
            "Batch 43, Loss: 0.41434532403945923\n",
            "Batch 44, Loss: 0.26355141401290894\n",
            "Batch 45, Loss: 0.22044363617897034\n",
            "Batch 46, Loss: 0.26049894094467163\n",
            "Batch 47, Loss: 0.39654862880706787\n",
            "Batch 48, Loss: 0.38129591941833496\n",
            "Batch 49, Loss: 0.3760477304458618\n",
            "Batch 50, Loss: 0.20406505465507507\n",
            "Batch 51, Loss: 0.29455074667930603\n",
            "Batch 52, Loss: 0.46053236722946167\n",
            "Batch 53, Loss: 0.33315062522888184\n",
            "Batch 54, Loss: 0.3746141791343689\n",
            "Batch 55, Loss: 0.1551528424024582\n",
            "Batch 56, Loss: 0.1876993477344513\n",
            "Batch 57, Loss: 0.2488759458065033\n",
            "Batch 58, Loss: 0.19757983088493347\n",
            "Batch 59, Loss: 0.24422091245651245\n",
            "Batch 60, Loss: 0.19783321022987366\n",
            "Batch 61, Loss: 0.3025548458099365\n",
            "Batch 62, Loss: 0.3195948302745819\n",
            "Batch 63, Loss: 0.21674568951129913\n",
            "Batch 64, Loss: 0.23827606439590454\n",
            "Batch 65, Loss: 0.09597499668598175\n",
            "Batch 66, Loss: 0.27963459491729736\n",
            "Batch 67, Loss: 0.2939624488353729\n",
            "Batch 68, Loss: 0.20351365208625793\n",
            "Batch 69, Loss: 0.18176540732383728\n",
            "Batch 70, Loss: 0.1597038358449936\n",
            "Batch 71, Loss: 0.29946357011795044\n",
            "Batch 72, Loss: 0.18997228145599365\n",
            "Batch 73, Loss: 0.24530789256095886\n",
            "Batch 74, Loss: 0.12549105286598206\n",
            "Batch 75, Loss: 0.15444594621658325\n",
            "Batch 76, Loss: 0.25165385007858276\n",
            "Batch 77, Loss: 0.21532011032104492\n",
            "Batch 78, Loss: 0.2670116722583771\n",
            "Batch 79, Loss: 0.38956278562545776\n",
            "Batch 80, Loss: 0.20070776343345642\n",
            "Batch 81, Loss: 0.2831975221633911\n",
            "Batch 82, Loss: 0.19771575927734375\n",
            "Batch 83, Loss: 0.21649211645126343\n",
            "Batch 84, Loss: 0.19691142439842224\n",
            "Batch 85, Loss: 0.23135493695735931\n",
            "Batch 86, Loss: 0.26942768692970276\n",
            "Batch 87, Loss: 0.26251256465911865\n",
            "Batch 88, Loss: 0.32089799642562866\n",
            "Batch 89, Loss: 0.1815982460975647\n",
            "Batch 90, Loss: 0.2660025954246521\n",
            "Batch 91, Loss: 0.444141149520874\n",
            "Batch 92, Loss: 0.27888038754463196\n",
            "Batch 93, Loss: 0.3632223606109619\n",
            "Batch 94, Loss: 0.1929507851600647\n",
            "Batch 95, Loss: 0.4035133421421051\n",
            "Batch 96, Loss: 0.22139930725097656\n",
            "Batch 97, Loss: 0.1576162874698639\n",
            "Batch 98, Loss: 0.12560218572616577\n",
            "Batch 99, Loss: 0.3298245668411255\n",
            "Batch 100, Loss: 0.2679743766784668\n",
            "Batch 101, Loss: 0.22253331542015076\n",
            "Batch 102, Loss: 0.5149575471878052\n",
            "Batch 103, Loss: 0.47178030014038086\n",
            "Batch 104, Loss: 0.22402966022491455\n",
            "Batch 105, Loss: 0.18488845229148865\n",
            "Batch 106, Loss: 0.12024125456809998\n",
            "Batch 107, Loss: 0.20012539625167847\n",
            "Batch 108, Loss: 0.25998225808143616\n",
            "Batch 109, Loss: 0.28617042303085327\n",
            "Batch 110, Loss: 0.18990209698677063\n",
            "Batch 111, Loss: 0.3296045660972595\n",
            "Batch 112, Loss: 0.12153059244155884\n",
            "Batch 113, Loss: 0.20447897911071777\n",
            "Batch 114, Loss: 0.19789539277553558\n",
            "Batch 115, Loss: 0.16656208038330078\n",
            "Batch 116, Loss: 0.3300129771232605\n",
            "Batch 117, Loss: 0.2171369343996048\n",
            "Batch 118, Loss: 0.3466304540634155\n",
            "Batch 119, Loss: 0.24576681852340698\n",
            "Batch 120, Loss: 0.16355019807815552\n",
            "Batch 121, Loss: 0.2082895040512085\n",
            "Batch 122, Loss: 0.4052232503890991\n",
            "Batch 123, Loss: 0.2626148462295532\n",
            "Batch 124, Loss: 0.18773695826530457\n",
            "Batch 125, Loss: 0.5703467130661011\n",
            "Batch 126, Loss: 0.2357122004032135\n",
            "Batch 127, Loss: 0.2691091001033783\n",
            "Batch 128, Loss: 0.2673453092575073\n",
            "Batch 129, Loss: 0.369066447019577\n",
            "Batch 130, Loss: 0.24521389603614807\n",
            "Batch 131, Loss: 0.20122751593589783\n",
            "Batch 132, Loss: 0.23218181729316711\n",
            "Batch 133, Loss: 0.2485448271036148\n",
            "Batch 134, Loss: 0.16432878375053406\n",
            "Batch 135, Loss: 0.4293971657752991\n",
            "Batch 136, Loss: 0.21865692734718323\n",
            "Batch 137, Loss: 0.2319766730070114\n",
            "Batch 138, Loss: 0.2586667537689209\n",
            "Batch 139, Loss: 0.3130859136581421\n",
            "Batch 140, Loss: 0.3596208095550537\n",
            "Batch 141, Loss: 0.2875880002975464\n",
            "Batch 142, Loss: 0.14326679706573486\n",
            "Batch 143, Loss: 0.30722862482070923\n",
            "Batch 144, Loss: 0.1962774395942688\n",
            "Batch 145, Loss: 0.25162628293037415\n",
            "Batch 146, Loss: 0.16129451990127563\n",
            "Batch 147, Loss: 0.24694034457206726\n",
            "Batch 148, Loss: 0.19990065693855286\n",
            "Batch 149, Loss: 0.22117957472801208\n",
            "Batch 150, Loss: 0.31933653354644775\n",
            "Batch 151, Loss: 0.2552180886268616\n",
            "Batch 152, Loss: 0.4437004327774048\n",
            "Batch 153, Loss: 0.23430824279785156\n",
            "Batch 154, Loss: 0.15720635652542114\n",
            "Batch 155, Loss: 0.24959301948547363\n",
            "Batch 156, Loss: 0.2857648730278015\n",
            "Batch 157, Loss: 0.3239803910255432\n",
            "Batch 158, Loss: 0.20981690287590027\n",
            "Batch 159, Loss: 0.30430829524993896\n",
            "Batch 160, Loss: 0.292280912399292\n",
            "Batch 161, Loss: 0.2756955623626709\n",
            "Batch 162, Loss: 0.14124427735805511\n",
            "Batch 163, Loss: 0.20127838850021362\n",
            "Batch 164, Loss: 0.19146819412708282\n",
            "Batch 165, Loss: 0.3434383273124695\n",
            "Batch 166, Loss: 0.3508930802345276\n",
            "Batch 167, Loss: 0.24327042698860168\n",
            "Batch 168, Loss: 0.19454455375671387\n",
            "Batch 169, Loss: 0.3300313353538513\n",
            "Batch 170, Loss: 0.34956082701683044\n",
            "Batch 171, Loss: 0.3029860258102417\n",
            "Batch 172, Loss: 0.29053568840026855\n",
            "Batch 173, Loss: 0.224889874458313\n",
            "Batch 174, Loss: 0.502514660358429\n",
            "Batch 175, Loss: 0.4650334119796753\n",
            "Batch 176, Loss: 0.2497577965259552\n",
            "Batch 177, Loss: 0.20621401071548462\n",
            "Batch 178, Loss: 0.20594164729118347\n",
            "Batch 179, Loss: 0.26544487476348877\n",
            "Batch 180, Loss: 0.22680284082889557\n",
            "Batch 181, Loss: 0.1605241596698761\n",
            "Batch 182, Loss: 0.3422721326351166\n",
            "Batch 183, Loss: 0.33873018622398376\n",
            "Batch 184, Loss: 0.38447168469429016\n",
            "Batch 185, Loss: 0.22332696616649628\n",
            "Batch 186, Loss: 0.2414594292640686\n",
            "Batch 187, Loss: 0.3505655825138092\n",
            "Batch 188, Loss: 0.24964994192123413\n",
            "Batch 189, Loss: 0.26614487171173096\n",
            "Batch 190, Loss: 0.23121626675128937\n",
            "Batch 191, Loss: 0.1872824728488922\n",
            "Batch 192, Loss: 0.15040206909179688\n",
            "Batch 193, Loss: 0.2721354365348816\n",
            "Batch 194, Loss: 0.17014804482460022\n",
            "Batch 195, Loss: 0.2686290144920349\n",
            "Batch 196, Loss: 0.17209437489509583\n",
            "Batch 197, Loss: 0.25297313928604126\n",
            "Batch 198, Loss: 0.21267905831336975\n",
            "Batch 199, Loss: 0.29785120487213135\n",
            "Batch 200, Loss: 0.2159121036529541\n",
            "Batch 201, Loss: 0.20324715971946716\n",
            "Batch 202, Loss: 0.13258256018161774\n",
            "Batch 203, Loss: 0.3295513987541199\n",
            "Batch 204, Loss: 0.3109704852104187\n",
            "Batch 205, Loss: 0.24369749426841736\n",
            "Batch 206, Loss: 0.26129984855651855\n",
            "Batch 207, Loss: 0.22224336862564087\n",
            "Batch 208, Loss: 0.22687079012393951\n",
            "Batch 209, Loss: 0.17835424840450287\n",
            "Batch 210, Loss: 0.22303880751132965\n",
            "Batch 211, Loss: 0.2591541111469269\n",
            "Batch 212, Loss: 0.1513904184103012\n",
            "Batch 213, Loss: 0.17792931199073792\n",
            "Batch 214, Loss: 0.2092963457107544\n",
            "Batch 215, Loss: 0.25150251388549805\n",
            "Batch 216, Loss: 0.19063764810562134\n",
            "Batch 217, Loss: 0.17860054969787598\n",
            "Batch 218, Loss: 0.14711666107177734\n",
            "Batch 219, Loss: 0.20321807265281677\n",
            "Batch 220, Loss: 0.24929873645305634\n",
            "Batch 221, Loss: 0.2341044545173645\n",
            "Batch 222, Loss: 0.2630960941314697\n",
            "Batch 223, Loss: 0.33482545614242554\n",
            "Batch 224, Loss: 0.37704312801361084\n",
            "Batch 225, Loss: 0.2871711850166321\n",
            "Batch 226, Loss: 0.16058939695358276\n",
            "Batch 227, Loss: 0.2697075307369232\n",
            "Batch 228, Loss: 0.16338521242141724\n",
            "Batch 229, Loss: 0.2197926938533783\n",
            "Batch 230, Loss: 0.3172665238380432\n",
            "Epoch 42, Loss: 0.3172665238380432\n",
            "Batch 1, Loss: 0.13678857684135437\n",
            "Batch 2, Loss: 0.16060423851013184\n",
            "Batch 3, Loss: 0.1724536120891571\n",
            "Batch 4, Loss: 0.11048950254917145\n",
            "Batch 5, Loss: 0.11354819685220718\n",
            "Batch 6, Loss: 0.3087296485900879\n",
            "Batch 7, Loss: 0.09720881283283234\n",
            "Batch 8, Loss: 0.2555014193058014\n",
            "Batch 9, Loss: 0.36032339930534363\n",
            "Batch 10, Loss: 0.17306429147720337\n",
            "Batch 11, Loss: 0.1566479653120041\n",
            "Batch 12, Loss: 0.2642987370491028\n",
            "Batch 13, Loss: 0.18111175298690796\n",
            "Batch 14, Loss: 0.19649994373321533\n",
            "Batch 15, Loss: 0.20144836604595184\n",
            "Batch 16, Loss: 0.2652929425239563\n",
            "Batch 17, Loss: 0.19750440120697021\n",
            "Batch 18, Loss: 0.2375338226556778\n",
            "Batch 19, Loss: 0.1531791090965271\n",
            "Batch 20, Loss: 0.22469907999038696\n",
            "Batch 21, Loss: 0.16482150554656982\n",
            "Batch 22, Loss: 0.16184541583061218\n",
            "Batch 23, Loss: 0.18774288892745972\n",
            "Batch 24, Loss: 0.28419944643974304\n",
            "Batch 25, Loss: 0.10938537120819092\n",
            "Batch 26, Loss: 0.22301463782787323\n",
            "Batch 27, Loss: 0.16255219280719757\n",
            "Batch 28, Loss: 0.1334894299507141\n",
            "Batch 29, Loss: 0.21280306577682495\n",
            "Batch 30, Loss: 0.21810153126716614\n",
            "Batch 31, Loss: 0.14814405143260956\n",
            "Batch 32, Loss: 0.11453425884246826\n",
            "Batch 33, Loss: 0.3021728992462158\n",
            "Batch 34, Loss: 0.15235783159732819\n",
            "Batch 35, Loss: 0.20400087535381317\n",
            "Batch 36, Loss: 0.17067068815231323\n",
            "Batch 37, Loss: 0.123842254281044\n",
            "Batch 38, Loss: 0.1827729493379593\n",
            "Batch 39, Loss: 0.1427740603685379\n",
            "Batch 40, Loss: 0.1922491490840912\n",
            "Batch 41, Loss: 0.12904620170593262\n",
            "Batch 42, Loss: 0.15764783322811127\n",
            "Batch 43, Loss: 0.1393756866455078\n",
            "Batch 44, Loss: 0.11529789865016937\n",
            "Batch 45, Loss: 0.09725859761238098\n",
            "Batch 46, Loss: 0.1553800106048584\n",
            "Batch 47, Loss: 0.23987752199172974\n",
            "Batch 48, Loss: 0.15707632899284363\n",
            "Batch 49, Loss: 0.33774328231811523\n",
            "Batch 50, Loss: 0.14912110567092896\n",
            "Batch 51, Loss: 0.13983479142189026\n",
            "Batch 52, Loss: 0.1459992378950119\n",
            "Batch 53, Loss: 0.18442174792289734\n",
            "Batch 54, Loss: 0.16223040223121643\n",
            "Batch 55, Loss: 0.18606631457805634\n",
            "Batch 56, Loss: 0.31074294447898865\n",
            "Batch 57, Loss: 0.1819022297859192\n",
            "Batch 58, Loss: 0.2008725106716156\n",
            "Batch 59, Loss: 0.2650764584541321\n",
            "Batch 60, Loss: 0.1391068696975708\n",
            "Batch 61, Loss: 0.2010539472103119\n",
            "Batch 62, Loss: 0.125340074300766\n",
            "Batch 63, Loss: 0.28637367486953735\n",
            "Batch 64, Loss: 0.13811425864696503\n",
            "Batch 65, Loss: 0.18719176948070526\n",
            "Batch 66, Loss: 0.09448513388633728\n",
            "Batch 67, Loss: 0.08998502790927887\n",
            "Batch 68, Loss: 0.11911577731370926\n",
            "Batch 69, Loss: 0.14019712805747986\n",
            "Batch 70, Loss: 0.20010489225387573\n",
            "Batch 71, Loss: 0.09215286374092102\n",
            "Batch 72, Loss: 0.2788756191730499\n",
            "Batch 73, Loss: 0.26619479060173035\n",
            "Batch 74, Loss: 0.13933990895748138\n",
            "Batch 75, Loss: 0.16065606474876404\n",
            "Batch 76, Loss: 0.29934436082839966\n",
            "Batch 77, Loss: 0.1785770058631897\n",
            "Batch 78, Loss: 0.3288707435131073\n",
            "Batch 79, Loss: 0.23074644804000854\n",
            "Batch 80, Loss: 0.4049058258533478\n",
            "Batch 81, Loss: 0.1294877529144287\n",
            "Batch 82, Loss: 0.22864501178264618\n",
            "Batch 83, Loss: 0.1439991295337677\n",
            "Batch 84, Loss: 0.20202648639678955\n",
            "Batch 85, Loss: 0.28850364685058594\n",
            "Batch 86, Loss: 0.16303622722625732\n",
            "Batch 87, Loss: 0.12842237949371338\n",
            "Batch 88, Loss: 0.15544867515563965\n",
            "Batch 89, Loss: 0.14606213569641113\n",
            "Batch 90, Loss: 0.119932159781456\n",
            "Batch 91, Loss: 0.24331720173358917\n",
            "Batch 92, Loss: 0.10008906573057175\n",
            "Batch 93, Loss: 0.1579706370830536\n",
            "Batch 94, Loss: 0.18348346650600433\n",
            "Batch 95, Loss: 0.163302481174469\n",
            "Batch 96, Loss: 0.16974304616451263\n",
            "Batch 97, Loss: 0.24219834804534912\n",
            "Batch 98, Loss: 0.24727824330329895\n",
            "Batch 99, Loss: 0.1293410062789917\n",
            "Batch 100, Loss: 0.23417478799819946\n",
            "Batch 101, Loss: 0.15506598353385925\n",
            "Batch 102, Loss: 0.11418011784553528\n",
            "Batch 103, Loss: 0.166664719581604\n",
            "Batch 104, Loss: 0.20933754742145538\n",
            "Batch 105, Loss: 0.25172510743141174\n",
            "Batch 106, Loss: 0.16747403144836426\n",
            "Batch 107, Loss: 0.14787232875823975\n",
            "Batch 108, Loss: 0.19210822880268097\n",
            "Batch 109, Loss: 0.17284655570983887\n",
            "Batch 110, Loss: 0.11479940265417099\n",
            "Batch 111, Loss: 0.15924927592277527\n",
            "Batch 112, Loss: 0.17030346393585205\n",
            "Batch 113, Loss: 0.18328949809074402\n",
            "Batch 114, Loss: 0.2343110889196396\n",
            "Batch 115, Loss: 0.14717257022857666\n",
            "Batch 116, Loss: 0.18165726959705353\n",
            "Batch 117, Loss: 0.2111518383026123\n",
            "Batch 118, Loss: 0.31420156359672546\n",
            "Batch 119, Loss: 0.16239012777805328\n",
            "Batch 120, Loss: 0.17712965607643127\n",
            "Batch 121, Loss: 0.16743157804012299\n",
            "Batch 122, Loss: 0.16331036388874054\n",
            "Batch 123, Loss: 0.30363398790359497\n",
            "Batch 124, Loss: 0.169295534491539\n",
            "Batch 125, Loss: 0.15809425711631775\n",
            "Batch 126, Loss: 0.1123499721288681\n",
            "Batch 127, Loss: 0.32700449228286743\n",
            "Batch 128, Loss: 0.1898198425769806\n",
            "Batch 129, Loss: 0.09318256378173828\n",
            "Batch 130, Loss: 0.2758742868900299\n",
            "Batch 131, Loss: 0.1981024593114853\n",
            "Batch 132, Loss: 0.15633346140384674\n",
            "Batch 133, Loss: 0.140296071767807\n",
            "Batch 134, Loss: 0.13970275223255157\n",
            "Batch 135, Loss: 0.2297353744506836\n",
            "Batch 136, Loss: 0.09919635206460953\n",
            "Batch 137, Loss: 0.26328644156455994\n",
            "Batch 138, Loss: 0.18795791268348694\n",
            "Batch 139, Loss: 0.2642740309238434\n",
            "Batch 140, Loss: 0.3165319263935089\n",
            "Batch 141, Loss: 0.26594144105911255\n",
            "Batch 142, Loss: 0.35475900769233704\n",
            "Batch 143, Loss: 0.14401140809059143\n",
            "Batch 144, Loss: 0.10417568683624268\n",
            "Batch 145, Loss: 0.1385398805141449\n",
            "Batch 146, Loss: 0.14497940242290497\n",
            "Batch 147, Loss: 0.2200862467288971\n",
            "Batch 148, Loss: 0.2964033782482147\n",
            "Batch 149, Loss: 0.1862238049507141\n",
            "Batch 150, Loss: 0.24598395824432373\n",
            "Batch 151, Loss: 0.22974267601966858\n",
            "Batch 152, Loss: 0.30825915932655334\n",
            "Batch 153, Loss: 0.20816031098365784\n",
            "Batch 154, Loss: 0.3039783835411072\n",
            "Batch 155, Loss: 0.327866792678833\n",
            "Batch 156, Loss: 0.18259882926940918\n",
            "Batch 157, Loss: 0.417322039604187\n",
            "Batch 158, Loss: 0.21556593477725983\n",
            "Batch 159, Loss: 0.2574401795864105\n",
            "Batch 160, Loss: 0.17969757318496704\n",
            "Batch 161, Loss: 0.2324797511100769\n",
            "Batch 162, Loss: 0.14226564764976501\n",
            "Batch 163, Loss: 0.25062093138694763\n",
            "Batch 164, Loss: 0.28223931789398193\n",
            "Batch 165, Loss: 0.24236702919006348\n",
            "Batch 166, Loss: 0.16542959213256836\n",
            "Batch 167, Loss: 0.16293299198150635\n",
            "Batch 168, Loss: 0.120656318962574\n",
            "Batch 169, Loss: 0.15732114017009735\n",
            "Batch 170, Loss: 0.3404689133167267\n",
            "Batch 171, Loss: 0.237891286611557\n",
            "Batch 172, Loss: 0.2536243200302124\n",
            "Batch 173, Loss: 0.2192687690258026\n",
            "Batch 174, Loss: 0.305584192276001\n",
            "Batch 175, Loss: 0.18610306084156036\n",
            "Batch 176, Loss: 0.3781188726425171\n",
            "Batch 177, Loss: 0.1547921597957611\n",
            "Batch 178, Loss: 0.2540458142757416\n",
            "Batch 179, Loss: 0.2700994312763214\n",
            "Batch 180, Loss: 0.1791352480649948\n",
            "Batch 181, Loss: 0.22870910167694092\n",
            "Batch 182, Loss: 0.25319376587867737\n",
            "Batch 183, Loss: 0.13991686701774597\n",
            "Batch 184, Loss: 0.194136381149292\n",
            "Batch 185, Loss: 0.28774774074554443\n",
            "Batch 186, Loss: 0.24854612350463867\n",
            "Batch 187, Loss: 0.26471012830734253\n",
            "Batch 188, Loss: 0.20969605445861816\n",
            "Batch 189, Loss: 0.26725125312805176\n",
            "Batch 190, Loss: 0.19768372178077698\n",
            "Batch 191, Loss: 0.26310089230537415\n",
            "Batch 192, Loss: 0.23368343710899353\n",
            "Batch 193, Loss: 0.20201587677001953\n",
            "Batch 194, Loss: 0.4094153642654419\n",
            "Batch 195, Loss: 0.3993106782436371\n",
            "Batch 196, Loss: 0.24106508493423462\n",
            "Batch 197, Loss: 0.3074660003185272\n",
            "Batch 198, Loss: 0.14499542117118835\n",
            "Batch 199, Loss: 0.20175500214099884\n",
            "Batch 200, Loss: 0.21361368894577026\n",
            "Batch 201, Loss: 0.21151092648506165\n",
            "Batch 202, Loss: 0.28453242778778076\n",
            "Batch 203, Loss: 0.36116763949394226\n",
            "Batch 204, Loss: 0.23149709403514862\n",
            "Batch 205, Loss: 0.19440673291683197\n",
            "Batch 206, Loss: 0.20351994037628174\n",
            "Batch 207, Loss: 0.19880768656730652\n",
            "Batch 208, Loss: 0.2152697592973709\n",
            "Batch 209, Loss: 0.14414557814598083\n",
            "Batch 210, Loss: 0.19502228498458862\n",
            "Batch 211, Loss: 0.13520121574401855\n",
            "Batch 212, Loss: 0.12815076112747192\n",
            "Batch 213, Loss: 0.14941497147083282\n",
            "Batch 214, Loss: 0.33193594217300415\n",
            "Batch 215, Loss: 0.1548936516046524\n",
            "Batch 216, Loss: 0.3268915116786957\n",
            "Batch 217, Loss: 0.2600238025188446\n",
            "Batch 218, Loss: 0.25924548506736755\n",
            "Batch 219, Loss: 0.2883117198944092\n",
            "Batch 220, Loss: 0.2412528693675995\n",
            "Batch 221, Loss: 0.2064826339483261\n",
            "Batch 222, Loss: 0.170758917927742\n",
            "Batch 223, Loss: 0.08682961761951447\n",
            "Batch 224, Loss: 0.29151788353919983\n",
            "Batch 225, Loss: 0.1911523938179016\n",
            "Batch 226, Loss: 0.2359408438205719\n",
            "Batch 227, Loss: 0.20612353086471558\n",
            "Batch 228, Loss: 0.2660250663757324\n",
            "Batch 229, Loss: 0.4692050814628601\n",
            "Batch 230, Loss: 0.19176602363586426\n",
            "Epoch 43, Loss: 0.19176602363586426\n",
            "Batch 1, Loss: 0.1715504676103592\n",
            "Batch 2, Loss: 0.23367197811603546\n",
            "Batch 3, Loss: 0.13948914408683777\n",
            "Batch 4, Loss: 0.1627306044101715\n",
            "Batch 5, Loss: 0.21392352879047394\n",
            "Batch 6, Loss: 0.255705326795578\n",
            "Batch 7, Loss: 0.21807067096233368\n",
            "Batch 8, Loss: 0.17033085227012634\n",
            "Batch 9, Loss: 0.15398338437080383\n",
            "Batch 10, Loss: 0.22728586196899414\n",
            "Batch 11, Loss: 0.45892831683158875\n",
            "Batch 12, Loss: 0.18673311173915863\n",
            "Batch 13, Loss: 0.10008608549833298\n",
            "Batch 14, Loss: 0.09912164509296417\n",
            "Batch 15, Loss: 0.22408661246299744\n",
            "Batch 16, Loss: 0.17606525123119354\n",
            "Batch 17, Loss: 0.18056383728981018\n",
            "Batch 18, Loss: 0.3360321521759033\n",
            "Batch 19, Loss: 0.16088521480560303\n",
            "Batch 20, Loss: 0.1725475788116455\n",
            "Batch 21, Loss: 0.29161930084228516\n",
            "Batch 22, Loss: 0.14674495160579681\n",
            "Batch 23, Loss: 0.11057397723197937\n",
            "Batch 24, Loss: 0.1732143610715866\n",
            "Batch 25, Loss: 0.24931655824184418\n",
            "Batch 26, Loss: 0.12355576455593109\n",
            "Batch 27, Loss: 0.26217421889305115\n",
            "Batch 28, Loss: 0.16211539506912231\n",
            "Batch 29, Loss: 0.23386383056640625\n",
            "Batch 30, Loss: 0.17068277299404144\n",
            "Batch 31, Loss: 0.2542456388473511\n",
            "Batch 32, Loss: 0.12826432287693024\n",
            "Batch 33, Loss: 0.4494377076625824\n",
            "Batch 34, Loss: 0.21283850073814392\n",
            "Batch 35, Loss: 0.24899980425834656\n",
            "Batch 36, Loss: 0.1839865744113922\n",
            "Batch 37, Loss: 0.18144726753234863\n",
            "Batch 38, Loss: 0.11389671266078949\n",
            "Batch 39, Loss: 0.2873055934906006\n",
            "Batch 40, Loss: 0.25780948996543884\n",
            "Batch 41, Loss: 0.15766501426696777\n",
            "Batch 42, Loss: 0.12330709397792816\n",
            "Batch 43, Loss: 0.40975284576416016\n",
            "Batch 44, Loss: 0.1847556233406067\n",
            "Batch 45, Loss: 0.07436298578977585\n",
            "Batch 46, Loss: 0.16470593214035034\n",
            "Batch 47, Loss: 0.16164320707321167\n",
            "Batch 48, Loss: 0.2232399582862854\n",
            "Batch 49, Loss: 0.12287548184394836\n",
            "Batch 50, Loss: 0.24890649318695068\n",
            "Batch 51, Loss: 0.21293166279792786\n",
            "Batch 52, Loss: 0.2036093920469284\n",
            "Batch 53, Loss: 0.12855419516563416\n",
            "Batch 54, Loss: 0.40598011016845703\n",
            "Batch 55, Loss: 0.2482108473777771\n",
            "Batch 56, Loss: 0.17505650222301483\n",
            "Batch 57, Loss: 0.1871872842311859\n",
            "Batch 58, Loss: 0.1729070097208023\n",
            "Batch 59, Loss: 0.13870108127593994\n",
            "Batch 60, Loss: 0.24571502208709717\n",
            "Batch 61, Loss: 0.1283104419708252\n",
            "Batch 62, Loss: 0.1228710263967514\n",
            "Batch 63, Loss: 0.2054125815629959\n",
            "Batch 64, Loss: 0.22526013851165771\n",
            "Batch 65, Loss: 0.159469872713089\n",
            "Batch 66, Loss: 0.21825158596038818\n",
            "Batch 67, Loss: 0.1420098841190338\n",
            "Batch 68, Loss: 0.17391279339790344\n",
            "Batch 69, Loss: 0.08010440319776535\n",
            "Batch 70, Loss: 0.22016695141792297\n",
            "Batch 71, Loss: 0.1272120475769043\n",
            "Batch 72, Loss: 0.3222867548465729\n",
            "Batch 73, Loss: 0.19650718569755554\n",
            "Batch 74, Loss: 0.3473931849002838\n",
            "Batch 75, Loss: 0.2923709750175476\n",
            "Batch 76, Loss: 0.1291901171207428\n",
            "Batch 77, Loss: 0.13584807515144348\n",
            "Batch 78, Loss: 0.23554737865924835\n",
            "Batch 79, Loss: 0.18203802406787872\n",
            "Batch 80, Loss: 0.19202354550361633\n",
            "Batch 81, Loss: 0.19710373878479004\n",
            "Batch 82, Loss: 0.24832099676132202\n",
            "Batch 83, Loss: 0.1592814326286316\n",
            "Batch 84, Loss: 0.21534478664398193\n",
            "Batch 85, Loss: 0.17176729440689087\n",
            "Batch 86, Loss: 0.1306886523962021\n",
            "Batch 87, Loss: 0.3483915328979492\n",
            "Batch 88, Loss: 0.19180771708488464\n",
            "Batch 89, Loss: 0.18119458854198456\n",
            "Batch 90, Loss: 0.3245118260383606\n",
            "Batch 91, Loss: 0.16649606823921204\n",
            "Batch 92, Loss: 0.24079327285289764\n",
            "Batch 93, Loss: 0.09853044152259827\n",
            "Batch 94, Loss: 0.13399550318717957\n",
            "Batch 95, Loss: 0.1564670205116272\n",
            "Batch 96, Loss: 0.16255301237106323\n",
            "Batch 97, Loss: 0.19598343968391418\n",
            "Batch 98, Loss: 0.1764310598373413\n",
            "Batch 99, Loss: 0.18204782903194427\n",
            "Batch 100, Loss: 0.36908072233200073\n",
            "Batch 101, Loss: 0.1934414505958557\n",
            "Batch 102, Loss: 0.188396155834198\n",
            "Batch 103, Loss: 0.2342745065689087\n",
            "Batch 104, Loss: 0.20048323273658752\n",
            "Batch 105, Loss: 0.11410040408372879\n",
            "Batch 106, Loss: 0.2415677011013031\n",
            "Batch 107, Loss: 0.2923380434513092\n",
            "Batch 108, Loss: 0.1689824014902115\n",
            "Batch 109, Loss: 0.2789843678474426\n",
            "Batch 110, Loss: 0.14009058475494385\n",
            "Batch 111, Loss: 0.16282379627227783\n",
            "Batch 112, Loss: 0.14947478473186493\n",
            "Batch 113, Loss: 0.33319127559661865\n",
            "Batch 114, Loss: 0.13907596468925476\n",
            "Batch 115, Loss: 0.19741177558898926\n",
            "Batch 116, Loss: 0.15688684582710266\n",
            "Batch 117, Loss: 0.14786100387573242\n",
            "Batch 118, Loss: 0.21810251474380493\n",
            "Batch 119, Loss: 0.21338121592998505\n",
            "Batch 120, Loss: 0.1022430807352066\n",
            "Batch 121, Loss: 0.31461411714553833\n",
            "Batch 122, Loss: 0.1125645861029625\n",
            "Batch 123, Loss: 0.21957814693450928\n",
            "Batch 124, Loss: 0.25776660442352295\n",
            "Batch 125, Loss: 0.16481128334999084\n",
            "Batch 126, Loss: 0.1657654047012329\n",
            "Batch 127, Loss: 0.15676695108413696\n",
            "Batch 128, Loss: 0.13892164826393127\n",
            "Batch 129, Loss: 0.22415250539779663\n",
            "Batch 130, Loss: 0.18298278748989105\n",
            "Batch 131, Loss: 0.15526390075683594\n",
            "Batch 132, Loss: 0.2508619427680969\n",
            "Batch 133, Loss: 0.1663929522037506\n",
            "Batch 134, Loss: 0.17522001266479492\n",
            "Batch 135, Loss: 0.34108462929725647\n",
            "Batch 136, Loss: 0.19751128554344177\n",
            "Batch 137, Loss: 0.30677464604377747\n",
            "Batch 138, Loss: 0.17726117372512817\n",
            "Batch 139, Loss: 0.15173271298408508\n",
            "Batch 140, Loss: 0.2827863097190857\n",
            "Batch 141, Loss: 0.2033727467060089\n",
            "Batch 142, Loss: 0.1936456859111786\n",
            "Batch 143, Loss: 0.12964007258415222\n",
            "Batch 144, Loss: 0.21733447909355164\n",
            "Batch 145, Loss: 0.19035011529922485\n",
            "Batch 146, Loss: 0.12656357884407043\n",
            "Batch 147, Loss: 0.26064664125442505\n",
            "Batch 148, Loss: 0.2817000150680542\n",
            "Batch 149, Loss: 0.23382408916950226\n",
            "Batch 150, Loss: 0.21426348388195038\n",
            "Batch 151, Loss: 0.15538081526756287\n",
            "Batch 152, Loss: 0.18796683847904205\n",
            "Batch 153, Loss: 0.07872070372104645\n",
            "Batch 154, Loss: 0.24057289958000183\n",
            "Batch 155, Loss: 0.26866406202316284\n",
            "Batch 156, Loss: 0.2777682840824127\n",
            "Batch 157, Loss: 0.13718491792678833\n",
            "Batch 158, Loss: 0.2005424201488495\n",
            "Batch 159, Loss: 0.27448633313179016\n",
            "Batch 160, Loss: 0.18144504725933075\n",
            "Batch 161, Loss: 0.17602422833442688\n",
            "Batch 162, Loss: 0.17239588499069214\n",
            "Batch 163, Loss: 0.09162424504756927\n",
            "Batch 164, Loss: 0.1583392173051834\n",
            "Batch 165, Loss: 0.19201220571994781\n",
            "Batch 166, Loss: 0.17603176832199097\n",
            "Batch 167, Loss: 0.18941116333007812\n",
            "Batch 168, Loss: 0.13945984840393066\n",
            "Batch 169, Loss: 0.2753075957298279\n",
            "Batch 170, Loss: 0.18739095330238342\n",
            "Batch 171, Loss: 0.1643921136856079\n",
            "Batch 172, Loss: 0.2348947376012802\n",
            "Batch 173, Loss: 0.25810056924819946\n",
            "Batch 174, Loss: 0.3116886615753174\n",
            "Batch 175, Loss: 0.20148780941963196\n",
            "Batch 176, Loss: 0.15905573964118958\n",
            "Batch 177, Loss: 0.24727652966976166\n",
            "Batch 178, Loss: 0.20536571741104126\n",
            "Batch 179, Loss: 0.12543335556983948\n",
            "Batch 180, Loss: 0.1322961151599884\n",
            "Batch 181, Loss: 0.31674742698669434\n",
            "Batch 182, Loss: 0.5378087162971497\n",
            "Batch 183, Loss: 0.2992996871471405\n",
            "Batch 184, Loss: 0.2559788227081299\n",
            "Batch 185, Loss: 0.2839117646217346\n",
            "Batch 186, Loss: 0.22876031696796417\n",
            "Batch 187, Loss: 0.2882523536682129\n",
            "Batch 188, Loss: 0.25032854080200195\n",
            "Batch 189, Loss: 0.17305584251880646\n",
            "Batch 190, Loss: 0.29758545756340027\n",
            "Batch 191, Loss: 0.2662009000778198\n",
            "Batch 192, Loss: 0.21811531484127045\n",
            "Batch 193, Loss: 0.18680033087730408\n",
            "Batch 194, Loss: 0.1962864100933075\n",
            "Batch 195, Loss: 0.24741913378238678\n",
            "Batch 196, Loss: 0.2315075546503067\n",
            "Batch 197, Loss: 0.1498926877975464\n",
            "Batch 198, Loss: 0.38182246685028076\n",
            "Batch 199, Loss: 0.21037447452545166\n",
            "Batch 200, Loss: 0.15209488570690155\n",
            "Batch 201, Loss: 0.3066520690917969\n",
            "Batch 202, Loss: 0.28552377223968506\n",
            "Batch 203, Loss: 0.07950708270072937\n",
            "Batch 204, Loss: 0.25043153762817383\n",
            "Batch 205, Loss: 0.20821638405323029\n",
            "Batch 206, Loss: 0.20331557095050812\n",
            "Batch 207, Loss: 0.34399253129959106\n",
            "Batch 208, Loss: 0.3533834218978882\n",
            "Batch 209, Loss: 0.31268179416656494\n",
            "Batch 210, Loss: 0.17140516638755798\n",
            "Batch 211, Loss: 0.1834762990474701\n",
            "Batch 212, Loss: 0.13358432054519653\n",
            "Batch 213, Loss: 0.22604982554912567\n",
            "Batch 214, Loss: 0.48907092213630676\n",
            "Batch 215, Loss: 0.1834190934896469\n",
            "Batch 216, Loss: 0.26195788383483887\n",
            "Batch 217, Loss: 0.17354841530323029\n",
            "Batch 218, Loss: 0.3445659279823303\n",
            "Batch 219, Loss: 0.15476620197296143\n",
            "Batch 220, Loss: 0.28052574396133423\n",
            "Batch 221, Loss: 0.2756524085998535\n",
            "Batch 222, Loss: 0.40394526720046997\n",
            "Batch 223, Loss: 0.25808703899383545\n",
            "Batch 224, Loss: 0.18873845040798187\n",
            "Batch 225, Loss: 0.17221859097480774\n",
            "Batch 226, Loss: 0.18933889269828796\n",
            "Batch 227, Loss: 0.1820550411939621\n",
            "Batch 228, Loss: 0.17854762077331543\n",
            "Batch 229, Loss: 0.20232313871383667\n",
            "Batch 230, Loss: 0.16843421757221222\n",
            "Epoch 44, Loss: 0.16843421757221222\n",
            "Batch 1, Loss: 0.1341811865568161\n",
            "Batch 2, Loss: 0.13446642458438873\n",
            "Batch 3, Loss: 0.16181062161922455\n",
            "Batch 4, Loss: 0.22188380360603333\n",
            "Batch 5, Loss: 0.3898801803588867\n",
            "Batch 6, Loss: 0.11284072697162628\n",
            "Batch 7, Loss: 0.17370128631591797\n",
            "Batch 8, Loss: 0.20055462419986725\n",
            "Batch 9, Loss: 0.1854555308818817\n",
            "Batch 10, Loss: 0.15399271249771118\n",
            "Batch 11, Loss: 0.08398877084255219\n",
            "Batch 12, Loss: 0.1323712319135666\n",
            "Batch 13, Loss: 0.14465823769569397\n",
            "Batch 14, Loss: 0.16896307468414307\n",
            "Batch 15, Loss: 0.3061617314815521\n",
            "Batch 16, Loss: 0.2787032127380371\n",
            "Batch 17, Loss: 0.1541481465101242\n",
            "Batch 18, Loss: 0.2996320426464081\n",
            "Batch 19, Loss: 0.14910194277763367\n",
            "Batch 20, Loss: 0.10662322491407394\n",
            "Batch 21, Loss: 0.12843787670135498\n",
            "Batch 22, Loss: 0.2251724898815155\n",
            "Batch 23, Loss: 0.16399790346622467\n",
            "Batch 24, Loss: 0.26670217514038086\n",
            "Batch 25, Loss: 0.12173494696617126\n",
            "Batch 26, Loss: 0.1592063009738922\n",
            "Batch 27, Loss: 0.13881729543209076\n",
            "Batch 28, Loss: 0.16844776272773743\n",
            "Batch 29, Loss: 0.2494891881942749\n",
            "Batch 30, Loss: 0.12848402559757233\n",
            "Batch 31, Loss: 0.15234993398189545\n",
            "Batch 32, Loss: 0.10268080234527588\n",
            "Batch 33, Loss: 0.15418466925621033\n",
            "Batch 34, Loss: 0.17977412045001984\n",
            "Batch 35, Loss: 0.21068808436393738\n",
            "Batch 36, Loss: 0.1318453699350357\n",
            "Batch 37, Loss: 0.1320411115884781\n",
            "Batch 38, Loss: 0.12812776863574982\n",
            "Batch 39, Loss: 0.12779656052589417\n",
            "Batch 40, Loss: 0.23735490441322327\n",
            "Batch 41, Loss: 0.15426239371299744\n",
            "Batch 42, Loss: 0.16100552678108215\n",
            "Batch 43, Loss: 0.20562224090099335\n",
            "Batch 44, Loss: 0.27502599358558655\n",
            "Batch 45, Loss: 0.22683949768543243\n",
            "Batch 46, Loss: 0.16854751110076904\n",
            "Batch 47, Loss: 0.11003738641738892\n",
            "Batch 48, Loss: 0.09221546351909637\n",
            "Batch 49, Loss: 0.09799423813819885\n",
            "Batch 50, Loss: 0.20635242760181427\n",
            "Batch 51, Loss: 0.12986266613006592\n",
            "Batch 52, Loss: 0.23601263761520386\n",
            "Batch 53, Loss: 0.06850804388523102\n",
            "Batch 54, Loss: 0.1456700563430786\n",
            "Batch 55, Loss: 0.09971311688423157\n",
            "Batch 56, Loss: 0.135184645652771\n",
            "Batch 57, Loss: 0.22250312566757202\n",
            "Batch 58, Loss: 0.14032647013664246\n",
            "Batch 59, Loss: 0.09866536408662796\n",
            "Batch 60, Loss: 0.2205209583044052\n",
            "Batch 61, Loss: 0.12914510071277618\n",
            "Batch 62, Loss: 0.1416555941104889\n",
            "Batch 63, Loss: 0.19192111492156982\n",
            "Batch 64, Loss: 0.18870513141155243\n",
            "Batch 65, Loss: 0.1742093712091446\n",
            "Batch 66, Loss: 0.2501169443130493\n",
            "Batch 67, Loss: 0.14186999201774597\n",
            "Batch 68, Loss: 0.15733760595321655\n",
            "Batch 69, Loss: 0.19603335857391357\n",
            "Batch 70, Loss: 0.18367379903793335\n",
            "Batch 71, Loss: 0.10661055892705917\n",
            "Batch 72, Loss: 0.10966627299785614\n",
            "Batch 73, Loss: 0.16525916755199432\n",
            "Batch 74, Loss: 0.15787871181964874\n",
            "Batch 75, Loss: 0.15784430503845215\n",
            "Batch 76, Loss: 0.1047946959733963\n",
            "Batch 77, Loss: 0.20608222484588623\n",
            "Batch 78, Loss: 0.1743723601102829\n",
            "Batch 79, Loss: 0.16929247975349426\n",
            "Batch 80, Loss: 0.12224022299051285\n",
            "Batch 81, Loss: 0.21630354225635529\n",
            "Batch 82, Loss: 0.22764407098293304\n",
            "Batch 83, Loss: 0.16196605563163757\n",
            "Batch 84, Loss: 0.1858680248260498\n",
            "Batch 85, Loss: 0.17582961916923523\n",
            "Batch 86, Loss: 0.17125552892684937\n",
            "Batch 87, Loss: 0.09343841671943665\n",
            "Batch 88, Loss: 0.1370425522327423\n",
            "Batch 89, Loss: 0.11791781336069107\n",
            "Batch 90, Loss: 0.16764529049396515\n",
            "Batch 91, Loss: 0.12845084071159363\n",
            "Batch 92, Loss: 0.16406595706939697\n",
            "Batch 93, Loss: 0.08509067445993423\n",
            "Batch 94, Loss: 0.16220790147781372\n",
            "Batch 95, Loss: 0.1483457237482071\n",
            "Batch 96, Loss: 0.11050623655319214\n",
            "Batch 97, Loss: 0.1750059574842453\n",
            "Batch 98, Loss: 0.18875080347061157\n",
            "Batch 99, Loss: 0.20849040150642395\n",
            "Batch 100, Loss: 0.17503690719604492\n",
            "Batch 101, Loss: 0.1859111785888672\n",
            "Batch 102, Loss: 0.11802324652671814\n",
            "Batch 103, Loss: 0.1155475303530693\n",
            "Batch 104, Loss: 0.126899853348732\n",
            "Batch 105, Loss: 0.11446218937635422\n",
            "Batch 106, Loss: 0.16659501194953918\n",
            "Batch 107, Loss: 0.14028865098953247\n",
            "Batch 108, Loss: 0.0989568680524826\n",
            "Batch 109, Loss: 0.12208845466375351\n",
            "Batch 110, Loss: 0.17988994717597961\n",
            "Batch 111, Loss: 0.21359799802303314\n",
            "Batch 112, Loss: 0.1185254454612732\n",
            "Batch 113, Loss: 0.18750858306884766\n",
            "Batch 114, Loss: 0.12424187362194061\n",
            "Batch 115, Loss: 0.1286572515964508\n",
            "Batch 116, Loss: 0.1372552216053009\n",
            "Batch 117, Loss: 0.17398877441883087\n",
            "Batch 118, Loss: 0.19976837933063507\n",
            "Batch 119, Loss: 0.15824243426322937\n",
            "Batch 120, Loss: 0.14566759765148163\n",
            "Batch 121, Loss: 0.227447971701622\n",
            "Batch 122, Loss: 0.21236461400985718\n",
            "Batch 123, Loss: 0.17816120386123657\n",
            "Batch 124, Loss: 0.17082470655441284\n",
            "Batch 125, Loss: 0.10862390697002411\n",
            "Batch 126, Loss: 0.1511421799659729\n",
            "Batch 127, Loss: 0.18620911240577698\n",
            "Batch 128, Loss: 0.22838416695594788\n",
            "Batch 129, Loss: 0.297682523727417\n",
            "Batch 130, Loss: 0.16557134687900543\n",
            "Batch 131, Loss: 0.23949536681175232\n",
            "Batch 132, Loss: 0.22220300137996674\n",
            "Batch 133, Loss: 0.25427326560020447\n",
            "Batch 134, Loss: 0.21101407706737518\n",
            "Batch 135, Loss: 0.1288810819387436\n",
            "Batch 136, Loss: 0.309347540140152\n",
            "Batch 137, Loss: 0.24217498302459717\n",
            "Batch 138, Loss: 0.2617669105529785\n",
            "Batch 139, Loss: 0.16522133350372314\n",
            "Batch 140, Loss: 0.34457048773765564\n",
            "Batch 141, Loss: 0.17853455245494843\n",
            "Batch 142, Loss: 0.23487308621406555\n",
            "Batch 143, Loss: 0.23917663097381592\n",
            "Batch 144, Loss: 0.16539651155471802\n",
            "Batch 145, Loss: 0.13011682033538818\n",
            "Batch 146, Loss: 0.19728398323059082\n",
            "Batch 147, Loss: 0.2338438779115677\n",
            "Batch 148, Loss: 0.1524893343448639\n",
            "Batch 149, Loss: 0.26496896147727966\n",
            "Batch 150, Loss: 0.16429904103279114\n",
            "Batch 151, Loss: 0.17475005984306335\n",
            "Batch 152, Loss: 0.1556045114994049\n",
            "Batch 153, Loss: 0.23811739683151245\n",
            "Batch 154, Loss: 0.18458330631256104\n",
            "Batch 155, Loss: 0.14504374563694\n",
            "Batch 156, Loss: 0.18944889307022095\n",
            "Batch 157, Loss: 0.14443278312683105\n",
            "Batch 158, Loss: 0.2286626696586609\n",
            "Batch 159, Loss: 0.17862191796302795\n",
            "Batch 160, Loss: 0.20418033003807068\n",
            "Batch 161, Loss: 0.2687992453575134\n",
            "Batch 162, Loss: 0.14414215087890625\n",
            "Batch 163, Loss: 0.2642287015914917\n",
            "Batch 164, Loss: 0.3590012490749359\n",
            "Batch 165, Loss: 0.14965975284576416\n",
            "Batch 166, Loss: 0.316863477230072\n",
            "Batch 167, Loss: 0.20962998270988464\n",
            "Batch 168, Loss: 0.2711704671382904\n",
            "Batch 169, Loss: 0.16083937883377075\n",
            "Batch 170, Loss: 0.17046597599983215\n",
            "Batch 171, Loss: 0.15806138515472412\n",
            "Batch 172, Loss: 0.08771258592605591\n",
            "Batch 173, Loss: 0.17462535202503204\n",
            "Batch 174, Loss: 0.2641323506832123\n",
            "Batch 175, Loss: 0.2079818844795227\n",
            "Batch 176, Loss: 0.3196983337402344\n",
            "Batch 177, Loss: 0.1980346441268921\n",
            "Batch 178, Loss: 0.16324841976165771\n",
            "Batch 179, Loss: 0.21454504132270813\n",
            "Batch 180, Loss: 0.25579923391342163\n",
            "Batch 181, Loss: 0.20382195711135864\n",
            "Batch 182, Loss: 0.29166895151138306\n",
            "Batch 183, Loss: 0.1164664551615715\n",
            "Batch 184, Loss: 0.23593361675739288\n",
            "Batch 185, Loss: 0.19006997346878052\n",
            "Batch 186, Loss: 0.12486506998538971\n",
            "Batch 187, Loss: 0.24309390783309937\n",
            "Batch 188, Loss: 0.18296092748641968\n",
            "Batch 189, Loss: 0.1857069730758667\n",
            "Batch 190, Loss: 0.2876748740673065\n",
            "Batch 191, Loss: 0.3481678366661072\n",
            "Batch 192, Loss: 0.13288626074790955\n",
            "Batch 193, Loss: 0.1362035572528839\n",
            "Batch 194, Loss: 0.2856828570365906\n",
            "Batch 195, Loss: 0.1879476010799408\n",
            "Batch 196, Loss: 0.16471123695373535\n",
            "Batch 197, Loss: 0.27286872267723083\n",
            "Batch 198, Loss: 0.29883962869644165\n",
            "Batch 199, Loss: 0.14908908307552338\n",
            "Batch 200, Loss: 0.14497792720794678\n",
            "Batch 201, Loss: 0.39961832761764526\n",
            "Batch 202, Loss: 0.3373301029205322\n",
            "Batch 203, Loss: 0.4291374683380127\n",
            "Batch 204, Loss: 0.3779515326023102\n",
            "Batch 205, Loss: 0.22729457914829254\n",
            "Batch 206, Loss: 0.1918742060661316\n",
            "Batch 207, Loss: 0.17475347220897675\n",
            "Batch 208, Loss: 0.23738303780555725\n",
            "Batch 209, Loss: 0.1726056933403015\n",
            "Batch 210, Loss: 0.31550103425979614\n",
            "Batch 211, Loss: 0.2047862708568573\n",
            "Batch 212, Loss: 0.1372462511062622\n",
            "Batch 213, Loss: 0.43321502208709717\n",
            "Batch 214, Loss: 0.20347093045711517\n",
            "Batch 215, Loss: 0.1287863850593567\n",
            "Batch 216, Loss: 0.301466703414917\n",
            "Batch 217, Loss: 0.21758443117141724\n",
            "Batch 218, Loss: 0.20231486856937408\n",
            "Batch 219, Loss: 0.15583232045173645\n",
            "Batch 220, Loss: 0.23695702850818634\n",
            "Batch 221, Loss: 0.2785492539405823\n",
            "Batch 222, Loss: 0.25017160177230835\n",
            "Batch 223, Loss: 0.2627296447753906\n",
            "Batch 224, Loss: 0.14864960312843323\n",
            "Batch 225, Loss: 0.1969609260559082\n",
            "Batch 226, Loss: 0.3609847128391266\n",
            "Batch 227, Loss: 0.2441336214542389\n",
            "Batch 228, Loss: 0.20585492253303528\n",
            "Batch 229, Loss: 0.23239266872406006\n",
            "Batch 230, Loss: 0.18908219039440155\n",
            "Epoch 45, Loss: 0.18908219039440155\n",
            "Batch 1, Loss: 0.16045504808425903\n",
            "Batch 2, Loss: 0.29479119181632996\n",
            "Batch 3, Loss: 0.2159350961446762\n",
            "Batch 4, Loss: 0.20102593302726746\n",
            "Batch 5, Loss: 0.2916485667228699\n",
            "Batch 6, Loss: 0.2459625005722046\n",
            "Batch 7, Loss: 0.3808485269546509\n",
            "Batch 8, Loss: 0.12926459312438965\n",
            "Batch 9, Loss: 0.16314828395843506\n",
            "Batch 10, Loss: 0.21739308536052704\n",
            "Batch 11, Loss: 0.15837028622627258\n",
            "Batch 12, Loss: 0.40839627385139465\n",
            "Batch 13, Loss: 0.4296644926071167\n",
            "Batch 14, Loss: 0.14735066890716553\n",
            "Batch 15, Loss: 0.13167217373847961\n",
            "Batch 16, Loss: 0.4494473934173584\n",
            "Batch 17, Loss: 0.19806167483329773\n",
            "Batch 18, Loss: 0.30814066529273987\n",
            "Batch 19, Loss: 0.2693096101284027\n",
            "Batch 20, Loss: 0.12296859920024872\n",
            "Batch 21, Loss: 0.2736800014972687\n",
            "Batch 22, Loss: 0.16996510326862335\n",
            "Batch 23, Loss: 0.21132086217403412\n",
            "Batch 24, Loss: 0.17315232753753662\n",
            "Batch 25, Loss: 0.15180717408657074\n",
            "Batch 26, Loss: 0.12780296802520752\n",
            "Batch 27, Loss: 0.3397139608860016\n",
            "Batch 28, Loss: 0.3856835961341858\n",
            "Batch 29, Loss: 0.13044176995754242\n",
            "Batch 30, Loss: 0.15686823427677155\n",
            "Batch 31, Loss: 0.3185836672782898\n",
            "Batch 32, Loss: 0.12710943818092346\n",
            "Batch 33, Loss: 0.19191622734069824\n",
            "Batch 34, Loss: 0.19204716384410858\n",
            "Batch 35, Loss: 0.3296792507171631\n",
            "Batch 36, Loss: 0.18636086583137512\n",
            "Batch 37, Loss: 0.14736254513263702\n",
            "Batch 38, Loss: 0.1498498171567917\n",
            "Batch 39, Loss: 0.2661760449409485\n",
            "Batch 40, Loss: 0.15990501642227173\n",
            "Batch 41, Loss: 0.2326631098985672\n",
            "Batch 42, Loss: 0.23412175476551056\n",
            "Batch 43, Loss: 0.11531287431716919\n",
            "Batch 44, Loss: 0.1623312532901764\n",
            "Batch 45, Loss: 0.4277075231075287\n",
            "Batch 46, Loss: 0.2618936598300934\n",
            "Batch 47, Loss: 0.26516684889793396\n",
            "Batch 48, Loss: 0.0996854230761528\n",
            "Batch 49, Loss: 0.220939502120018\n",
            "Batch 50, Loss: 0.39189383387565613\n",
            "Batch 51, Loss: 0.24035054445266724\n",
            "Batch 52, Loss: 0.456770658493042\n",
            "Batch 53, Loss: 0.20015250146389008\n",
            "Batch 54, Loss: 0.143305242061615\n",
            "Batch 55, Loss: 0.20177000761032104\n",
            "Batch 56, Loss: 0.14119607210159302\n",
            "Batch 57, Loss: 0.18412601947784424\n",
            "Batch 58, Loss: 0.17771026492118835\n",
            "Batch 59, Loss: 0.1511993408203125\n",
            "Batch 60, Loss: 0.125253826379776\n",
            "Batch 61, Loss: 0.24902018904685974\n",
            "Batch 62, Loss: 0.11701491475105286\n",
            "Batch 63, Loss: 0.21986320614814758\n",
            "Batch 64, Loss: 0.2401113063097\n",
            "Batch 65, Loss: 0.1492689996957779\n",
            "Batch 66, Loss: 0.4053373336791992\n",
            "Batch 67, Loss: 0.19835758209228516\n",
            "Batch 68, Loss: 0.18950287997722626\n",
            "Batch 69, Loss: 0.15401682257652283\n",
            "Batch 70, Loss: 0.20698122680187225\n",
            "Batch 71, Loss: 0.25255340337753296\n",
            "Batch 72, Loss: 0.14808088541030884\n",
            "Batch 73, Loss: 0.2418144941329956\n",
            "Batch 74, Loss: 0.20169702172279358\n",
            "Batch 75, Loss: 0.1979997754096985\n",
            "Batch 76, Loss: 0.20641572773456573\n",
            "Batch 77, Loss: 0.14590829610824585\n",
            "Batch 78, Loss: 0.08966157585382462\n",
            "Batch 79, Loss: 0.16009308397769928\n",
            "Batch 80, Loss: 0.38325291872024536\n",
            "Batch 81, Loss: 0.1407560408115387\n",
            "Batch 82, Loss: 0.18317192792892456\n",
            "Batch 83, Loss: 0.12169349193572998\n",
            "Batch 84, Loss: 0.31831467151641846\n",
            "Batch 85, Loss: 0.1163165494799614\n",
            "Batch 86, Loss: 0.15391314029693604\n",
            "Batch 87, Loss: 0.16407501697540283\n",
            "Batch 88, Loss: 0.17253327369689941\n",
            "Batch 89, Loss: 0.1153898611664772\n",
            "Batch 90, Loss: 0.21827314794063568\n",
            "Batch 91, Loss: 0.1625899374485016\n",
            "Batch 92, Loss: 0.18676802515983582\n",
            "Batch 93, Loss: 0.2575693130493164\n",
            "Batch 94, Loss: 0.13552406430244446\n",
            "Batch 95, Loss: 0.20917515456676483\n",
            "Batch 96, Loss: 0.21385884284973145\n",
            "Batch 97, Loss: 0.23604214191436768\n",
            "Batch 98, Loss: 0.16029322147369385\n",
            "Batch 99, Loss: 0.19360896944999695\n",
            "Batch 100, Loss: 0.21243968605995178\n",
            "Batch 101, Loss: 0.15064948797225952\n",
            "Batch 102, Loss: 0.13357317447662354\n",
            "Batch 103, Loss: 0.2713173031806946\n",
            "Batch 104, Loss: 0.1001376062631607\n",
            "Batch 105, Loss: 0.17651499807834625\n",
            "Batch 106, Loss: 0.316392719745636\n",
            "Batch 107, Loss: 0.29756611585617065\n",
            "Batch 108, Loss: 0.17426040768623352\n",
            "Batch 109, Loss: 0.2990734279155731\n",
            "Batch 110, Loss: 0.23418739438056946\n",
            "Batch 111, Loss: 0.13604560494422913\n",
            "Batch 112, Loss: 0.17481276392936707\n",
            "Batch 113, Loss: 0.24223503470420837\n",
            "Batch 114, Loss: 0.16435101628303528\n",
            "Batch 115, Loss: 0.1424408257007599\n",
            "Batch 116, Loss: 0.28920841217041016\n",
            "Batch 117, Loss: 0.18425872921943665\n",
            "Batch 118, Loss: 0.12169808149337769\n",
            "Batch 119, Loss: 0.20837512612342834\n",
            "Batch 120, Loss: 0.18209746479988098\n",
            "Batch 121, Loss: 0.19960951805114746\n",
            "Batch 122, Loss: 0.20775669813156128\n",
            "Batch 123, Loss: 0.24400264024734497\n",
            "Batch 124, Loss: 0.1719590127468109\n",
            "Batch 125, Loss: 0.20163549482822418\n",
            "Batch 126, Loss: 0.22193768620491028\n",
            "Batch 127, Loss: 0.20575924217700958\n",
            "Batch 128, Loss: 0.33735543489456177\n",
            "Batch 129, Loss: 0.16082517802715302\n",
            "Batch 130, Loss: 0.22583909332752228\n",
            "Batch 131, Loss: 0.13257572054862976\n",
            "Batch 132, Loss: 0.25630444288253784\n",
            "Batch 133, Loss: 0.18940147757530212\n",
            "Batch 134, Loss: 0.3585982024669647\n",
            "Batch 135, Loss: 0.27685439586639404\n",
            "Batch 136, Loss: 0.21423916518688202\n",
            "Batch 137, Loss: 0.0803661122918129\n",
            "Batch 138, Loss: 0.20782750844955444\n",
            "Batch 139, Loss: 0.14967289566993713\n",
            "Batch 140, Loss: 0.1743622124195099\n",
            "Batch 141, Loss: 0.22915060818195343\n",
            "Batch 142, Loss: 0.16488610208034515\n",
            "Batch 143, Loss: 0.3118962347507477\n",
            "Batch 144, Loss: 0.1372019648551941\n",
            "Batch 145, Loss: 0.23557201027870178\n",
            "Batch 146, Loss: 0.2481587827205658\n",
            "Batch 147, Loss: 0.14459168910980225\n",
            "Batch 148, Loss: 0.20884305238723755\n",
            "Batch 149, Loss: 0.1306537389755249\n",
            "Batch 150, Loss: 0.21222132444381714\n",
            "Batch 151, Loss: 0.19707566499710083\n",
            "Batch 152, Loss: 0.15939943492412567\n",
            "Batch 153, Loss: 0.1077549085021019\n",
            "Batch 154, Loss: 0.3369673490524292\n",
            "Batch 155, Loss: 0.2153375744819641\n",
            "Batch 156, Loss: 0.3446592688560486\n",
            "Batch 157, Loss: 0.2355317622423172\n",
            "Batch 158, Loss: 0.20092490315437317\n",
            "Batch 159, Loss: 0.16977360844612122\n",
            "Batch 160, Loss: 0.24135883152484894\n",
            "Batch 161, Loss: 0.1723150610923767\n",
            "Batch 162, Loss: 0.2530079483985901\n",
            "Batch 163, Loss: 0.09179859608411789\n",
            "Batch 164, Loss: 0.1642417311668396\n",
            "Batch 165, Loss: 0.09250734746456146\n",
            "Batch 166, Loss: 0.2852010726928711\n",
            "Batch 167, Loss: 0.2516118586063385\n",
            "Batch 168, Loss: 0.26732805371284485\n",
            "Batch 169, Loss: 0.1634417176246643\n",
            "Batch 170, Loss: 0.272330641746521\n",
            "Batch 171, Loss: 0.128856360912323\n",
            "Batch 172, Loss: 0.28778693079948425\n",
            "Batch 173, Loss: 0.2708333134651184\n",
            "Batch 174, Loss: 0.1536594182252884\n",
            "Batch 175, Loss: 0.22120369970798492\n",
            "Batch 176, Loss: 0.3784812390804291\n",
            "Batch 177, Loss: 0.19390541315078735\n",
            "Batch 178, Loss: 0.15544454753398895\n",
            "Batch 179, Loss: 0.3051590919494629\n",
            "Batch 180, Loss: 0.1902001053094864\n",
            "Batch 181, Loss: 0.2723478674888611\n",
            "Batch 182, Loss: 0.19863615930080414\n",
            "Batch 183, Loss: 0.2615206837654114\n",
            "Batch 184, Loss: 0.29151931405067444\n",
            "Batch 185, Loss: 0.2379569411277771\n",
            "Batch 186, Loss: 0.2276429682970047\n",
            "Batch 187, Loss: 0.15774038434028625\n",
            "Batch 188, Loss: 0.26886069774627686\n",
            "Batch 189, Loss: 0.2748587429523468\n",
            "Batch 190, Loss: 0.17943590879440308\n",
            "Batch 191, Loss: 0.19617852568626404\n",
            "Batch 192, Loss: 0.1726781129837036\n",
            "Batch 193, Loss: 0.2563621401786804\n",
            "Batch 194, Loss: 0.30533596873283386\n",
            "Batch 195, Loss: 0.3804938793182373\n",
            "Batch 196, Loss: 0.38778138160705566\n",
            "Batch 197, Loss: 0.21988365054130554\n",
            "Batch 198, Loss: 0.12957438826560974\n",
            "Batch 199, Loss: 0.15261855721473694\n",
            "Batch 200, Loss: 0.34808599948883057\n",
            "Batch 201, Loss: 0.12965476512908936\n",
            "Batch 202, Loss: 0.2642446458339691\n",
            "Batch 203, Loss: 0.18149322271347046\n",
            "Batch 204, Loss: 0.19390204548835754\n",
            "Batch 205, Loss: 0.3907662034034729\n",
            "Batch 206, Loss: 0.14568567276000977\n",
            "Batch 207, Loss: 0.4220582842826843\n",
            "Batch 208, Loss: 0.19107352197170258\n",
            "Batch 209, Loss: 0.35332047939300537\n",
            "Batch 210, Loss: 0.2170066237449646\n",
            "Batch 211, Loss: 0.22251412272453308\n",
            "Batch 212, Loss: 0.2657265067100525\n",
            "Batch 213, Loss: 0.16780295968055725\n",
            "Batch 214, Loss: 0.2593507468700409\n",
            "Batch 215, Loss: 0.2538655698299408\n",
            "Batch 216, Loss: 0.3018529415130615\n",
            "Batch 217, Loss: 0.3689391613006592\n",
            "Batch 218, Loss: 0.33726853132247925\n",
            "Batch 219, Loss: 0.21218302845954895\n",
            "Batch 220, Loss: 0.42113491892814636\n",
            "Batch 221, Loss: 0.2636118531227112\n",
            "Batch 222, Loss: 0.14239326119422913\n",
            "Batch 223, Loss: 0.23633968830108643\n",
            "Batch 224, Loss: 0.23334670066833496\n",
            "Batch 225, Loss: 0.20562013983726501\n",
            "Batch 226, Loss: 0.1525871753692627\n",
            "Batch 227, Loss: 0.23407381772994995\n",
            "Batch 228, Loss: 0.26840493083000183\n",
            "Batch 229, Loss: 0.25020697712898254\n",
            "Batch 230, Loss: 0.6045976281166077\n",
            "Epoch 46, Loss: 0.6045976281166077\n",
            "Batch 1, Loss: 0.1504749357700348\n",
            "Batch 2, Loss: 0.18625029921531677\n",
            "Batch 3, Loss: 0.4111067056655884\n",
            "Batch 4, Loss: 0.17905278503894806\n",
            "Batch 5, Loss: 0.18372397124767303\n",
            "Batch 6, Loss: 0.5653032660484314\n",
            "Batch 7, Loss: 0.36466723680496216\n",
            "Batch 8, Loss: 0.20653098821640015\n",
            "Batch 9, Loss: 0.18596449494361877\n",
            "Batch 10, Loss: 0.26193469762802124\n",
            "Batch 11, Loss: 0.3394237458705902\n",
            "Batch 12, Loss: 0.3652856945991516\n",
            "Batch 13, Loss: 0.4321158826351166\n",
            "Batch 14, Loss: 0.2547931671142578\n",
            "Batch 15, Loss: 0.322055459022522\n",
            "Batch 16, Loss: 0.37263888120651245\n",
            "Batch 17, Loss: 0.1992470771074295\n",
            "Batch 18, Loss: 0.39088892936706543\n",
            "Batch 19, Loss: 0.2811752259731293\n",
            "Batch 20, Loss: 0.20234820246696472\n",
            "Batch 21, Loss: 0.14551794528961182\n",
            "Batch 22, Loss: 0.39488741755485535\n",
            "Batch 23, Loss: 0.16546207666397095\n",
            "Batch 24, Loss: 0.20191675424575806\n",
            "Batch 25, Loss: 0.20894598960876465\n",
            "Batch 26, Loss: 0.11681939661502838\n",
            "Batch 27, Loss: 0.35362809896469116\n",
            "Batch 28, Loss: 0.2367454618215561\n",
            "Batch 29, Loss: 0.3006252944469452\n",
            "Batch 30, Loss: 0.2555158734321594\n",
            "Batch 31, Loss: 0.17874334752559662\n",
            "Batch 32, Loss: 0.20366628468036652\n",
            "Batch 33, Loss: 0.21288743615150452\n",
            "Batch 34, Loss: 0.25895988941192627\n",
            "Batch 35, Loss: 0.2614009976387024\n",
            "Batch 36, Loss: 0.2286921590566635\n",
            "Batch 37, Loss: 0.17558147013187408\n",
            "Batch 38, Loss: 0.23811767995357513\n",
            "Batch 39, Loss: 0.17433510720729828\n",
            "Batch 40, Loss: 0.20017458498477936\n",
            "Batch 41, Loss: 0.17397646605968475\n",
            "Batch 42, Loss: 0.1320779025554657\n",
            "Batch 43, Loss: 0.17497199773788452\n",
            "Batch 44, Loss: 0.21146541833877563\n",
            "Batch 45, Loss: 0.13045328855514526\n",
            "Batch 46, Loss: 0.18849411606788635\n",
            "Batch 47, Loss: 0.24890734255313873\n",
            "Batch 48, Loss: 0.1514814794063568\n",
            "Batch 49, Loss: 0.1735086888074875\n",
            "Batch 50, Loss: 0.1420598328113556\n",
            "Batch 51, Loss: 0.2936074435710907\n",
            "Batch 52, Loss: 0.14004197716712952\n",
            "Batch 53, Loss: 0.13203519582748413\n",
            "Batch 54, Loss: 0.25715410709381104\n",
            "Batch 55, Loss: 0.15016767382621765\n",
            "Batch 56, Loss: 0.2249719202518463\n",
            "Batch 57, Loss: 0.3212134540081024\n",
            "Batch 58, Loss: 0.12875813245773315\n",
            "Batch 59, Loss: 0.1898619830608368\n",
            "Batch 60, Loss: 0.213399276137352\n",
            "Batch 61, Loss: 0.09659294784069061\n",
            "Batch 62, Loss: 0.3192521333694458\n",
            "Batch 63, Loss: 0.22378690540790558\n",
            "Batch 64, Loss: 0.15908364951610565\n",
            "Batch 65, Loss: 0.14186197519302368\n",
            "Batch 66, Loss: 0.14539667963981628\n",
            "Batch 67, Loss: 0.2452402114868164\n",
            "Batch 68, Loss: 0.2538297474384308\n",
            "Batch 69, Loss: 0.11261244118213654\n",
            "Batch 70, Loss: 0.22468245029449463\n",
            "Batch 71, Loss: 0.15265607833862305\n",
            "Batch 72, Loss: 0.19167691469192505\n",
            "Batch 73, Loss: 0.28168097138404846\n",
            "Batch 74, Loss: 0.3164784014225006\n",
            "Batch 75, Loss: 0.2321670949459076\n",
            "Batch 76, Loss: 0.15206637978553772\n",
            "Batch 77, Loss: 0.10818837583065033\n",
            "Batch 78, Loss: 0.14610351622104645\n",
            "Batch 79, Loss: 0.18329738080501556\n",
            "Batch 80, Loss: 0.28536900877952576\n",
            "Batch 81, Loss: 0.1646650731563568\n",
            "Batch 82, Loss: 0.12736548483371735\n",
            "Batch 83, Loss: 0.16001112759113312\n",
            "Batch 84, Loss: 0.2788052260875702\n",
            "Batch 85, Loss: 0.3029457926750183\n",
            "Batch 86, Loss: 0.11000359803438187\n",
            "Batch 87, Loss: 0.16815006732940674\n",
            "Batch 88, Loss: 0.16772660613059998\n",
            "Batch 89, Loss: 0.1682913452386856\n",
            "Batch 90, Loss: 0.13357101380825043\n",
            "Batch 91, Loss: 0.2853274941444397\n",
            "Batch 92, Loss: 0.11430944502353668\n",
            "Batch 93, Loss: 0.135968416929245\n",
            "Batch 94, Loss: 0.20982488989830017\n",
            "Batch 95, Loss: 0.16949208080768585\n",
            "Batch 96, Loss: 0.11096849292516708\n",
            "Batch 97, Loss: 0.1620291769504547\n",
            "Batch 98, Loss: 0.1601448357105255\n",
            "Batch 99, Loss: 0.14025478065013885\n",
            "Batch 100, Loss: 0.15000495314598083\n",
            "Batch 101, Loss: 0.12106573581695557\n",
            "Batch 102, Loss: 0.2066546082496643\n",
            "Batch 103, Loss: 0.13752885162830353\n",
            "Batch 104, Loss: 0.08040695637464523\n",
            "Batch 105, Loss: 0.1257416009902954\n",
            "Batch 106, Loss: 0.12537065148353577\n",
            "Batch 107, Loss: 0.136728897690773\n",
            "Batch 108, Loss: 0.2460092157125473\n",
            "Batch 109, Loss: 0.2598333954811096\n",
            "Batch 110, Loss: 0.14026829600334167\n",
            "Batch 111, Loss: 0.14562778174877167\n",
            "Batch 112, Loss: 0.14995963871479034\n",
            "Batch 113, Loss: 0.3339509963989258\n",
            "Batch 114, Loss: 0.18219521641731262\n",
            "Batch 115, Loss: 0.15309807658195496\n",
            "Batch 116, Loss: 0.23346395790576935\n",
            "Batch 117, Loss: 0.15890540182590485\n",
            "Batch 118, Loss: 0.16912247240543365\n",
            "Batch 119, Loss: 0.13567575812339783\n",
            "Batch 120, Loss: 0.16665826737880707\n",
            "Batch 121, Loss: 0.11039707064628601\n",
            "Batch 122, Loss: 0.18269658088684082\n",
            "Batch 123, Loss: 0.12542086839675903\n",
            "Batch 124, Loss: 0.18565279245376587\n",
            "Batch 125, Loss: 0.1700800657272339\n",
            "Batch 126, Loss: 0.1575714647769928\n",
            "Batch 127, Loss: 0.2083432972431183\n",
            "Batch 128, Loss: 0.10940045863389969\n",
            "Batch 129, Loss: 0.26211100816726685\n",
            "Batch 130, Loss: 0.16363590955734253\n",
            "Batch 131, Loss: 0.2039276361465454\n",
            "Batch 132, Loss: 0.2526550590991974\n",
            "Batch 133, Loss: 0.2205282300710678\n",
            "Batch 134, Loss: 0.16468927264213562\n",
            "Batch 135, Loss: 0.15265101194381714\n",
            "Batch 136, Loss: 0.18208888173103333\n",
            "Batch 137, Loss: 0.2069244235754013\n",
            "Batch 138, Loss: 0.1669325828552246\n",
            "Batch 139, Loss: 0.13792134821414948\n",
            "Batch 140, Loss: 0.22375203669071198\n",
            "Batch 141, Loss: 0.10190680623054504\n",
            "Batch 142, Loss: 0.18849074840545654\n",
            "Batch 143, Loss: 0.2405102401971817\n",
            "Batch 144, Loss: 0.1910838931798935\n",
            "Batch 145, Loss: 0.3416249752044678\n",
            "Batch 146, Loss: 0.21366620063781738\n",
            "Batch 147, Loss: 0.2421487718820572\n",
            "Batch 148, Loss: 0.14072085916996002\n",
            "Batch 149, Loss: 0.21315614879131317\n",
            "Batch 150, Loss: 0.13144396245479584\n",
            "Batch 151, Loss: 0.1723020076751709\n",
            "Batch 152, Loss: 0.13283558189868927\n",
            "Batch 153, Loss: 0.4290597140789032\n",
            "Batch 154, Loss: 0.15966486930847168\n",
            "Batch 155, Loss: 0.25692975521087646\n",
            "Batch 156, Loss: 0.21339963376522064\n",
            "Batch 157, Loss: 0.09926394373178482\n",
            "Batch 158, Loss: 0.19750170409679413\n",
            "Batch 159, Loss: 0.11053213477134705\n",
            "Batch 160, Loss: 0.16363181173801422\n",
            "Batch 161, Loss: 0.16651025414466858\n",
            "Batch 162, Loss: 0.2744155526161194\n",
            "Batch 163, Loss: 0.14993804693222046\n",
            "Batch 164, Loss: 0.16047152876853943\n",
            "Batch 165, Loss: 0.2680455446243286\n",
            "Batch 166, Loss: 0.1529669165611267\n",
            "Batch 167, Loss: 0.14293229579925537\n",
            "Batch 168, Loss: 0.16407683491706848\n",
            "Batch 169, Loss: 0.13392487168312073\n",
            "Batch 170, Loss: 0.25102952122688293\n",
            "Batch 171, Loss: 0.14251098036766052\n",
            "Batch 172, Loss: 0.2431863248348236\n",
            "Batch 173, Loss: 0.29867205023765564\n",
            "Batch 174, Loss: 0.13481372594833374\n",
            "Batch 175, Loss: 0.1288207322359085\n",
            "Batch 176, Loss: 0.18361124396324158\n",
            "Batch 177, Loss: 0.12033239006996155\n",
            "Batch 178, Loss: 0.2850366234779358\n",
            "Batch 179, Loss: 0.2339075654745102\n",
            "Batch 180, Loss: 0.2418936789035797\n",
            "Batch 181, Loss: 0.20860783755779266\n",
            "Batch 182, Loss: 0.09784067422151566\n",
            "Batch 183, Loss: 0.18917810916900635\n",
            "Batch 184, Loss: 0.15308654308319092\n",
            "Batch 185, Loss: 0.17498761415481567\n",
            "Batch 186, Loss: 0.0870710015296936\n",
            "Batch 187, Loss: 0.1905686855316162\n",
            "Batch 188, Loss: 0.19387872517108917\n",
            "Batch 189, Loss: 0.15815676748752594\n",
            "Batch 190, Loss: 0.12374673783779144\n",
            "Batch 191, Loss: 0.15031325817108154\n",
            "Batch 192, Loss: 0.16547131538391113\n",
            "Batch 193, Loss: 0.22503520548343658\n",
            "Batch 194, Loss: 0.14135798811912537\n",
            "Batch 195, Loss: 0.20822027325630188\n",
            "Batch 196, Loss: 0.15750879049301147\n",
            "Batch 197, Loss: 0.30578309297561646\n",
            "Batch 198, Loss: 0.2165185809135437\n",
            "Batch 199, Loss: 0.24080561101436615\n",
            "Batch 200, Loss: 0.19211649894714355\n",
            "Batch 201, Loss: 0.21913522481918335\n",
            "Batch 202, Loss: 0.22130116820335388\n",
            "Batch 203, Loss: 0.12890920042991638\n",
            "Batch 204, Loss: 0.22631072998046875\n",
            "Batch 205, Loss: 0.27202484011650085\n",
            "Batch 206, Loss: 0.21638169884681702\n",
            "Batch 207, Loss: 0.09057970345020294\n",
            "Batch 208, Loss: 0.3934803605079651\n",
            "Batch 209, Loss: 0.1702113151550293\n",
            "Batch 210, Loss: 0.1558649241924286\n",
            "Batch 211, Loss: 0.27831143140792847\n",
            "Batch 212, Loss: 0.23431843519210815\n",
            "Batch 213, Loss: 0.17650136351585388\n",
            "Batch 214, Loss: 0.3220718204975128\n",
            "Batch 215, Loss: 0.4014180898666382\n",
            "Batch 216, Loss: 0.20729026198387146\n",
            "Batch 217, Loss: 0.18341219425201416\n",
            "Batch 218, Loss: 0.3248126804828644\n",
            "Batch 219, Loss: 0.4185473918914795\n",
            "Batch 220, Loss: 0.2420330047607422\n",
            "Batch 221, Loss: 0.17381510138511658\n",
            "Batch 222, Loss: 0.24241410195827484\n",
            "Batch 223, Loss: 0.21418194472789764\n",
            "Batch 224, Loss: 0.3250548541545868\n",
            "Batch 225, Loss: 0.2133079469203949\n",
            "Batch 226, Loss: 0.3253399729728699\n",
            "Batch 227, Loss: 0.15379822254180908\n",
            "Batch 228, Loss: 0.20893552899360657\n",
            "Batch 229, Loss: 0.17406928539276123\n",
            "Batch 230, Loss: 0.16462013125419617\n",
            "Epoch 47, Loss: 0.16462013125419617\n",
            "Batch 1, Loss: 0.12707506120204926\n",
            "Batch 2, Loss: 0.18254610896110535\n",
            "Batch 3, Loss: 0.12013130635023117\n",
            "Batch 4, Loss: 0.1168360561132431\n",
            "Batch 5, Loss: 0.13577762246131897\n",
            "Batch 6, Loss: 0.11738726496696472\n",
            "Batch 7, Loss: 0.22791272401809692\n",
            "Batch 8, Loss: 0.22679254412651062\n",
            "Batch 9, Loss: 0.12178510427474976\n",
            "Batch 10, Loss: 0.20132379233837128\n",
            "Batch 11, Loss: 0.2028021514415741\n",
            "Batch 12, Loss: 0.08243859559297562\n",
            "Batch 13, Loss: 0.15025030076503754\n",
            "Batch 14, Loss: 0.08619271218776703\n",
            "Batch 15, Loss: 0.08513842523097992\n",
            "Batch 16, Loss: 0.1765907108783722\n",
            "Batch 17, Loss: 0.265018105506897\n",
            "Batch 18, Loss: 0.09978565573692322\n",
            "Batch 19, Loss: 0.07345147430896759\n",
            "Batch 20, Loss: 0.14721697568893433\n",
            "Batch 21, Loss: 0.10369841754436493\n",
            "Batch 22, Loss: 0.10717472434043884\n",
            "Batch 23, Loss: 0.14668840169906616\n",
            "Batch 24, Loss: 0.09759995341300964\n",
            "Batch 25, Loss: 0.10904116928577423\n",
            "Batch 26, Loss: 0.17230236530303955\n",
            "Batch 27, Loss: 0.1538209766149521\n",
            "Batch 28, Loss: 0.14803539216518402\n",
            "Batch 29, Loss: 0.07489913702011108\n",
            "Batch 30, Loss: 0.15078136324882507\n",
            "Batch 31, Loss: 0.13463762402534485\n",
            "Batch 32, Loss: 0.1024010106921196\n",
            "Batch 33, Loss: 0.08632920682430267\n",
            "Batch 34, Loss: 0.10700330138206482\n",
            "Batch 35, Loss: 0.1548607349395752\n",
            "Batch 36, Loss: 0.22196348011493683\n",
            "Batch 37, Loss: 0.1062934547662735\n",
            "Batch 38, Loss: 0.08029167354106903\n",
            "Batch 39, Loss: 0.10887645184993744\n",
            "Batch 40, Loss: 0.12239977717399597\n",
            "Batch 41, Loss: 0.14850667119026184\n",
            "Batch 42, Loss: 0.19162365794181824\n",
            "Batch 43, Loss: 0.1952556073665619\n",
            "Batch 44, Loss: 0.14308634400367737\n",
            "Batch 45, Loss: 0.19685544073581696\n",
            "Batch 46, Loss: 0.13928617537021637\n",
            "Batch 47, Loss: 0.19571739435195923\n",
            "Batch 48, Loss: 0.06657224893569946\n",
            "Batch 49, Loss: 0.12748876214027405\n",
            "Batch 50, Loss: 0.16302570700645447\n",
            "Batch 51, Loss: 0.14124655723571777\n",
            "Batch 52, Loss: 0.17896242439746857\n",
            "Batch 53, Loss: 0.18530477583408356\n",
            "Batch 54, Loss: 0.14439958333969116\n",
            "Batch 55, Loss: 0.12618306279182434\n",
            "Batch 56, Loss: 0.06425729393959045\n",
            "Batch 57, Loss: 0.1604200303554535\n",
            "Batch 58, Loss: 0.10876502096652985\n",
            "Batch 59, Loss: 0.16062788665294647\n",
            "Batch 60, Loss: 0.25598570704460144\n",
            "Batch 61, Loss: 0.17173877358436584\n",
            "Batch 62, Loss: 0.12507790327072144\n",
            "Batch 63, Loss: 0.2872820496559143\n",
            "Batch 64, Loss: 0.09889344871044159\n",
            "Batch 65, Loss: 0.1168956607580185\n",
            "Batch 66, Loss: 0.1356400102376938\n",
            "Batch 67, Loss: 0.1940111517906189\n",
            "Batch 68, Loss: 0.13815388083457947\n",
            "Batch 69, Loss: 0.1641537845134735\n",
            "Batch 70, Loss: 0.16109326481819153\n",
            "Batch 71, Loss: 0.1414710283279419\n",
            "Batch 72, Loss: 0.19258543848991394\n",
            "Batch 73, Loss: 0.1355912983417511\n",
            "Batch 74, Loss: 0.16269448399543762\n",
            "Batch 75, Loss: 0.13016963005065918\n",
            "Batch 76, Loss: 0.20290851593017578\n",
            "Batch 77, Loss: 0.13835826516151428\n",
            "Batch 78, Loss: 0.09215009212493896\n",
            "Batch 79, Loss: 0.08369316160678864\n",
            "Batch 80, Loss: 0.20708785951137543\n",
            "Batch 81, Loss: 0.242207333445549\n",
            "Batch 82, Loss: 0.20356091856956482\n",
            "Batch 83, Loss: 0.12895426154136658\n",
            "Batch 84, Loss: 0.16523867845535278\n",
            "Batch 85, Loss: 0.1140880286693573\n",
            "Batch 86, Loss: 0.10889621824026108\n",
            "Batch 87, Loss: 0.1620325744152069\n",
            "Batch 88, Loss: 0.17410120368003845\n",
            "Batch 89, Loss: 0.2271462380886078\n",
            "Batch 90, Loss: 0.16373120248317719\n",
            "Batch 91, Loss: 0.22100427746772766\n",
            "Batch 92, Loss: 0.20185241103172302\n",
            "Batch 93, Loss: 0.22134394943714142\n",
            "Batch 94, Loss: 0.2621535062789917\n",
            "Batch 95, Loss: 0.44223934412002563\n",
            "Batch 96, Loss: 0.2354622781276703\n",
            "Batch 97, Loss: 0.14408926665782928\n",
            "Batch 98, Loss: 0.16966423392295837\n",
            "Batch 99, Loss: 0.18368105590343475\n",
            "Batch 100, Loss: 0.16941547393798828\n",
            "Batch 101, Loss: 0.18779492378234863\n",
            "Batch 102, Loss: 0.21976116299629211\n",
            "Batch 103, Loss: 0.12586501240730286\n",
            "Batch 104, Loss: 0.13085822761058807\n",
            "Batch 105, Loss: 0.2118736207485199\n",
            "Batch 106, Loss: 0.1495327353477478\n",
            "Batch 107, Loss: 0.15778213739395142\n",
            "Batch 108, Loss: 0.17814382910728455\n",
            "Batch 109, Loss: 0.09439627081155777\n",
            "Batch 110, Loss: 0.12482002377510071\n",
            "Batch 111, Loss: 0.22571812570095062\n",
            "Batch 112, Loss: 0.15859901905059814\n",
            "Batch 113, Loss: 0.25337299704551697\n",
            "Batch 114, Loss: 0.11195774376392365\n",
            "Batch 115, Loss: 0.21142613887786865\n",
            "Batch 116, Loss: 0.2645084857940674\n",
            "Batch 117, Loss: 0.11273187398910522\n",
            "Batch 118, Loss: 0.16466602683067322\n",
            "Batch 119, Loss: 0.168802410364151\n",
            "Batch 120, Loss: 0.2309107780456543\n",
            "Batch 121, Loss: 0.20894721150398254\n",
            "Batch 122, Loss: 0.17399242520332336\n",
            "Batch 123, Loss: 0.16093941032886505\n",
            "Batch 124, Loss: 0.1798386573791504\n",
            "Batch 125, Loss: 0.13697151839733124\n",
            "Batch 126, Loss: 0.16237851977348328\n",
            "Batch 127, Loss: 0.1274929940700531\n",
            "Batch 128, Loss: 0.20708918571472168\n",
            "Batch 129, Loss: 0.20910701155662537\n",
            "Batch 130, Loss: 0.13295675814151764\n",
            "Batch 131, Loss: 0.19782063364982605\n",
            "Batch 132, Loss: 0.12134437263011932\n",
            "Batch 133, Loss: 0.10895094275474548\n",
            "Batch 134, Loss: 0.2346596121788025\n",
            "Batch 135, Loss: 0.11421224474906921\n",
            "Batch 136, Loss: 0.2264264076948166\n",
            "Batch 137, Loss: 0.20496314764022827\n",
            "Batch 138, Loss: 0.19029228389263153\n",
            "Batch 139, Loss: 0.17781907320022583\n",
            "Batch 140, Loss: 0.12577128410339355\n",
            "Batch 141, Loss: 0.11321708559989929\n",
            "Batch 142, Loss: 0.18878650665283203\n",
            "Batch 143, Loss: 0.14723269641399384\n",
            "Batch 144, Loss: 0.1586546003818512\n",
            "Batch 145, Loss: 0.15257218480110168\n",
            "Batch 146, Loss: 0.36473989486694336\n",
            "Batch 147, Loss: 0.23824483156204224\n",
            "Batch 148, Loss: 0.158369779586792\n",
            "Batch 149, Loss: 0.20139403641223907\n",
            "Batch 150, Loss: 0.10514833778142929\n",
            "Batch 151, Loss: 0.13959704339504242\n",
            "Batch 152, Loss: 0.13097058236598969\n",
            "Batch 153, Loss: 0.14782439172267914\n",
            "Batch 154, Loss: 0.11222466081380844\n",
            "Batch 155, Loss: 0.13416333496570587\n",
            "Batch 156, Loss: 0.1475568413734436\n",
            "Batch 157, Loss: 0.21492090821266174\n",
            "Batch 158, Loss: 0.20904649794101715\n",
            "Batch 159, Loss: 0.23887300491333008\n",
            "Batch 160, Loss: 0.136984720826149\n",
            "Batch 161, Loss: 0.208383247256279\n",
            "Batch 162, Loss: 0.1444813311100006\n",
            "Batch 163, Loss: 0.16896039247512817\n",
            "Batch 164, Loss: 0.1463090479373932\n",
            "Batch 165, Loss: 0.21799840033054352\n",
            "Batch 166, Loss: 0.1466265767812729\n",
            "Batch 167, Loss: 0.09852570295333862\n",
            "Batch 168, Loss: 0.10934419184923172\n",
            "Batch 169, Loss: 0.20204077661037445\n",
            "Batch 170, Loss: 0.0953541100025177\n",
            "Batch 171, Loss: 0.22082191705703735\n",
            "Batch 172, Loss: 0.13072076439857483\n",
            "Batch 173, Loss: 0.07823847234249115\n",
            "Batch 174, Loss: 0.1274779587984085\n",
            "Batch 175, Loss: 0.20295807719230652\n",
            "Batch 176, Loss: 0.10455340892076492\n",
            "Batch 177, Loss: 0.1013684868812561\n",
            "Batch 178, Loss: 0.13404570519924164\n",
            "Batch 179, Loss: 0.21694928407669067\n",
            "Batch 180, Loss: 0.1338261365890503\n",
            "Batch 181, Loss: 0.14446285367012024\n",
            "Batch 182, Loss: 0.17600485682487488\n",
            "Batch 183, Loss: 0.22798027098178864\n",
            "Batch 184, Loss: 0.29465383291244507\n",
            "Batch 185, Loss: 0.14603039622306824\n",
            "Batch 186, Loss: 0.1498449742794037\n",
            "Batch 187, Loss: 0.18102040886878967\n",
            "Batch 188, Loss: 0.2937687635421753\n",
            "Batch 189, Loss: 0.2062971144914627\n",
            "Batch 190, Loss: 0.1857692301273346\n",
            "Batch 191, Loss: 0.1474011242389679\n",
            "Batch 192, Loss: 0.14764639735221863\n",
            "Batch 193, Loss: 0.21803247928619385\n",
            "Batch 194, Loss: 0.09802484512329102\n",
            "Batch 195, Loss: 0.12020622193813324\n",
            "Batch 196, Loss: 0.13909666240215302\n",
            "Batch 197, Loss: 0.11902204900979996\n",
            "Batch 198, Loss: 0.17310090363025665\n",
            "Batch 199, Loss: 0.16531279683113098\n",
            "Batch 200, Loss: 0.15430819988250732\n",
            "Batch 201, Loss: 0.3027743101119995\n",
            "Batch 202, Loss: 0.20742668211460114\n",
            "Batch 203, Loss: 0.24273434281349182\n",
            "Batch 204, Loss: 0.21951033174991608\n",
            "Batch 205, Loss: 0.18011826276779175\n",
            "Batch 206, Loss: 0.31504499912261963\n",
            "Batch 207, Loss: 0.23974937200546265\n",
            "Batch 208, Loss: 0.3246959447860718\n",
            "Batch 209, Loss: 0.0934956818819046\n",
            "Batch 210, Loss: 0.15270665287971497\n",
            "Batch 211, Loss: 0.08897840976715088\n",
            "Batch 212, Loss: 0.13848908245563507\n",
            "Batch 213, Loss: 0.18156564235687256\n",
            "Batch 214, Loss: 0.2576937973499298\n",
            "Batch 215, Loss: 0.43702632188796997\n",
            "Batch 216, Loss: 0.12910643219947815\n",
            "Batch 217, Loss: 0.1959545910358429\n",
            "Batch 218, Loss: 0.1637021005153656\n",
            "Batch 219, Loss: 0.32258594036102295\n",
            "Batch 220, Loss: 0.15679055452346802\n",
            "Batch 221, Loss: 0.14412972331047058\n",
            "Batch 222, Loss: 0.15471738576889038\n",
            "Batch 223, Loss: 0.33620643615722656\n",
            "Batch 224, Loss: 0.20278845727443695\n",
            "Batch 225, Loss: 0.2284967005252838\n",
            "Batch 226, Loss: 0.2554813027381897\n",
            "Batch 227, Loss: 0.16438765823841095\n",
            "Batch 228, Loss: 0.2278824746608734\n",
            "Batch 229, Loss: 0.2060556709766388\n",
            "Batch 230, Loss: 0.15316349267959595\n",
            "Epoch 48, Loss: 0.15316349267959595\n",
            "Batch 1, Loss: 0.11005263775587082\n",
            "Batch 2, Loss: 0.1434280276298523\n",
            "Batch 3, Loss: 0.13951992988586426\n",
            "Batch 4, Loss: 0.09555988013744354\n",
            "Batch 5, Loss: 0.0832848846912384\n",
            "Batch 6, Loss: 0.08393073081970215\n",
            "Batch 7, Loss: 0.23027899861335754\n",
            "Batch 8, Loss: 0.11280430853366852\n",
            "Batch 9, Loss: 0.1892888993024826\n",
            "Batch 10, Loss: 0.12714675068855286\n",
            "Batch 11, Loss: 0.18333706259727478\n",
            "Batch 12, Loss: 0.10396336019039154\n",
            "Batch 13, Loss: 0.09280098974704742\n",
            "Batch 14, Loss: 0.10240146517753601\n",
            "Batch 15, Loss: 0.1869906187057495\n",
            "Batch 16, Loss: 0.11319632828235626\n",
            "Batch 17, Loss: 0.10290618985891342\n",
            "Batch 18, Loss: 0.11854042112827301\n",
            "Batch 19, Loss: 0.13675174117088318\n",
            "Batch 20, Loss: 0.09155836701393127\n",
            "Batch 21, Loss: 0.12450271099805832\n",
            "Batch 22, Loss: 0.10249398648738861\n",
            "Batch 23, Loss: 0.14837968349456787\n",
            "Batch 24, Loss: 0.1070936769247055\n",
            "Batch 25, Loss: 0.09261281788349152\n",
            "Batch 26, Loss: 0.1359386444091797\n",
            "Batch 27, Loss: 0.10751214623451233\n",
            "Batch 28, Loss: 0.16205480694770813\n",
            "Batch 29, Loss: 0.11279045045375824\n",
            "Batch 30, Loss: 0.14359676837921143\n",
            "Batch 31, Loss: 0.12309567630290985\n",
            "Batch 32, Loss: 0.16148154437541962\n",
            "Batch 33, Loss: 0.11699716001749039\n",
            "Batch 34, Loss: 0.10444783419370651\n",
            "Batch 35, Loss: 0.11891883611679077\n",
            "Batch 36, Loss: 0.30625319480895996\n",
            "Batch 37, Loss: 0.33383363485336304\n",
            "Batch 38, Loss: 0.14624488353729248\n",
            "Batch 39, Loss: 0.1325221061706543\n",
            "Batch 40, Loss: 0.07587996870279312\n",
            "Batch 41, Loss: 0.1421217918395996\n",
            "Batch 42, Loss: 0.08682791888713837\n",
            "Batch 43, Loss: 0.1766657829284668\n",
            "Batch 44, Loss: 0.18348419666290283\n",
            "Batch 45, Loss: 0.14488941431045532\n",
            "Batch 46, Loss: 0.19489601254463196\n",
            "Batch 47, Loss: 0.17528922855854034\n",
            "Batch 48, Loss: 0.19939035177230835\n",
            "Batch 49, Loss: 0.10940716415643692\n",
            "Batch 50, Loss: 0.11155897378921509\n",
            "Batch 51, Loss: 0.19521130621433258\n",
            "Batch 52, Loss: 0.30977705121040344\n",
            "Batch 53, Loss: 0.1503898948431015\n",
            "Batch 54, Loss: 0.13218145072460175\n",
            "Batch 55, Loss: 0.12338168919086456\n",
            "Batch 56, Loss: 0.1079166978597641\n",
            "Batch 57, Loss: 0.15173041820526123\n",
            "Batch 58, Loss: 0.09533625841140747\n",
            "Batch 59, Loss: 0.1673988401889801\n",
            "Batch 60, Loss: 0.13810209929943085\n",
            "Batch 61, Loss: 0.20541012287139893\n",
            "Batch 62, Loss: 0.16488710045814514\n",
            "Batch 63, Loss: 0.12415915727615356\n",
            "Batch 64, Loss: 0.11434106528759003\n",
            "Batch 65, Loss: 0.17562595009803772\n",
            "Batch 66, Loss: 0.09060397744178772\n",
            "Batch 67, Loss: 0.28142067790031433\n",
            "Batch 68, Loss: 0.10469663143157959\n",
            "Batch 69, Loss: 0.20805557072162628\n",
            "Batch 70, Loss: 0.20247070491313934\n",
            "Batch 71, Loss: 0.12056910991668701\n",
            "Batch 72, Loss: 0.13257557153701782\n",
            "Batch 73, Loss: 0.09618701785802841\n",
            "Batch 74, Loss: 0.13853789865970612\n",
            "Batch 75, Loss: 0.08192674815654755\n",
            "Batch 76, Loss: 0.19325736165046692\n",
            "Batch 77, Loss: 0.1271876096725464\n",
            "Batch 78, Loss: 0.11826111376285553\n",
            "Batch 79, Loss: 0.1282224953174591\n",
            "Batch 80, Loss: 0.16367454826831818\n",
            "Batch 81, Loss: 0.12467895448207855\n",
            "Batch 82, Loss: 0.12469560652971268\n",
            "Batch 83, Loss: 0.09515520930290222\n",
            "Batch 84, Loss: 0.18293911218643188\n",
            "Batch 85, Loss: 0.13039396703243256\n",
            "Batch 86, Loss: 0.13520470261573792\n",
            "Batch 87, Loss: 0.06913629174232483\n",
            "Batch 88, Loss: 0.16205918788909912\n",
            "Batch 89, Loss: 0.11102572083473206\n",
            "Batch 90, Loss: 0.12010832875967026\n",
            "Batch 91, Loss: 0.1183730959892273\n",
            "Batch 92, Loss: 0.15632310509681702\n",
            "Batch 93, Loss: 0.177348792552948\n",
            "Batch 94, Loss: 0.1043858677148819\n",
            "Batch 95, Loss: 0.1414387822151184\n",
            "Batch 96, Loss: 0.10195176303386688\n",
            "Batch 97, Loss: 0.09214237332344055\n",
            "Batch 98, Loss: 0.2549338936805725\n",
            "Batch 99, Loss: 0.1361449956893921\n",
            "Batch 100, Loss: 0.12247098982334137\n",
            "Batch 101, Loss: 0.13742393255233765\n",
            "Batch 102, Loss: 0.23991377651691437\n",
            "Batch 103, Loss: 0.1442982256412506\n",
            "Batch 104, Loss: 0.10450498759746552\n",
            "Batch 105, Loss: 0.3055979311466217\n",
            "Batch 106, Loss: 0.10102873295545578\n",
            "Batch 107, Loss: 0.1507493555545807\n",
            "Batch 108, Loss: 0.08280779421329498\n",
            "Batch 109, Loss: 0.13874462246894836\n",
            "Batch 110, Loss: 0.0977073684334755\n",
            "Batch 111, Loss: 0.139104962348938\n",
            "Batch 112, Loss: 0.19356368482112885\n",
            "Batch 113, Loss: 0.3008655905723572\n",
            "Batch 114, Loss: 0.11907004565000534\n",
            "Batch 115, Loss: 0.2759639620780945\n",
            "Batch 116, Loss: 0.1479630470275879\n",
            "Batch 117, Loss: 0.0988273173570633\n",
            "Batch 118, Loss: 0.23898732662200928\n",
            "Batch 119, Loss: 0.1766171157360077\n",
            "Batch 120, Loss: 0.15728533267974854\n",
            "Batch 121, Loss: 0.1749679446220398\n",
            "Batch 122, Loss: 0.12818700075149536\n",
            "Batch 123, Loss: 0.13861043751239777\n",
            "Batch 124, Loss: 0.15510648488998413\n",
            "Batch 125, Loss: 0.13960303366184235\n",
            "Batch 126, Loss: 0.08944107592105865\n",
            "Batch 127, Loss: 0.14254826307296753\n",
            "Batch 128, Loss: 0.18686489760875702\n",
            "Batch 129, Loss: 0.12446105480194092\n",
            "Batch 130, Loss: 0.15182936191558838\n",
            "Batch 131, Loss: 0.1301240473985672\n",
            "Batch 132, Loss: 0.21115559339523315\n",
            "Batch 133, Loss: 0.14345017075538635\n",
            "Batch 134, Loss: 0.09663061797618866\n",
            "Batch 135, Loss: 0.11420810222625732\n",
            "Batch 136, Loss: 0.1115577220916748\n",
            "Batch 137, Loss: 0.14180900156497955\n",
            "Batch 138, Loss: 0.2427070438861847\n",
            "Batch 139, Loss: 0.16941750049591064\n",
            "Batch 140, Loss: 0.2052583545446396\n",
            "Batch 141, Loss: 0.2391599416732788\n",
            "Batch 142, Loss: 0.19274696707725525\n",
            "Batch 143, Loss: 0.24000772833824158\n",
            "Batch 144, Loss: 0.2589576542377472\n",
            "Batch 145, Loss: 0.1491818130016327\n",
            "Batch 146, Loss: 0.13731607794761658\n",
            "Batch 147, Loss: 0.196024090051651\n",
            "Batch 148, Loss: 0.22841252386569977\n",
            "Batch 149, Loss: 0.2058066427707672\n",
            "Batch 150, Loss: 0.1964007318019867\n",
            "Batch 151, Loss: 0.10479730367660522\n",
            "Batch 152, Loss: 0.24593251943588257\n",
            "Batch 153, Loss: 0.16612263023853302\n",
            "Batch 154, Loss: 0.14475220441818237\n",
            "Batch 155, Loss: 0.1273423582315445\n",
            "Batch 156, Loss: 0.12222211807966232\n",
            "Batch 157, Loss: 0.11286032944917679\n",
            "Batch 158, Loss: 0.2877974808216095\n",
            "Batch 159, Loss: 0.14219720661640167\n",
            "Batch 160, Loss: 0.12978465855121613\n",
            "Batch 161, Loss: 0.10276614129543304\n",
            "Batch 162, Loss: 0.15344491600990295\n",
            "Batch 163, Loss: 0.24807611107826233\n",
            "Batch 164, Loss: 0.25449857115745544\n",
            "Batch 165, Loss: 0.19850362837314606\n",
            "Batch 166, Loss: 0.17309552431106567\n",
            "Batch 167, Loss: 0.1059625893831253\n",
            "Batch 168, Loss: 0.16231021285057068\n",
            "Batch 169, Loss: 0.22728627920150757\n",
            "Batch 170, Loss: 0.185603529214859\n",
            "Batch 171, Loss: 0.2754567265510559\n",
            "Batch 172, Loss: 0.17855709791183472\n",
            "Batch 173, Loss: 0.329640656709671\n",
            "Batch 174, Loss: 0.24397727847099304\n",
            "Batch 175, Loss: 0.1622879058122635\n",
            "Batch 176, Loss: 0.18616816401481628\n",
            "Batch 177, Loss: 0.0905439555644989\n",
            "Batch 178, Loss: 0.23010937869548798\n",
            "Batch 179, Loss: 0.24263255298137665\n",
            "Batch 180, Loss: 0.1737842559814453\n",
            "Batch 181, Loss: 0.16909509897232056\n",
            "Batch 182, Loss: 0.27034610509872437\n",
            "Batch 183, Loss: 0.15210402011871338\n",
            "Batch 184, Loss: 0.2507045269012451\n",
            "Batch 185, Loss: 0.2557140588760376\n",
            "Batch 186, Loss: 0.20240147411823273\n",
            "Batch 187, Loss: 0.1072247326374054\n",
            "Batch 188, Loss: 0.18887220323085785\n",
            "Batch 189, Loss: 0.20704080164432526\n",
            "Batch 190, Loss: 0.26332366466522217\n",
            "Batch 191, Loss: 0.14313888549804688\n",
            "Batch 192, Loss: 0.23553702235221863\n",
            "Batch 193, Loss: 0.11821632087230682\n",
            "Batch 194, Loss: 0.17713794112205505\n",
            "Batch 195, Loss: 0.22678904235363007\n",
            "Batch 196, Loss: 0.23015406727790833\n",
            "Batch 197, Loss: 0.23056399822235107\n",
            "Batch 198, Loss: 0.13236534595489502\n",
            "Batch 199, Loss: 0.10986850410699844\n",
            "Batch 200, Loss: 0.1507025957107544\n",
            "Batch 201, Loss: 0.18401354551315308\n",
            "Batch 202, Loss: 0.16163969039916992\n",
            "Batch 203, Loss: 0.15249517560005188\n",
            "Batch 204, Loss: 0.30209624767303467\n",
            "Batch 205, Loss: 0.14265838265419006\n",
            "Batch 206, Loss: 0.16842757165431976\n",
            "Batch 207, Loss: 0.14444206655025482\n",
            "Batch 208, Loss: 0.2936111092567444\n",
            "Batch 209, Loss: 0.16761495172977448\n",
            "Batch 210, Loss: 0.11448110640048981\n",
            "Batch 211, Loss: 0.16246910393238068\n",
            "Batch 212, Loss: 0.16957955062389374\n",
            "Batch 213, Loss: 0.2858262062072754\n",
            "Batch 214, Loss: 0.14852294325828552\n",
            "Batch 215, Loss: 0.19677090644836426\n",
            "Batch 216, Loss: 0.19081372022628784\n",
            "Batch 217, Loss: 0.18407025933265686\n",
            "Batch 218, Loss: 0.1822165548801422\n",
            "Batch 219, Loss: 0.295067697763443\n",
            "Batch 220, Loss: 0.2786262631416321\n",
            "Batch 221, Loss: 0.21766838431358337\n",
            "Batch 222, Loss: 0.16165104508399963\n",
            "Batch 223, Loss: 0.34943264722824097\n",
            "Batch 224, Loss: 0.17369651794433594\n",
            "Batch 225, Loss: 0.19498515129089355\n",
            "Batch 226, Loss: 0.18946555256843567\n",
            "Batch 227, Loss: 0.5779203176498413\n",
            "Batch 228, Loss: 0.23703134059906006\n",
            "Batch 229, Loss: 0.23400309681892395\n",
            "Batch 230, Loss: 0.18590497970581055\n",
            "Epoch 49, Loss: 0.18590497970581055\n",
            "Batch 1, Loss: 0.16677731275558472\n",
            "Batch 2, Loss: 0.11307165026664734\n",
            "Batch 3, Loss: 0.1413273811340332\n",
            "Batch 4, Loss: 0.12578386068344116\n",
            "Batch 5, Loss: 0.18830323219299316\n",
            "Batch 6, Loss: 0.13607409596443176\n",
            "Batch 7, Loss: 0.10879542678594589\n",
            "Batch 8, Loss: 0.1836823970079422\n",
            "Batch 9, Loss: 0.13647359609603882\n",
            "Batch 10, Loss: 0.12234465032815933\n",
            "Batch 11, Loss: 0.16261614859104156\n",
            "Batch 12, Loss: 0.20712211728096008\n",
            "Batch 13, Loss: 0.1536567509174347\n",
            "Batch 14, Loss: 0.15696373581886292\n",
            "Batch 15, Loss: 0.11215061694383621\n",
            "Batch 16, Loss: 0.21556466817855835\n",
            "Batch 17, Loss: 0.11688587814569473\n",
            "Batch 18, Loss: 0.11614041030406952\n",
            "Batch 19, Loss: 0.15624862909317017\n",
            "Batch 20, Loss: 0.16404366493225098\n",
            "Batch 21, Loss: 0.10408017039299011\n",
            "Batch 22, Loss: 0.14448091387748718\n",
            "Batch 23, Loss: 0.12846232950687408\n",
            "Batch 24, Loss: 0.12515516579151154\n",
            "Batch 25, Loss: 0.09284944832324982\n",
            "Batch 26, Loss: 0.12096387892961502\n",
            "Batch 27, Loss: 0.10375422984361649\n",
            "Batch 28, Loss: 0.11406999826431274\n",
            "Batch 29, Loss: 0.17636612057685852\n",
            "Batch 30, Loss: 0.07674543559551239\n",
            "Batch 31, Loss: 0.13733819127082825\n",
            "Batch 32, Loss: 0.305949330329895\n",
            "Batch 33, Loss: 0.12944293022155762\n",
            "Batch 34, Loss: 0.1452742964029312\n",
            "Batch 35, Loss: 0.12437187135219574\n",
            "Batch 36, Loss: 0.07644890248775482\n",
            "Batch 37, Loss: 0.09411294758319855\n",
            "Batch 38, Loss: 0.15406185388565063\n",
            "Batch 39, Loss: 0.1261761337518692\n",
            "Batch 40, Loss: 0.0771029144525528\n",
            "Batch 41, Loss: 0.11948195844888687\n",
            "Batch 42, Loss: 0.1543153077363968\n",
            "Batch 43, Loss: 0.1164715588092804\n",
            "Batch 44, Loss: 0.13449004292488098\n",
            "Batch 45, Loss: 0.11898747086524963\n",
            "Batch 46, Loss: 0.171254962682724\n",
            "Batch 47, Loss: 0.15592575073242188\n",
            "Batch 48, Loss: 0.13021861016750336\n",
            "Batch 49, Loss: 0.1303219348192215\n",
            "Batch 50, Loss: 0.09720118343830109\n",
            "Batch 51, Loss: 0.10586710274219513\n",
            "Batch 52, Loss: 0.09746213257312775\n",
            "Batch 53, Loss: 0.1151205450296402\n",
            "Batch 54, Loss: 0.13787391781806946\n",
            "Batch 55, Loss: 0.12640994787216187\n",
            "Batch 56, Loss: 0.13552266359329224\n",
            "Batch 57, Loss: 0.14496785402297974\n",
            "Batch 58, Loss: 0.1551927924156189\n",
            "Batch 59, Loss: 0.09639592468738556\n",
            "Batch 60, Loss: 0.1280106008052826\n",
            "Batch 61, Loss: 0.1727564036846161\n",
            "Batch 62, Loss: 0.11786781251430511\n",
            "Batch 63, Loss: 0.17678135633468628\n",
            "Batch 64, Loss: 0.15031619369983673\n",
            "Batch 65, Loss: 0.12832148373126984\n",
            "Batch 66, Loss: 0.17504025995731354\n",
            "Batch 67, Loss: 0.08490267395973206\n",
            "Batch 68, Loss: 0.09532703459262848\n",
            "Batch 69, Loss: 0.1248847246170044\n",
            "Batch 70, Loss: 0.18572105467319489\n",
            "Batch 71, Loss: 0.10221174359321594\n",
            "Batch 72, Loss: 0.12511058151721954\n",
            "Batch 73, Loss: 0.25204217433929443\n",
            "Batch 74, Loss: 0.11524021625518799\n",
            "Batch 75, Loss: 0.1344691514968872\n",
            "Batch 76, Loss: 0.15411560237407684\n",
            "Batch 77, Loss: 0.1438777595758438\n",
            "Batch 78, Loss: 0.09843181073665619\n",
            "Batch 79, Loss: 0.1349644958972931\n",
            "Batch 80, Loss: 0.149368017911911\n",
            "Batch 81, Loss: 0.1805281937122345\n",
            "Batch 82, Loss: 0.15245430171489716\n",
            "Batch 83, Loss: 0.1362452507019043\n",
            "Batch 84, Loss: 0.17233146727085114\n",
            "Batch 85, Loss: 0.09744865447282791\n",
            "Batch 86, Loss: 0.1578844040632248\n",
            "Batch 87, Loss: 0.14214450120925903\n",
            "Batch 88, Loss: 0.12081936001777649\n",
            "Batch 89, Loss: 0.14226685464382172\n",
            "Batch 90, Loss: 0.372478723526001\n",
            "Batch 91, Loss: 0.18084250390529633\n",
            "Batch 92, Loss: 0.15168675780296326\n",
            "Batch 93, Loss: 0.11070024967193604\n",
            "Batch 94, Loss: 0.1475992351770401\n",
            "Batch 95, Loss: 0.18616007268428802\n",
            "Batch 96, Loss: 0.22582799196243286\n",
            "Batch 97, Loss: 0.15993264317512512\n",
            "Batch 98, Loss: 0.16742387413978577\n",
            "Batch 99, Loss: 0.09834426641464233\n",
            "Batch 100, Loss: 0.15280140936374664\n",
            "Batch 101, Loss: 0.1341228485107422\n",
            "Batch 102, Loss: 0.09845631569623947\n",
            "Batch 103, Loss: 0.16977868974208832\n",
            "Batch 104, Loss: 0.23763924837112427\n",
            "Batch 105, Loss: 0.17586706578731537\n",
            "Batch 106, Loss: 0.09411181509494781\n",
            "Batch 107, Loss: 0.1466999500989914\n",
            "Batch 108, Loss: 0.19706100225448608\n",
            "Batch 109, Loss: 0.12695598602294922\n",
            "Batch 110, Loss: 0.15231993794441223\n",
            "Batch 111, Loss: 0.20992957055568695\n",
            "Batch 112, Loss: 0.12357931584119797\n",
            "Batch 113, Loss: 0.15421369671821594\n",
            "Batch 114, Loss: 0.1366695910692215\n",
            "Batch 115, Loss: 0.18380451202392578\n",
            "Batch 116, Loss: 0.25908106565475464\n",
            "Batch 117, Loss: 0.15241502225399017\n",
            "Batch 118, Loss: 0.11892209947109222\n",
            "Batch 119, Loss: 0.23052121698856354\n",
            "Batch 120, Loss: 0.19216322898864746\n",
            "Batch 121, Loss: 0.19323663413524628\n",
            "Batch 122, Loss: 0.12404066324234009\n",
            "Batch 123, Loss: 0.12914760410785675\n",
            "Batch 124, Loss: 0.15110641717910767\n",
            "Batch 125, Loss: 0.22763550281524658\n",
            "Batch 126, Loss: 0.10856419801712036\n",
            "Batch 127, Loss: 0.17753493785858154\n",
            "Batch 128, Loss: 0.09392251074314117\n",
            "Batch 129, Loss: 0.23472559452056885\n",
            "Batch 130, Loss: 0.13358139991760254\n",
            "Batch 131, Loss: 0.24149194359779358\n",
            "Batch 132, Loss: 0.23172907531261444\n",
            "Batch 133, Loss: 0.15949556231498718\n",
            "Batch 134, Loss: 0.26827478408813477\n",
            "Batch 135, Loss: 0.10260739922523499\n",
            "Batch 136, Loss: 0.14956292510032654\n",
            "Batch 137, Loss: 0.18269725143909454\n",
            "Batch 138, Loss: 0.16672661900520325\n",
            "Batch 139, Loss: 0.24371027946472168\n",
            "Batch 140, Loss: 0.12425516545772552\n",
            "Batch 141, Loss: 0.1968967318534851\n",
            "Batch 142, Loss: 0.21795782446861267\n",
            "Batch 143, Loss: 0.19257497787475586\n",
            "Batch 144, Loss: 0.23455944657325745\n",
            "Batch 145, Loss: 0.19968296587467194\n",
            "Batch 146, Loss: 0.13586336374282837\n",
            "Batch 147, Loss: 0.12334124743938446\n",
            "Batch 148, Loss: 0.16194336116313934\n",
            "Batch 149, Loss: 0.1246340349316597\n",
            "Batch 150, Loss: 0.09943286329507828\n",
            "Batch 151, Loss: 0.29124265909194946\n",
            "Batch 152, Loss: 0.1806177794933319\n",
            "Batch 153, Loss: 0.1759720891714096\n",
            "Batch 154, Loss: 0.15379828214645386\n",
            "Batch 155, Loss: 0.1584138572216034\n",
            "Batch 156, Loss: 0.2006511092185974\n",
            "Batch 157, Loss: 0.165456622838974\n",
            "Batch 158, Loss: 0.1368221938610077\n",
            "Batch 159, Loss: 0.21859630942344666\n",
            "Batch 160, Loss: 0.1225212812423706\n",
            "Batch 161, Loss: 0.1810724437236786\n",
            "Batch 162, Loss: 0.1265397071838379\n",
            "Batch 163, Loss: 0.11368638277053833\n",
            "Batch 164, Loss: 0.12267476320266724\n",
            "Batch 165, Loss: 0.19106720387935638\n",
            "Batch 166, Loss: 0.13550406694412231\n",
            "Batch 167, Loss: 0.16847243905067444\n",
            "Batch 168, Loss: 0.19123879075050354\n",
            "Batch 169, Loss: 0.1630782186985016\n",
            "Batch 170, Loss: 0.23696386814117432\n",
            "Batch 171, Loss: 0.11516585946083069\n",
            "Batch 172, Loss: 0.15725776553153992\n",
            "Batch 173, Loss: 0.16633719205856323\n",
            "Batch 174, Loss: 0.17724192142486572\n",
            "Batch 175, Loss: 0.15092021226882935\n",
            "Batch 176, Loss: 0.11544941365718842\n",
            "Batch 177, Loss: 0.24924902617931366\n",
            "Batch 178, Loss: 0.20847195386886597\n",
            "Batch 179, Loss: 0.23139627277851105\n",
            "Batch 180, Loss: 0.229474738240242\n",
            "Batch 181, Loss: 0.1489522010087967\n",
            "Batch 182, Loss: 0.286477267742157\n",
            "Batch 183, Loss: 0.2176409810781479\n",
            "Batch 184, Loss: 0.13436931371688843\n",
            "Batch 185, Loss: 0.3719368875026703\n",
            "Batch 186, Loss: 0.16673266887664795\n",
            "Batch 187, Loss: 0.12291808426380157\n",
            "Batch 188, Loss: 0.18248704075813293\n",
            "Batch 189, Loss: 0.13039036095142365\n",
            "Batch 190, Loss: 0.33282577991485596\n",
            "Batch 191, Loss: 0.14229097962379456\n",
            "Batch 192, Loss: 0.23609761893749237\n",
            "Batch 193, Loss: 0.15499767661094666\n",
            "Batch 194, Loss: 0.12650194764137268\n",
            "Batch 195, Loss: 0.09702397137880325\n",
            "Batch 196, Loss: 0.20287588238716125\n",
            "Batch 197, Loss: 0.22679945826530457\n",
            "Batch 198, Loss: 0.31117957830429077\n",
            "Batch 199, Loss: 0.2567322552204132\n",
            "Batch 200, Loss: 0.18371865153312683\n",
            "Batch 201, Loss: 0.13227549195289612\n",
            "Batch 202, Loss: 0.26434794068336487\n",
            "Batch 203, Loss: 0.23953242599964142\n",
            "Batch 204, Loss: 0.14243659377098083\n",
            "Batch 205, Loss: 0.15370413661003113\n",
            "Batch 206, Loss: 0.13221028447151184\n",
            "Batch 207, Loss: 0.27994248270988464\n",
            "Batch 208, Loss: 0.14695872366428375\n",
            "Batch 209, Loss: 0.2170467972755432\n",
            "Batch 210, Loss: 0.1744820475578308\n",
            "Batch 211, Loss: 0.13659429550170898\n",
            "Batch 212, Loss: 0.1749585121870041\n",
            "Batch 213, Loss: 0.2290843278169632\n",
            "Batch 214, Loss: 0.13961142301559448\n",
            "Batch 215, Loss: 0.1326235979795456\n",
            "Batch 216, Loss: 0.2650316059589386\n",
            "Batch 217, Loss: 0.15588894486427307\n",
            "Batch 218, Loss: 0.1653711050748825\n",
            "Batch 219, Loss: 0.2014627754688263\n",
            "Batch 220, Loss: 0.14655239880084991\n",
            "Batch 221, Loss: 0.11917190253734589\n",
            "Batch 222, Loss: 0.12116535753011703\n",
            "Batch 223, Loss: 0.286697655916214\n",
            "Batch 224, Loss: 0.16626951098442078\n",
            "Batch 225, Loss: 0.19153572618961334\n",
            "Batch 226, Loss: 0.14193159341812134\n",
            "Batch 227, Loss: 0.2045435607433319\n",
            "Batch 228, Loss: 0.21025782823562622\n",
            "Batch 229, Loss: 0.17532330751419067\n",
            "Batch 230, Loss: 0.0797034278512001\n",
            "Epoch 50, Loss: 0.0797034278512001\n"
          ]
        }
      ],
      "source": [
        "train_model(vit_model, train_dataloader, epochs=50)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Performing Validation"
      ],
      "metadata": {
        "id": "QRzv3si32Ydj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def validate_model(model, data_loader):\n",
        "    \"\"\"\n",
        "    Validates the model's accuracy on a given dataset.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The trained PyTorch model.\n",
        "        data_loader (DataLoader): The DataLoader for the validation/test set.\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Disable gradient calculation for inference\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "\n",
        "            # Get the predicted class (the index of the max log-probability)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            # Count the total number of labels\n",
        "            total += labels.size(0)\n",
        "\n",
        "            # Count the number of correct predictions\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Accuracy on the validation set: {accuracy:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "id": "106KYkmYq-HD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validate_model(vit_model, val_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPrsrQzOrKCf",
        "outputId": "8a037be6-d651-4d55-ebf7-2430cd0056a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on the validation set: 34.86%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation accuracy is : 34.86% <br>\n",
        "Model is Little Bit Overfitting."
      ],
      "metadata": {
        "id": "rQ4SEFVh2eZf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkhuLJbMsUrH"
      },
      "outputs": [],
      "source": [
        "#---Train the model that you have coded from scratch not pre-trained model.-----#\n",
        "#--- NOTE: You should not use pre-trained model here---#\n",
        "# train_model(VGG16, dataloader, epochs=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlCSre9oH1kK"
      },
      "source": [
        "#Answer the following Questions (All are mandatory, unless mentioned)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhdjaotHH5tk"
      },
      "source": [
        "## <ins>Question-0 (Example)</ins>: In the ViT paper [3], did the authors specify anywhere that their model is better than standard convolutional architectures?\n",
        "## <ins>Answer-0</ins>: Yes. In the abstract, the authors claim that Vision Transformers consume less computational power to achieve better performance.\n",
        "\n",
        "### <ins>Supporting statement in paper</ins>: \"When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OY9UC0yuJZ90"
      },
      "source": [
        "## <ins>Question-1</ins>: What aare the major contribtuions of VGG-16,19 architecture? Justify your answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kdoHlThJ0SG"
      },
      "source": [
        "## <ins>Question-2</ins>: What are the main contributions of Residual Networks [2]? What problem do they solve? Are they better than VGG? If yes, how? Please answer your question briefly and justify your statements with supporting statements from the paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKLiyq7wKPXI"
      },
      "source": [
        "## <ins>Question-3</ins>: What are the main contributions of ViT? What are the main advantages of ViT compared to CNNs? Are there any limitations? If yes, what are they? Please answer your question briefly and justify your statements with supporting statements from the paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4zBZ3DYKl1d"
      },
      "source": [
        "## <ins>Question-4</ins>: Now, comparing these three models, which one is better? Why is the selected model better than the others? Can you briefly state the applications of them which are related to your domain of interest? To be specific, using the model of your choice, can you specify the directions which could help to solve problems other than face recognition?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJPJJoGeRUop"
      },
      "source": [
        "## <ins>Question-5</ins>: What are the key architectural differences among the three models? Differentiate between each of the components and explain why each component acts like building blocks for these architectures."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06PYyapjLYdS"
      },
      "source": [
        "## <ins>Question-6 (Optional)</ins>: All the above-mentioned models are for classification purposes. Can you use these models for any other tasks (other than classification)? If so, can you specify your ideas and justify your statements with research articles you have studied?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJa0SD-uVXNy"
      },
      "source": [
        "## <ins>Question-1</ins>: What are the major contribtuions of VGG-16,19 architecture? Justify your answer.\n",
        "  VGGâ€™s primary contribution, as detailed in its paper [1], was a systematic investigation into the effect of network depth on accuracy. The authors demonstrated that by using a uniform and simple architecture of very small 3x3 convolutional filters throughout the network, they could build deep models (up to 19 layers) that achieved state-of-the-art results. This established that depth is a more important factor for performance than filter size or network width.\n",
        "\n",
        "  **The major contributions of the VGG architecture are:**\n",
        "\n",
        "  * **Demonstration of the Importance of Depth:** The primary contribution was a rigorous, controlled experiment that proved increasing network depth to 16-19 weight layers led to significant accuracy improvements on large-scale image recognition.\n",
        "\n",
        "  * **The Efficacy of Small Filters:** They showed that stacking multiple small (3x3) convolutional filters is more effective than using larger filters (e.g., 5x5, 7x7, 11x11). This design increases non-linearity and reduces the number of parameters.\n",
        "\n",
        "  * **A Simple, Homogeneous Architecture:** VGG provided a uniform and modular architectural design (repeated blocks of 3x3 conv layers and 2x2 max-pool) that became a new standard baseline.\n",
        "\n",
        "  * **Scale Jittering:** They popularized the use of scale jittering during training as a highly effective data augmentation technique for improving generalization.\n",
        "\n",
        "**Supporting statement from paper [1]** \"Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3Ã—3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16â€“19 weight layers.\" (Abstract). Furthermore, the results in Table 3 show a clear decrease in error from configuration A (11 layers) to E (19 layers).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <ins>Question-2</ins>: What are the main contributions of Residual Networks [2]? What problem do they solve? Are they better than VGG? If yes, how? Please answer your question briefly and justify your statements with supporting statements from the paper.\n",
        "  The main contribution of ResNet is the **residual learning framework** and the introduction of the **residual connection** (or skip connection). They **solved the degradation problem,** where training accuracy for deeper plain networks would get worse than their shallower counterparts. This was an optimization issue, not overfitting. The skip connection allows the network to learn a residual function F(x) instead of a direct mapping H(x), making it easier to optimize the network's layers.\n",
        "\n",
        "  **Identifying and Solving the Degradation Problem:** ResNet formally identified that deeper networks suffer from degradation (increasing training error), which is not due to overfitting but due to optimization difficulties. They solved this problem with the residual learning framework.\n",
        "\n",
        " **The Residual Block with Identity Shortcuts:** They introduced a simple yet profoundly effective building block that uses identity shortcut connections to enable smooth gradient flow and make it easy to learn identity mappings.\n",
        "\n",
        " **Enabling Training of Extremely Deep Networks:** This framework made it feasible to train networks that were previously impossible to optimize, such as ResNet-152, and even networks with over 1000 layers.\n",
        "\n",
        " **State-of-the-Art Performance:** ResNets achieved record-breaking results on ImageNet and dramatically improved performance on other tasks like object detection and segmentation.\n",
        "\n",
        "  **Yes, ResNets are better than VGG.** They can be trained to be significantly deeper (up to 152 layers) and more efficiently than VGG, while also having lower complexity. This is because the residual connections solve the vanishing gradient problem that plagues plain deep networks.ResNet-152 has 11.3 billion FLOPs, while VGG-19 has 19.6 billion FLOPs. ResNet achieves higher accuracy with 44% lower computational cost.\n",
        "\n",
        "  **Supporting statement from paper [2]:** \"On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layersâ€”8x deeper than VGG nets [41] but still having lower complexity.\" The paper also explicitly shows in Figure 4 that the 34-layer ResNet has a lower training error than the 34-layer plain network, and a lower validation error than both the 18-layer and 34-layer plain networks."
      ],
      "metadata": {
        "id": "D2DZLZ9JdQEJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <ins>Question-3</ins>: What are the main contributions of ViT? What are the main advantages of ViT compared to CNNs? Are there any limitations? If yes, what are they? Please answer your question briefly and justify your statements with supporting statements from the paper.\n",
        "\n",
        "  **Main Contribution:** The Vision Transformer (ViT) was the first model to demonstrate that a standard Transformer architecture, relying almost solely on a self-attention mechanism, could achieve state-of-the-art results on image classification tasks when pre-trained on sufficiently large datasets.\n",
        "\n",
        "  **Advantages over CNNs:**\n",
        "\n",
        "  * **Global Receptive Field:** From the first layer, self-attention has a global view of the image, whereas CNNs need many layers to build a large receptive field. This is better for modeling long-range dependencies.\n",
        "\n",
        "  * **Superior Scalability:** ViTs scale more effectively to very large models and datasets, often leading to better performance than CNNs at the high end of compute and data.\n",
        "\n",
        "* **Conceptual Simplicity:** It uses a uniform architecture (Transformer blocks) throughout, unlike the progressive reduction in spatial resolution and increase in channels seen in CNNs.\n",
        "\n",
        "**Limitations:**\n",
        "\n",
        "  * **Data Hunger:** ViTs require massive datasets (e.g., JFT-300M) for pre-training to outperform CNNs. They typically underperform ResNets when trained on mid-sized datasets like ImageNet-1k from scratch. \"When trained on mid-sized datasets such as ImageNet without strong regularization, these models yield modest accuracies of a few percentage points below ResNets of comparable size.\" (ViT paper)\n",
        "\n",
        "  * **Computational Cost:** The self-attention mechanism has quadratic complexity in the number of input patches, making it computationally expensive for very high-resolution images.\n",
        "\n",
        "  * **Lack of Inductive Bias:** CNNs have built-in biases for locality and translation equivariance. ViTs have no such built-in spatial priors and must learn them from data, which is why they need more data."
      ],
      "metadata": {
        "id": "YUpbWGWgd7O2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <ins>Question-4</ins>: Now, comparing these three models, which one is better? Why is the selected model better than the others? Can you briefly state the applications of them which are related to your domain of interest? To be specific, using the model of your choice, can you specify the directions which could help to solve problems other than face recognition?\n",
        "\n",
        "**The Vision Transformer (ViT) is the best model to choose**. It is a paradigm-shifting architecture that demonstrates a forward-thinking, research-oriented mindset.\n",
        "\n",
        "ViT is superior because it challenges the long-standing dominance of convolutional neural networks (CNNs) in computer vision. It shows that by treating an image as a sequence of patches and using a standard Transformer encoder, a model can effectively learn to classify images. The key advantage is its ability to capture global context from the entire image using self-attention. Unlike CNNs, which have a local receptive field, ViT can model the relationships between any two parts of an image, no matter how far apart they are. This is a critical insight in modern deep learning and is particularly effective when the model is pre-trained on a massive dataset.\n",
        "\n",
        "**Applications and Future Directions:** <br>\n",
        "My domain of interest **is medical image analysis, specifically in diagnostics**. While face recognition is a form of image classification, ViT's strengths can be applied to more complex problems in this field.\n",
        "\n",
        "**Disease Detection in Histopathological Images:** ViT's ability to model global relationships between image patches is perfect for analyzing large, high-resolution histopathological slides. For example, a ViT model could learn to identify subtle, long-range patterns of cancer cells across an entire tissue sample, which is a major advantage over a CNN's local focus.\n",
        "\n",
        "**Surgical Video Analysis:** ViT could be used to analyze surgical videos to identify and classify surgical phases. By treating video frames as a sequence of images, ViT's self-attention mechanism could model the temporal relationships between different surgical tools and actions, providing a valuable tool for surgical training and safety."
      ],
      "metadata": {
        "id": "0m1i-q5XeG8L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <ins>Question-5</ins>: What are the key architectural differences among the three models? Differentiate between each of the components and explain why each component acts like building blocks for these architectures.\n",
        "\n",
        "The key architectural difference among VGG, ResNet, and ViT is their fundamental building block and how they handle information flow. Each model's unique component was designed to solve a specific problem in deep learning.\n",
        "\n",
        "**VGG:** Uniformity and Simplicity <br>\n",
        "  * **Building Block:** VGG's building block is a simple, repeating stack of 3x3 convolutional layers followed by a 2x2 max-pooling layer.\n",
        "\n",
        "* **Why it's a building block:** The authors showed that using small, uniform 3x3 filters throughout the network was highly effective. By stacking multiple 3x3 layers, they could achieve the same receptive field as a larger filter (e.g., a 5x5 or 7x7), but with fewer parameters and more non-linear activation functions. This made the decision function more discriminative and the architecture easier to implement and understand.\n",
        "\n",
        "**ResNet:** The Residual Block <br>\n",
        "* **Building Block:** The core building block of ResNet is the Residual Block. It consists of a stack of convolutional layers with a skip connection (or identity mapping) that adds the input of the block to its output.\n",
        "\n",
        "* **Why it's a building block:** The residual block was invented to solve the degradation problem in very deep networks, where training accuracy would decrease as more layers were added. The skip connection provides a direct path for the gradient to flow to earlier layers, which solves the vanishing gradient problem. This allows ResNet to be trained with hundreds of layers, making it significantly deeper and more accurate than VGG.\n",
        "\n",
        "**ViT:** The Transformer Encoder Block <br>\n",
        "* **Building Block:** The fundamental building block of ViT is the Transformer Encoder Block, which is composed of a Multi-Head Self-Attention layer and a feed-forward network.\n",
        "\n",
        "* **Why it's a building block:** ViT's architecture fundamentally departs from convolutions. It treats an image as a sequence of patches and uses the Transformer encoder to model the relationships between these patches. The Multi-Head Self-Attention layer is the key component, as it allows the model to capture global context from the entire image at every layer, which is a major advantage over the local receptive fields of CNNs."
      ],
      "metadata": {
        "id": "IQuCQN0HeN6w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <ins>Question-6 (Optional)</ins>: All the above-mentioned models are for classification purposes. Can you use these models for any other tasks (other than classification)? If so, can you specify your ideas and justify your statements with research articles you have studied?\n",
        "\n",
        "Yes, all three modelsâ€”VGG, ResNet, and ViTâ€”can be used for many other tasks beyond image classification. Their power lies in their ability to act as versatile feature extractors. The core idea is to take a pre-trained model, remove the final classification layer, and use the activations from an intermediate layer as a rich feature representation of the input image.\n",
        "\n",
        "**VGG and ResNet for Object Detection and Segmentation ðŸ–¼ï¸** <br>\n",
        "VGG and ResNet, both being powerful CNNs, are widely used as backbones for more complex computer vision tasks. The pre-trained convolutional layers (the \"backbone\") can be used to extract hierarchical features from an image, which are then fed into a specialized \"head\" that performs a different task.\n",
        "\n",
        "* **Object Detection:** Models like Faster R-CNN and YOLO use a pre-trained ResNet or VGG as a feature extractor. The convolutional layers of the ResNet are used to generate a feature map, which is then passed to a Region Proposal Network (RPN) and a classification/regression head to predict bounding boxes and class labels.\n",
        "\n",
        "* **Semantic Segmentation:** In models like U-Net and DeepLab, a pre-trained ResNet acts as the encoder. The features it extracts are then passed through a decoder to produce a pixel-wise segmentation map of the image.\n",
        "\n",
        "These applications are supported by the research in the ResNet paper, which explicitly mentions that ResNet features led to first-place wins in the ILSVRC 2015 competitions for detection and segmentation.\n",
        "\n",
        "**ViT for Multi-modal and Video Tasks**ðŸŽžï¸ <br>\n",
        "The Vision Transformer's strength is not limited to image patches; its architecture is inherently suitable for sequences of any kind.\n",
        "\n",
        "* **Video Classification:** A ViT model can be adapted for video classification by treating a video as a sequence of frames. The patches from each frame are flattened and arranged into a long sequence, which is then processed by the Transformer encoder. The model learns to understand the temporal relationships between frames, allowing it to classify the action in a video.\n",
        "\n",
        " * **Multi-modal Tasks:** ViT can be used for multi-modal tasks by combining image and text data. For example, in a vision-and-language model, a ViT encoder could be used to extract features from an image, while a text encoder (like BERT) extracts features from a text prompt. The outputs of both encoders are then combined in a single model that understands both modalities.\n",
        "\n",
        "**The ViT paper mentions this possibility in its conclusion, stating that applying ViT to other computer vision tasks like detection and segmentation is a promising direction for future research.**"
      ],
      "metadata": {
        "id": "WSYLJqxSkc_9"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}